---
title: Architettura delle applicazioni di Azure per la resilienza e disponibilità
description: Compilare la resilienza e disponibilità in un'applicazione Azure
author: MikeWasson
ms.date: 04/10/2019
ms.topic: article
ms.service: architecture-center
ms.subservice: cloud-design-principles
ms.openlocfilehash: ee4bb5b4a85e48fe0ff017297c31823c93a48f04
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 04/17/2019
ms.locfileid: "59646670"
---
# <a name="architecting-azure-applications-for-resiliency-and-availability"></a>Architettura delle applicazioni di Azure per la resilienza e disponibilità

Dopo aver sviluppato i requisiti per l'applicazione, il passaggio successivo consiste nella compilazione di resilienza e disponibilità al suo interno. Queste qualità non possono essere aggiunto alla fine &mdash; è necessario progettare li nell'architettura.

## <a name="conduct-a-failure-mode-analysis"></a>Condurre un'analisi della modalità di errore

*Analisi della modalità di errore* (FMA) si basa la resilienza in un sistema, identificando possibili punti di errore e che definisce come l'applicazione risponde a tali errori. La FMA deve essere delle fasi di progettazione e architettura di ripristino dagli errori è incorporata nel sistema dall'inizio. Gli obiettivi di un'analisi delle sono:

- Determinare quali tipi di errori di un'applicazione può verificarsi e come l'applicazione rileva questi errori.
- Acquisire i potenziali effetti di ogni tipo di errore e determinare la risposta dell'app.
- Pianificare la registrazione e monitoraggio dell'errore e identificare le strategie di ripristino.

Di seguito sono riportati alcuni esempi di modalità di errore e le strategie di rilevamento per un punto di errore specifico &mdash; una chiamata a un servizio web esterno:

| Modalità di errore           | Strategia di rilevamento           |
|------------------------|------------------------------|
| Il servizio non è disponibile | HTTP 5xx                     |
| Limitazione             | HTTP 429 (Troppe richieste) |
| Authentication         | HTTP 401 (Non autorizzato)      |
| Risposta lenta          | Timeout della richiesta            |

Per altre informazioni sul processo di FMA, con indicazioni specifiche per Azure, vedere [analisi della modalità di errore](../resiliency/failure-mode-analysis.md).

## <a name="plan-for-redundancy"></a>Piano per la ridondanza

Errori di variano nell'ambito dell'impatto. Alcuni errori hardware, ad esempio un disco guasto, influiscono su un singolo computer host. Un commutatore di rete non riusciti può influire su un rack di intero server. Errori meno comuni, ad esempio interruzione dell'alimentazione, interrompere un intero Data Center. È raro che un'intera area diventi non disponibile.

La ridondanza è un modo per rendere resiliente un'applicazione. Il livello di ridondanza dipende dai requisiti aziendali &mdash; non tutte le applicazioni richiedono la ridondanza tra aree per proteggersi da un'interruzione di area. In generale, è un compromesso tra incremento della ridondanza e affidabilità e versioni successive i costi e complessità.

### <a name="review-azure-redundancy-features"></a>Esaminare le funzionalità di ridondanza di Azure

Azure offre numerose funzionalità di ridondanza a ogni livello di errore, da una singola macchina virtuale (VM) di un'intera area.

- **Single VM** hanno un' [tempo di attività contratto di servizio (SLA)](https://azure.microsoft.com/support/legal/sla/virtual-machines) fornita da Azure. (La macchina virtuale deve usare archiviazione premium per tutti i dischi del sistema operativo e dischi dati). Anche se è possibile ottenere un contratto di servizio di livello superiore eseguendo due o più macchine virtuali, è possibile che una singola macchina virtuale sia già abbastanza affidabile per alcuni carichi di lavoro. Per i carichi di lavoro di produzione è tuttavia consigliabile usare due o più macchine virtuali per garantire la ridondanza.
- **Set di disponibilità** proteggerti da errori hardware localizzati, ad esempio un disco o errori di commutatore di rete. Le macchine virtuali in un set di disponibilità vengono distribuite tra un massimo di tre *domini di errore*. Domini di errore definisce un gruppo di macchine virtuali che condividono un comune power e commutatori di rete. Se un errore hardware influisce su un dominio di errore, viene indirizzato il traffico di rete alle macchine virtuali in altri domini di errore. Per altre informazioni sui set di disponibilità, vedere [gestire la disponibilità delle macchine virtuali Windows in Azure](/azure/virtual-machines/windows/manage-availability).
- **Le zone di disponibilità** sono aree fisicamente separate all'interno di un'area di Azure. Ogni zona di disponibilità può contare su risorse di alimentazione, rete e raffreddamento a sé. Distribuzione di macchine virtuali tra zone di disponibilità consente di proteggere un'applicazione in caso di errori a livello di Data Center. Le zone di disponibilità non sono supportate in tutte le aree. Per un elenco delle aree e dei servizi supportati, vedere [Informazioni sulle zone di disponibilità di Azure](/azure/availability-zones/az-overview).

    Se si prevede di usare le zone di disponibilità nella distribuzione, per prima cosa verificare che l'architettura dell'applicazione e la codebase supporta questa configurazione. Se si distribuisce il software commerciale, consultare il fornitore di software e testare in modo adeguato prima della distribuzione nell'ambiente di produzione. Un'applicazione deve mantenere lo stato e impedire la perdita di dati durante un'interruzione all'interno della zona configurata. L'applicazione deve supportare in esecuzione in un'infrastruttura flessibile e distribuita senza componenti di infrastruttura a livello di codice.
- **Azure Site Recovery** necessita di macchine virtuali di Azure in un'altra area di Azure per la continuità aziendale (BC) e il ripristino di emergenza (DR) di replica. È possibile condurre esercitazioni periodiche per assicurare che siano soddisfatti i requisiti di conformità. La macchina virtuale viene replicata con le impostazioni specificate nell'area selezionata in modo che è possibile ripristinare le applicazioni in caso di interruzioni nell'area di origine. Per altre informazioni, vedere [configurare il ripristino di emergenza in un'area di Azure secondaria per una macchina virtuale di Azure](/azure/site-recovery/azure-to-azure-quickstart/).

    Durante il test, verificare che il *obiettivo tempo di ripristino* (RTO) e *obiettivo del punto di ripristino* (RPO) soddisfa le proprie esigenze. RTO è il tempo massimo di che un'applicazione non è disponibile dopo un evento imprevisto e RPO è la durata massima di perdita dei dati durante un'emergenza.
- **Aree abbinate** vengono create usando Gestione traffico di Azure per distribuire il traffico Internet in aree diverse, la protezione di un'applicazione da un'interruzione di area. Ogni area di Azure è associata a un'altra area Insieme, queste aree formano un [ *coppia di aree*](/azure/best-practices-availability-paired-regions). Per soddisfare i requisiti di residenza dei dati per finalità fiscali e adempimenti, le coppie di aree si trovano all'interno della stessa area geografica (ad eccezione del Brasile meridionale).

    Per migliorare la resilienza dell'applicazione, Azure serializza gli aggiornamenti della piattaforma (manutenzione pianificata) tra ogni coppia di aree, in modo che solo una area abbinata viene aggiornata alla volta.
- Quando si progetta un'applicazione multiarea, tenere presente che la latenza di rete tra le aree è superiore all'interno di un'area. Ad esempio, se si replica un database per abilitare il failover, usare la replica di dati sincrona all'interno di un'area, ma la replica asincrona dei dati tra aree.

Nella tabella seguente confronta i fattori di ridondanza tra diverse strategie di resilienza:

| &nbsp; | Set di disponibilità | Zona di disponibilità | Azure Site Recovery/Area associata |
|--------|------------------|-------------------|-----------------------------------|
| Ambito dell'errore | Rack                  | Data center               | Region                               |
| Routing delle richieste  | Azure Load Balancer   | Bilanciamento del carico tra zone | Gestione traffico di Azure                |
| Latenza di rete  | Molto bassa              | Basso                      | Medio-alta                          |
| Rete virtuale  | Rete virtuale di Azure | Rete virtuale di Azure          | Peering reti virtuali tra aree |

### <a name="complete-azure-redundancy-tasks"></a>Attività di ridondanza di Azure completo

Usare le attività seguenti per soddisfare i requisiti di ridondanza:

- **Distribuire più istanze di servizi.** Se l'applicazione dipende da una singola istanza di un servizio, crea un singolo punto di errore. Il provisioning di più istanze migliora sia la resilienza che la scalabilità. Per [Servizio app di Azure](/azure/app-service/app-service-value-prop-what-is/) selezionare un [piano di servizio app](/azure/app-service/azure-web-sites-web-hosting-plans-in-depth-overview/) che offra più istanze. Per la [macchine virtuali di Azure](/azure/virtual-machines/virtual-machines-windows-about/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json), verificare che l'architettura abbia più di una macchina virtuale e che ogni macchina virtuale sia inclusa un [set di disponibilità](/azure/virtual-machines/virtual-machines-windows-manage-availability/).

- **Replicare le macchine virtuali con Azure Site Recovery.** Quando si esegue la replica di macchine virtuali di Azure usando [Site Recovery](/azure/site-recovery/), tutti i dischi delle macchine Virtuali vengono replicati in modo continuo all'area di destinazione in modo asincrono. I punti di ripristino vengono creati ogni pochi minuti, fornendo un valore RPO nell'ordine di minuti.

- **Considerare di distribuire l'applicazione tra più aree.** Se l'applicazione viene distribuita in una singola area e l'area non è più disponibile, l'applicazione sarà inoltre disponibile. Questa circostanza potrebbe essere inaccettabile in base alle condizioni del contratto di servizio dell'applicazione. In questo caso, occorre considerare la possibilità di distribuire l'applicazione e i relativi servizi tra più aree. Può usare una distribuzione multiarea un' *attivo-attivo* oppure *attivo-passivo* configurazione. Una configurazione attiva-attiva distribuisce le richieste tra più aree attive. Una configurazione attiva-passiva mantiene le istanze a caldo nell'area secondaria, ma non invia il traffico non esiste, a meno che l'area primaria non riesce. Per le distribuzioni multiarea, è consigliabile distribuire le aree abbinate, descritto in precedenza. Per altre informazioni, vedere [Continuità aziendale e ripristino di emergenza (BCDR): aree geografiche abbinate di Azure](/azure/best-practices-availability-paired-regions).

- **Usare Gestione traffico di Microsoft Azure per eseguire il routing del traffico dell'applicazione in aree diverse.** [Gestione traffico di Azure](/azure/traffic-manager/traffic-manager-overview/) esegue il bilanciamento del carico a livello di DNS e indirizza il traffico alle diverse aree di base di [routing del traffico](/azure/traffic-manager/traffic-manager-routing-methods/) (metodo) e l'integrità degli endpoint dell'applicazione. Senza gestione traffico, si è limitati a una singola area per la distribuzione, che vincola la scala, aumenta la latenza per alcuni utenti e fa sì che i tempi di inattività dell'applicazione, nel caso di un'interruzione del servizio a livello di area.

- **Configurare il Gateway applicazione di Azure per usare più istanze.** A seconda dei requisiti dell'applicazione, un [gateway applicazione di Azure](/azure/application-gateway/application-gateway-introduction/) potrebbe essere più adatto per distribuire le richieste ai servizi dell'applicazione. Tuttavia, singole istanze del servizio Gateway applicazione non è garantite da un contratto di servizio, pertanto è possibile che l'applicazione potrebbe non riuscire se l'istanza del Gateway applicazione non riesce. Effettuare il provisioning di più di un'istanza di medie o grandi dimensioni per garantire la disponibilità del servizio sotto le condizioni per il [contratto di servizio Gateway applicazione](https://azure.microsoft.com/support/legal/sla/application-gateway/).

## <a name="design-for-scalability"></a>Progettazione per la scalabilità

*Scalabilità* è la capacità di un sistema di gestire un incremento del carico ed è uno dei [concetti fondamentali della qualità del software](../guide/pillars.md). Le operazioni di scalabilità durante la fase di progettazione includono:

- **Carichi di lavoro di partizione.** Progettare le diverse parti del processo in modo che siano discrete e scomponibili. Ridurre al minimo le dimensioni di ogni parte. In questo modo le parti di componenti da distribuire in modo da Ottimizza l'uso di ogni unità di calcolo. Facilita anche la scalabilità dell'applicazione con l'aggiunta di altre istanze di risorse specifiche. Per domini complessi, valutare la possibilità di adottare un'[architettura di microservizi](../guide/architecture-styles/microservices.md).
- **Progettare per la scalabilità.** La scalabilità consente alle applicazioni di reagire a un carico variabile aumentando e riducendo il numero di istanze di ruoli, le code e gli altri servizi. L'applicazione deve tuttavia essere progettata tenendo presente tale necessità. Ad esempio, l'applicazione e i servizi che usa devono essere senza stati per consentire le richieste a essere indirizzate a qualsiasi istanza. Con i servizi senza stato significa anche che l'aggiunta o rimozione di un'istanza non influire negativamente sugli utenti correnti.
- **Pianificare la crescita con unità di scala.** Per ogni risorsa, conoscere i limiti massimi di scalabilità e usare partizionamento orizzontale o la scomposizione per superare tali limiti. Progettare l'applicazione in modo che possa essere ridimensionata facilmente aggiungendo una o più unità di scala. Determinare le unità di scala per il sistema in termini di set di risorse ben definiti. In questo modo applicare operazioni di scalabilità semplice e meno soggetto a impatto negativo causato da mancanza di risorse in una parte dell'intero sistema. Ad esempio, aggiungendo *X* numero di macchine virtuali front-end potrebbe richiedere *Y* numero di code aggiuntive e *Z* numero di account di archiviazione per gestire il carico di lavoro aggiuntivo. In modo che un'unità di scala può essere costituito *X* istanze di macchine Virtuali *Y* code, e *Z* gli account di archiviazione.
- **Evitare l'affinità del client.** Dove possibile, assicurarsi che l'applicazione non richieda affinity. Le richieste possono quindi essere indirizzate a qualsiasi istanza e il numero di istanze è irrilevante. Questo inoltre evita il sovraccarico dovuto all'archiviazione, al recupero e alla gestione delle informazioni sullo stato per ogni utente.
- **È possibile sfruttare le funzionalità di scalabilità automatica della piattaforma.** Usare le funzionalità di scalabilità automatica predefinite quando possibile, piuttosto che meccanismi personalizzati o di terze parti. Regole di scalabilità Usa pianificata, laddove possibile, per garantire che le risorse sono disponibili senza un ritardo di avvio, ma aggiungere la scalabilità automatica reattiva alle regole, ove appropriato, per gestire variazioni impreviste della domanda. Per altre informazioni, vedere [indicazioni sulla scalabilità automatica](../best-practices/auto-scaling.md).  

  Se l'applicazione non è configurato per scalabilità orizzontale automatica man mano che aumenta di carico, è possibile che i servizi dell'applicazione avrà esito negativo se vengono saturati dalle richieste degli utenti. Per altre informazioni, vedere gli articoli seguenti:

  - Generale: [Elenco di controllo per la scalabilità](../checklist/scalability.md)
  - Servizio app di Azure: [Scalare il conteggio delle istanze manualmente o automaticamente](/azure/monitoring-and-diagnostics/insights-how-to-scale/)
  - Servizi cloud: [Come ridimensionare automaticamente un servizio Cloud](/azure/cloud-services/cloud-services-how-to-scale/)
  - Macchine virtuali: [Set di scalabilità di ridimensionamento automatico e macchina virtuale](/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview/)

- **Eseguire l'offload di attività a elevato utilizzo di CPU/IO come attività in background.** Se una richiesta a un servizio dovrebbe richiedere un certo periodo di tempo o potrebbe assorbire una quantità notevole di risorse, l'offload dell'elaborazione a un'attività separata. Usare i processi in background per eseguire queste attività. Questa strategia consente al servizio per continuare a ricevere altre richieste e di rimanere attivo. Per altre informazioni, vedere le [indicazioni sui processi in background](../best-practices/background-jobs.md).
- **Distribuire il carico di lavoro per le attività in background.** Se sono presenti numerose attività in background o se le attività richiedono molto tempo o risorse, suddividere il lavoro tra più unità di calcolo. Per una possibile soluzione, vedere l’articolo relativo al [modello di consumer concorrenti](../patterns/competing-consumers.md).
- **Prendere in considerazione lo spostamento verso un *"shared-nothing"* architettura.** Questa architettura Usa nodi indipendenti e autosufficienti che non dispone di alcun singolo punto di contesa (ad esempio archiviazione o servizi condivisi). In teoria un sistema di questo tipo può essere scalato quasi all'infinito. Sebbene in genere un approccio completamente "shared-nothing" non è pratico, può offrire opportunità per progettare una migliore scalabilità. Buona lo spostamento verso un'architettura "shared-nothing" esempi di partizionamento dei dati ed evitare l'utilizzo di affinità di sessione sul lato server lo stato e il client.
- **Progettare i requisiti di archiviazione dell'applicazione da rientrare negli obiettivi di scalabilità e prestazioni di archiviazione di Azure.** Archiviazione di Azure è progettato per funzionare entro obiettivi di scalabilità e prestazioni predefiniti, quindi progettare l'applicazione per usare l'archiviazione entro tali obiettivi. Se si superano questi obiettivi, l'applicazione verifichi la limitazione delle richieste di archiviazione. Per evitare la limitazione delle richieste, il provisioning degli account di archiviazione aggiuntivo. Se si esegue vantaggi il limite di account di archiviazione, eseguire il provisioning di altre sottoscrizioni di Azure e quindi eseguire il provisioning di account di archiviazione aggiuntivi. Per altre informazioni, vedere [Obiettivi di scalabilità e prestazioni per Archiviazione di Azure](/azure/storage/storage-scalability-targets/).
- **Selezionare le dimensioni della VM corrette per l'applicazione.** Misurare la CPU, memoria, disco e i/o delle macchine virtuali nell'ambiente di produzione effettivo e verificare che le dimensioni VM selezionate siano sufficiente. In caso contrario, l'applicazione potrebbe essere soggetta a problemi di capacità man mano che le VM si avvicinano ai propri limiti. Le dimensioni delle VM sono descritte in dettaglio in [Dimensioni per le macchine virtuali Windows in Azure](/azure/virtual-machines/virtual-machines-windows-sizes/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).

## <a name="determine-subscription-and-service-requirements"></a>Determinare i requisiti di sottoscrizione e del servizio

Scegliere la sottoscrizione corretta e le funzionalità del servizio per l'app seguendo queste attività:

- **Valutare i requisiti rispetto [sottoscrizione di Azure e limiti dei servizi](/azure/azure-subscription-service-limits/).** *Le sottoscrizioni di Azure* hanno limiti su determinati tipi di risorse, ad esempio il numero di gruppi di risorse, i core e gli account di archiviazione. Se i requisiti dell'applicazione superano i limiti di sottoscrizione di Azure, creare un'altra sottoscrizione di Azure ed eseguirne il provisioning con un numero sufficiente di risorse. I singoli servizi di Azure hanno limiti di consumo, ad esempio i limiti per l'archiviazione, la velocità effettiva, il numero di connessioni, le richieste al secondo e altre metriche. L'applicazione avrà esito negativo se tenta di usare le risorse oltre questi limiti, tempi di inattività del servizio di limitazione delle richieste e possibili per gli utenti interessati. A seconda del servizio specifico e ai requisiti dell'applicazione, è spesso possibile evitare questi limiti mediante la scalabilità verticale (ad esempio, scegliere un altro piano tariffario) o la scalabilità orizzontale (ad esempio l'aggiunta di nuove istanze).
- **Determinare il numero di account di archiviazione è necessario.** Azure consente un numero specifico di account di archiviazione per ogni sottoscrizione. Per altre informazioni, vedere [Sottoscrizione di Azure e limiti, quote e vincoli dei servizi](/azure/azure-subscription-service-limits/#storage-limits).
- **Selezionare il livello di servizio corretto per il database SQL di Azure.** Se l'applicazione usa Database SQL di Azure, selezionare il livello di servizio appropriato. Se il livello non può gestire i requisiti dell'applicazione database transaction unit (DTU), verrà limitato l'utilizzo dei dati. Per ulteriori informazioni sul piano di servizio corretto, vedere [Prestazioni e opzioni del database SQL: riconoscimento delle offerte in ogni livello di servizio](/azure/sql-database/sql-database-service-tiers/).
- **Effettuare il provisioning di unità di richiesta sufficienti (RUs) in Azure Cosmos DB**. Con Azure Cosmos DB, viene addebitato un costo per la velocità effettiva sottoposta a provisioning e per le risorse di archiviazione utilizzate su base oraria. Il costo di tutte le operazioni di database viene normalizzato come unità riservate, che consente di astrarre le risorse di sistema, ad esempio memoria, CPU e numero di IOPS. Per altre informazioni, vedere [Unità richiesta in Azure Cosmos DB](/azure/cosmos-db/request-units).

## <a name="load-balance-as-needed"></a>Bilanciamento del carico in base alle esigenze

Corretto il bilanciamento del carico consente di soddisfare i requisiti di disponibilità e per ridurre al minimo i costi associati alla disponibilità.

- **Usare il bilanciamento del carico per distribuire le richieste.** Bilanciamento del carico distribuisce le richieste dell'applicazione alle istanze del servizio integre rimuovendo le istanze danneggiate dalla rotazione. Se il servizio Usa servizio App di Azure o servizi Cloud di Azure, è già con bilanciamento del carico per l'utente. Tuttavia, se l'applicazione usa macchine virtuali di Azure, è necessario eseguire il provisioning di un bilanciamento del carico. Per altre informazioni, vedere [che cos'è Azure Load Balancer?](/azure/load-balancer/load-balancer-overview/)

  È possibile usare Azure Load Balancer per eseguire queste operazioni:

  - Il bilanciamento del carico Internet il traffico in ingresso alle macchine virtuali. Questa configurazione è nota come un [ *pubblica di Load Balancer*](/azure/load-balancer/load-balancer-overview#publicloadbalancer).
  - Bilanciare il carico del traffico tra le VM all'interno di una rete virtuale. È anche possibile raggiungere un front-end di Load Balancer da una rete locale in uno scenario ibrido. Entrambi questi scenari usano una configurazione che è noto come un [ *bilanciamento del carico interno*](/azure/load-balancer/load-balancer-overview#internalloadbalancer).
  - Port forwarding del traffico a una porta di dettagliata in macchine virtuali specifiche con regole NAT in ingresso network address translation (NAT).
  - Offrire [connettività in uscita](/azure/load-balancer/load-balancer-outbound-connections) per le macchine virtuali all'interno della rete virtuale usando un Load Balancer pubblico.

- **Bilanciamento del carico tra le aree con gestione traffico, ad esempio Gestione traffico di Azure.** Per il bilanciamento del carico di traffico tra le aree richiede una soluzione di gestione traffico e Azure offre [Traffic Manager](https://azure.microsoft.com/services/traffic-manager/). È anche possibile sfruttare i vantaggi dei servizi di terze parti che forniscono funzionalità di gestione del traffico simili.

## <a name="implement-resiliency-strategies"></a>Implementare strategie di resilienza

Questa sezione vengono descritte alcune strategie di resilienza comuni. La maggior parte delle strategie seguenti non sono limitata a una determinata tecnologia. Le descrizioni riepilogano l'idea generale alla base di ogni tecnica e includono collegamenti ad altri documenti.

- **Implementare modelli di resilienza** per le operazioni remote laddove appropriato. Se l'applicazione dipende dalla comunicazione tra servizi remoti, seguire [schemi progettuali](../patterns/category/resiliency.md) per gestire gli errori temporanei.

- **Ripetere gli errori temporanei.** Questi può essere causati da una perdita temporanea della connettività di rete, una connessione a database eliminato o da un timeout quando un servizio è occupato. Spesso, un errore temporaneo può essere risolto eseguendo nuovamente la richiesta.

  - Per molti servizi di Azure, il client software development kit (SDK) implementa automaticamente nuovi tentativi in modo trasparente al chiamante. Visualizzare [indicazioni per servizi specifici di ripetizione di tentativi](../best-practices/retry-service-specific.md).
  - Né lo implementa il [schema Retry](../patterns/retry.md) per consentire l'applicazione di gestire in modo trasparente gli errori temporanei previsti durante il tentativo di connettersi a una risorsa servizio o di rete.

- **Usare un interruttore di circuito** per gestire gli errori che potrebbero richiedere una quantità variabile di tempo a correggere. Il [schema Circuit Breaker](../patterns/circuit-breaker.md) può impedire a un'applicazione di tentare ripetutamente un'operazione che potrebbe non riuscire. L'interruttore esegue il wrapping delle chiamate a un servizio e tiene traccia del numero di errori recenti. Se il conteggio degli errori supera una soglia, l'interruttore inizia a restituire un codice di errore senza chiamare il servizio. In questo modo il tempo di servizio per il ripristino e consente di evitare errori a catena.
- **Isolare le risorse critiche.** Gli errori in un sottosistema possono propagarsi, causando errori in altre parti dell'applicazione. Questa situazione può verificarsi se un errore impedisce che le risorse come i thread o socket viene liberato, causandone l'esaurimento. Per evitare questo problema, è possibile partizionare un sistema in gruppi isolati, in modo che un errore in una partizione non causi l'arresto dell'intero sistema.

    Di seguito sono riportati alcuni esempi di questa tecnica, che talvolta viene denominato il [modello a scomparti](../patterns/bulkhead.md):

  - Partizionare un database (ad esempio, dal tenant) e assegnare a un pool separato di istanze del server web per ogni partizione.
  - Usare pool di thread distinti per isolare le chiamate a servizi diversi: questo consente di evitare errori a catena in caso di errore di uno dei servizi. Per un esempio, vedere Netflix [Hystrix library](https://medium.com/netflix-techblog/introducing-hystrix-for-resiliency-engineering-13531c1ab362).
  - Uso [contenitori](https://en.wikipedia.org/wiki/Operating-system-level_virtualization) per limitare le risorse disponibili per un sottosistema specifico.

      ![Diagramma del modello A scomparti](_images/bulkhead.png)

- **Si applicano [ *transazioni di compensazione*](../patterns/compensating-transaction.md)**. Una transazione di compensazione è una transazione che annulla gli effetti di un'altra transazione completata. In un sistema distribuito, può essere difficile da ottenere coerenza transazionale assoluta. Le transazioni di compensazione consentono di ottenere la coerenza tramite una serie di transazioni di dimensioni inferiori che possono essere annullate a ogni passaggio. Per organizzare un viaggio, ad esempio, un cliente potrebbe prenotare un'automobile, una camera di albergo e un volo. Se uno di questi passaggi non riesce, l'intera operazione ha esito negativo. Anziché tentare di usare una singola transazione distribuita per l'intera operazione, è possibile definire una transazione di compensazione per ogni passaggio.
- **Implementare operazioni asincrone, laddove possibile.** Le operazioni sincrone possono monopolizzare le risorse e bloccare altre operazioni mentre il chiamante attende il completamento del processo. Progettare ogni parte dell'applicazione per consentire operazioni asincrone, laddove possibile. Per altre informazioni su come implementare la programmazione asincrona in C\#, vedere [programmazione asincrona](/dotnet/articles/csharp/async).

## <a name="ensure-that-availability-meets-slas"></a>Assicurarsi che la disponibilità soddisfi i contratti di servizio

*Disponibilità* è la percentuale di tempo per cui il sistema funziona ed è ed è uno dei [concetti fondamentali della qualità del software](../guide/pillars.md). Utilizzare le attività in questa sezione per esaminare l'architettura dell'applicazione da un punto di vista della disponibilità per assicurarsi che la propria disponibilità soddisfi i contratti di servizio.

- **Evitare i singoli punti di errore.**  Tutti i componenti, i servizi, le risorse e le istanze di calcolo devono essere distribuiti come istanze multiple, per impedire che un singolo punto di errore influisca sulla disponibilità. Meccanismi di autenticazione possono anche essere un singolo punto di guasto. Progettare l'applicazione per cui può essere configurato per usare più istanze e per rilevare gli errori e reindirizzare le richieste a istanze senza errori, automaticamente se la piattaforma non esegue questa operazione automaticamente.
- **Scomporre i carichi di lavoro in base all'obiettivo a livello di servizio.**  Se un servizio è composto da carichi di lavoro critici e meno critici, gestirli in modo diverso e specificare le funzionalità del servizio e il numero di istanze per soddisfare i rispettivi requisiti di disponibilità.
- **Ridurre al minimo e comprendere le dipendenze del servizio.** Ridurre al minimo il numero di diversi servizi utilizzati, laddove possibile. Assicurarsi di aver compreso tutte le funzionalità e servizio dipendenze esistenti nel sistema. In particolare, esaminare l'impatto complessivo di errore o una riduzione delle prestazioni in ogni dipendenza.
- **Progettare attività e i messaggi vengano *idempotente*, laddove possibile.** Un'operazione è idempotente se può essere ripetuta più volte producendo lo stesso risultato. Questo può garantire che richieste duplicate non causino problemi. I consumer di messaggi e le operazioni da essi effettuate devono essere idempotenti, affinché la ripetizione di un'operazione eseguita in precedenza non invalidi i risultati. Questo può significare rilevamento di messaggi duplicati o verifica della coerenza usando un approccio ottimistico alla gestione dei conflitti.
- **Configurare i timeout delle richieste.**  Servizi e risorse possono diventare non disponibili, causando la mancata riuscita delle richieste. Assicurarsi che i timeout applicati siano appropriati per ogni servizio o risorsa e per il client che vi accede. In alcuni casi si potrebbe consentire un timeout più lungo per una determinata istanza di un client, in base al contesto e alle altre azioni eseguite dal client. I timeout breve possono causare un numero eccessivo di tentativi per i servizi e le risorse con latenza notevole. I timeout lungo possono causare il blocco, se un numero elevato di richieste viene accodato, in attesa di un servizio o una risorsa di rispondere.
- **Utilizzare un gestore dei messaggi che implementa l’elevata disponibilità per le transazioni critiche.** Molte applicazioni cloud usano la messaggistica per attivare le attività asincrone. Per garantire il recapito dei messaggi, il sistema di messaggistica deve garantire un'elevata disponibilità. [Messaggistica del Bus di servizio di Azure](/azure/service-bus-messaging) implementi *almeno una volta* semantica, che significa che un messaggio è garantito a essere recapitato almeno una volta. In determinate circostanze possono recapitare i messaggi duplicati. Se l'elaborazione dei messaggi è idempotente (vedere la voce precedente), il recapito ripetuto non dovrebbe essere un problema.
- **Gli utenti con volumi elevati. limitazione totale.** In alcuni casi, un numero ridotto di utenti crea un carico eccessivo. Ciò può avere un impatto sugli altri utenti e può ridurre la disponibilità complessiva dell'applicazione. Quando un singolo client esegue un numero eccessivo di richieste, l'applicazione può limitare il client per un determinato periodo. Durante il periodo di limitazione delle richieste, l'applicazione Rifiuta alcune o tutte le richieste da quel client. La soglia per la limitazione delle richieste spesso dipende dal livello di servizio del cliente. Per altre informazioni, vedere [modello di limitazione delle richieste](../patterns/throttling.md).

    La limitazione delle richieste non implica che il client è stato necessariamente che agisce da utenti malintenzionati &mdash; solo che venga superata la quota del servizio. In alcuni casi, un consumer potrebbe superare di molto la quota o, altrimenti, potrebbe comportarsi in modo errato. In tal caso, si potrebbe andare avanti e bloccare l'utente. In genere questo avviene bloccando una chiave API o un intervallo di indirizzi IP.
- **Progettare le applicazioni in modo che le prestazioni si riducano in modo non drastico.** Il carico su un'applicazione può superare la capacità di una o più parti e causare così una riduzione della disponibilità ed errori di connessione. La scalabilità è possibile attenuare questo problema, ma può raggiungere un limite imposto da altri fattori, ad esempio la disponibilità di risorse o costi. Quando un'applicazione raggiunge il limite di una risorsa, deve eseguire le operazioni necessarie per ridurre al minimo l'impatto per l'utente. Ad esempio, in un sistema di e-commerce, se il sottosistema di elaborazione degli ordini è sotto pressione o ha esito negativo, si può essere disabilitato temporaneamente, consentendo ad altre funzionalità, come l'esplorazione del catalogo prodotti. Potrebbe essere opportuno posticipare le richieste a un sottosistema in errore &mdash; , ad esempio, continuando a permettere ai clienti di inviare ordini ma salvandoli per l'elaborazione successiva quando il sottosistema di ordini è nuovamente disponibile.
- **Gestire correttamente gli eventi burst rapidi.** La maggior parte delle applicazioni deve gestire carichi di lavoro variabili nel tempo. La scalabilità automatica consente di gestire il carico, ma potrebbe richiedere qualche minuto per le istanze aggiuntive a portare in linea e gestire le richieste. Per evitare che picchi di attività sovraccaricare l'applicazione, progettarlo accodi le richieste ai servizi che utilizza e ridurre le prestazioni gradualmente quando code si avvicinano alla capacità. Verificare le prestazioni e capacità sufficienti disponibile sia nelle condizioni di non burst a svuotare le code e gestire le richieste in sospeso. Per ulteriori informazioni, vedere il [modello di livellamento dei carichi basato sulle code](../patterns/queue-based-load-leveling.md).
- **Comporre o eseguire il failback da più componenti.** Progettazione di applicazioni da usare più istanze senza impatto sul funzionamento e le connessioni esistenti, laddove possibile. Per ottimizzare la disponibilità, usare più istanze e distribuire le richieste tra di essi e rilevare ed evitare l'invio di richieste a istanze non riuscite.
- **Eseguire il failback un altro servizio o del flusso di lavoro.** Ad esempio, se si verifica un errore di scrittura al Database SQL, archiviare temporaneamente i dati nell'archivio Blob o della Cache Redis. Fornire un modo per ripetere le scritture nel database SQL quando il servizio risulta disponibile. In alcuni casi, un'operazione non riuscita potrebbe essere un'azione alternativa che consente all'applicazione di continuare a funzionare, anche quando un componente o servizio non riesce. Se possibile, rilevare gli errori e reindirizzare le richieste ad altri servizi, mentre il servizio primario è offline.
- **Usare il livellamento del carico per contenere i picchi di traffico.** Le applicazioni possono verificarsi picchi improvvisi di traffico, che possono sovraccaricare i servizi back-end. Se un servizio back-end non può rispondere alle richieste in modo sufficientemente rapido, possono accumulare le richieste in sospeso o il servizio può limitare l'applicazione. Per evitare questo problema, è possibile usare una coda come un buffer. Quando è presente un nuovo elemento di lavoro, anziché chiamare immediatamente, il servizio back-end dell'applicazione Accoda un elemento di lavoro per eseguire in modo asincrono. La coda si comporta come un buffer che contiene i picchi di carico. Per altre informazioni, vedere [modello di livellamento carico basata su coda](../patterns/queue-based-load-leveling.md).

## <a name="manage-your-data"></a>Gestione dei dati

Modalità di gestione dei dati viene riprodotto direttamente nella disponibilità dell'applicazione. L'attività in questa sezione consentono di creare un piano di gestione per assicurare la disponibilità.

- **La replica dei dati e comprendere i metodi di replica per gli archivi di dati dell'applicazione.** La replica dei dati è una strategia generale per la gestione degli errori non temporanei in un archivio dati. Prendere in considerazione entrambi i percorsi di lettura e scrittura. A seconda della tecnologia di archiviazione, è possibile avere più repliche scrivibili o potrebbe essere una singola replica scrivibile e più repliche di sola lettura. Per ottimizzare la disponibilità, è possibile posizionare le repliche in più aree. Tuttavia, questo approccio aumenta la latenza quando si replicano i dati. In genere, la replica tra aree viene eseguita in modo asincrono e ciò implica un modello di coerenza finale e la potenziale perdita di dati se una replica ha esito negativo.  

  È possibile usare [Azure Site Recovery](/azure/site-recovery/azure-to-azure-quickstart/) replicare le macchine virtuali di Azure da un'area a altra. Site Recovery replica i dati in modo continuo nell'area di destinazione. Quando si verifica un'interruzione nel sito primario, eseguire il failover in una posizione secondaria.

- **Assicurarsi che nessun account utente singolo disponga dell'accesso sia ai dati di produzione che a quelli di backup.** Se un singolo account utente dispone dell'autorizzazione di scrittura sia nelle origini dati di backup che nelle origini dati di produzione, i backup dei dati risultano compromessi. Un utente malintenzionato potrebbe eliminare intenzionalmente tutti i tuoi dati e un utente normale potrebbe eliminarli accidentalmente. Progettare l'applicazione per limitare le autorizzazioni di ogni account utente. Solo accesso in scrittura agli utenti che lo richiedono e concedere l'accesso per la produzione o backup, ma non entrambi.
- **Documentare e testare il processo di failover e failback di archivio dati.** Se un archivio dati catastrofico, un operatore umano deve seguire un set di istruzioni documentate per eseguire il failover in un nuovo archivio dati. Se le procedure documentate sono errori, un operatore sarà in grado di seguirle correttamente e per eseguire il failover della risorsa. Testare regolarmente le istruzioni delle procedure per verificare che l'operatore che segue la documentazione può correttamente il failover e failback.
- **Eseguire il backup dei dati e convalidare i backup dei dati.** Eseguire periodicamente uno script per convalidare l'integrità dei dati, dello schema e le query per garantire che i dati di backup siano quelli previsti. Accedere e segnalare eventuali incoerenze in modo che il servizio di backup possa essere riparato.
- **Usare backup e ripristino temporizzato in periodici.** Regolarmente e automaticamente il backup dei dati che non vengono mantenuti in un' posizione. Verificare che sia possibile in modo affidabile ripristinare i dati e l'applicazione stessa in caso di errore. Assicurarsi che i backup soddisfino l'obiettivo RPO. La replica dei dati non è una funzionalità di backup, perché operazioni dannose o errori umani possono danneggiare i dati in tutte le repliche. Il processo di backup deve essere sicuro, per proteggere i dati in transito e nel servizio di archiviazione. I database possono essere ripristinati in genere a un momento precedente in fase di usando i log delle transazioni. Per altre informazioni, vedere [ripristino dal danneggiamento dei dati o dall'eliminazione accidentale](../resiliency/recovery-data-corruption.md).
- **È consigliabile usare un account di archiviazione con ridondanza geografica.** I dati archiviati in un account di archiviazione di Azure vengono sempre replicati in locale. Tuttavia, esistono più strategie di replica quando viene eseguito il provisioning di un account di archiviazione. Per proteggere i dati delle applicazioni nel caso raro quando un'intera area diventi non disponibile, selezionare [archiviazione con ridondanza geografica di Azure e accesso in lettura (RA-GRS)](/azure/storage/storage-redundancy/#read-access-geo-redundant-storage).  

    > [!NOTE]
    > Per le macchine virtuali, non affidarsi alla replica RA-GRS per ripristinare i dischi di macchina virtuale (file VHD). Usare invece [Backup di Azure](/azure/backup).

- **È consigliabile distribuire i dati di riferimento in più aree.** I dati di riferimento sono dati di sola lettura che supportano le funzionalità di un'applicazione. In genere non vengono modificati spesso. Anche se il ripristino da backup è un modo per gestire le interruzioni del servizio a livello di area, l'obiettivo RTO è relativamente lungo. Quando si distribuisce l'applicazione in un'area secondaria, è possibile adottare alcune strategie che migliorano l'RTO per i dati di riferimento.

    Poiché le modifiche ai dati di riferimento raramente, è possibile migliorare l'obiettivo RTO mantenendo una copia permanente nell'area secondaria. Ciò consente di eliminare il tempo necessario per ripristinare i backup dopo un'emergenza. Per soddisfare i requisiti di ripristino di emergenza in più aree, è necessario distribuire insieme l'applicazione e i dati di riferimento in più aree.

- **Usare la concorrenza ottimistica e la coerenza finale.** Le transazioni che bloccano l'accesso alle risorse tramite il blocco (*concorrenza pessimistica*) può provocare una riduzione delle prestazioni e ridurre la disponibilità. Questi problemi possono diventare particolarmente gravi nei sistemi distribuiti. In molti casi, un'attenta progettazione e tecniche, ad esempio il partizionamento, possono ridurre al minimo le probabilità di conflitti tra gli aggiornamenti in corso. Se i dati vengono replicati o leggere da un archivio aggiornato separatamente, i dati saranno solo con coerenza finale. Ma i vantaggi superano in genere l'impatto sulla disponibilità dell'utilizzo di transazioni per assicurare la coerenza immediata.
- **Usare la replica geografica attiva per il Database SQL per replicare le modifiche a un database secondario.** La replica geografica attiva per il Database SQL esegue automaticamente la replica modifiche del database a database secondari nella stessa area o un'area diversa. Per altre informazioni, vedere [creazione e uso di replica geografica attiva](/azure/sql-database/sql-database-active-geo-replication).

  In alternativa, è possibile adottare un approccio più manuale tramite il **copia del DATABASE** comando per creare una copia di backup del database con coerenza transazionale. È inoltre possibile usare il servizio di importazione/esportazione di Database di SQL Azure, che supporta l'esportazione dei database nei file BACPAC (file compressi contenenti lo schema del database e i dati associati) che vengono archiviati nella risorsa di archiviazione BLOB di Azure. Archiviazione di Azure crea due repliche del file di backup nella stessa area. Tuttavia, la frequenza del processo di backup determina il valore RPO, ovvero la quantità di dati che potrebbero andare persi negli scenari di emergenza. Ad esempio, se il backup dei dati ogni ora e una situazione di emergenza si verifica due minuti prima del backup, si perderanno 58 minuti di dati. Inoltre, per tutelarsi da un'eventuale interruzione a livello di un'area, è consigliabile copiare i file BACPAC in un'area alternativa. Per altre informazioni, vedere [Panoramica della continuità aziendale con Database SQL di Azure](/azure/sql-database/sql-database-business-continuity).

- **Usare i backup geografici per SQL Data Warehouse.** Per SQL Data Warehouse, usare [i backup geografici](/azure/sql-data-warehouse/backup-and-restore) per eseguire il ripristino a un'area geografica abbinata per il ripristino di emergenza. Questi backup vengono eseguiti ogni 24 ore e possono essere ripristinati entro 20 minuti nell'area abbinata. Questa funzionalità è attivata per impostazione predefinita per tutte le istanze di SQL Data Warehouse. Per altre informazioni su come ripristinare il data warehouse, vedere [eseguire il ripristino da un'area geografica di Azure usando PowerShell.](/azure/sql-data-warehouse/sql-data-warehouse-restore)

- **Replicare i dischi della macchina virtuale con Azure Site Recovery.** Quando si esegue la replica di macchine virtuali di Azure usando [Site Recovery](/azure/site-recovery/), tutti i dischi delle macchine Virtuali vengono replicati in modo continuo all'area di destinazione in modo asincrono. I punti di ripristino vengono creati a intervalli di pochi minuti. In questo modo è un valore RPO nell'ordine di minuti.
- **Eseguire il backup di SQL Server in esecuzione nelle VM o configurare una sessione di log shipping.** In caso di esecuzione di SQL Server in VM, sono disponibili due opzioni: backup tradizionali e log shipping. I backup tradizionali consentono di ripristinare a uno specifico punto nel tempo, ma il processo di recupero è lento. Il ripristino dei backup tradizionali, è necessario iniziare con un backup completo iniziale e quindi applicare i backup eseguiti successivamente. La seconda opzione consiste nel configurare una sessione di log shipping per ritardare il ripristino dei backup del log (ad esempio, di due ore). in modo da disporre di una finestra per il ripristino da errori nel server primario.
- **Usare un processo personalizzato o uno strumento di terze parti per il backup di archiviazione di Azure.** Archiviazione di Azure, è possibile sviluppare un processo di backup personalizzato o usare uno strumento di backup di terze parti. La maggior parte delle progettazioni di applicazioni hanno complessità aggiuntive, in cui archiviazione di risorse fanno riferimento a altro. Si consideri ad esempio un database SQL con una colonna che si collega a un blob in archiviazione di Azure. Se i backup non vengono eseguiti contemporaneamente, è possibile che il database contenga il puntatore a un BLOB di cui non è stato eseguito il backup prima dell'errore. L'applicazione o il piano di ripristino di emergenza devono implementare i processi per la gestione di questa incoerenza dopo un ripristino.
- **Per altre piattaforme di dati ospitati nelle macchine virtuali, usare la replica nativa o le funzionalità di snapshot.** Altre piattaforme di dati, ad esempio Elasticsearch o MongoDB, hanno le proprie funzionalità e considerazioni durante la creazione di un backup integrato e processo di ripristino. Per queste piattaforme di dati, la raccomandazione generale consiste nell'usare qualsiasi replica nativa o disponibile basata sull'integrazione o funzionalità di snapshot. Se tali funzionalità non esistono o non sono adatti, considerare l'utilizzo degli snapshot di Backup di Azure o del disco per creare una copia di point-in-time di dati dell'applicazione. In tutti i casi, è importante determinare come eseguire backup coerenti, soprattutto quando i dati dell'applicazione si estende su più sistemi di file o più unità sono combinate in un singolo file system.
- **Comprendere i metodi di replica per le origini dati dell'applicazione.** I dati dell'applicazione verranno archiviati in origini dati diverse e verranno hanno diversi requisiti di disponibilità. Valutare i metodi di replica per ogni tipo di archiviazione dei dati in Azure, tra cui [ridondanza di archiviazione di Azure](/azure/storage/storage-redundancy/) e [Database SQL la replica geografica attiva](/azure/sql-database/sql-database-geo-replication-overview/) per assicurarsi che l'applicazione dei dati i requisiti sono soddisfatti. Se si replicano macchine virtuali di Azure usando [Site Recovery](/azure/site-recovery/), tutti i dischi delle macchine Virtuali vengono replicati in modo continuo all'area di destinazione in modo asincrono. I punti di ripristino vengono creati a intervalli di pochi minuti.
- **Stabilire strategie dei dati per il ripristino di emergenza.** Gestione corretta dei dati è un aspetto complesso di qualsiasi piano di ripristino di emergenza. Durante il processo di ripristino, il recupero dei dati richiede in genere più tempo. Opzioni diverse per la modalità con funzionalità ridotte implicano sfide complesse per il recupero dei dati e coerenza.

## <a name="next-steps"></a>Passaggi successivi

> [!div class="nextstepaction"]
> [Test per la resilienza e disponibilità](./testing.md)
