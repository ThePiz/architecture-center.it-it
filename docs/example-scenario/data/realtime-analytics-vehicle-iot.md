---
title: Inserimento ed elaborazione in tempo reale dei dati IoT per il settore automobilistico
titleSuffix: Azure Example Scenarios
description: Inserire ed elaborare in tempo reale i dati dei veicoli con l'IoT.
author: msdpalam
ms.date: 09/12/2018
ms.custom: fasttrack
ms.openlocfilehash: edb0dc495db8742ae07826de5158db48f919e81f
ms.sourcegitcommit: bb7fcffbb41e2c26a26f8781df32825eb60df70c
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 12/20/2018
ms.locfileid: "53644071"
---
# <a name="ingestion-and-processing-of-real-time-automotive-iot-data"></a><span data-ttu-id="2201e-103">Inserimento ed elaborazione in tempo reale dei dati IoT per il settore automobilistico</span><span class="sxs-lookup"><span data-stu-id="2201e-103">Ingestion and processing of real-time automotive IoT data</span></span>

<span data-ttu-id="2201e-104">Questo scenario di esempio compila una pipeline di inserimento ed elaborazione dei dati in tempo reale per inserire ed elaborare i messaggi dai dispositivi IoT (in generale sensori) in una piattaforma di analisi dei Big Data in Azure.</span><span class="sxs-lookup"><span data-stu-id="2201e-104">This example scenario builds a real time data ingestion and processing pipeline to ingest and process messages from IoT devices (in general sensors) into a big data analytic platform in Azure.</span></span> <span data-ttu-id="2201e-105">Le piattaforme di inserimento ed elaborazione di dati telematici dei veicoli sono fondamentali per creare soluzioni connesse per il settore automobilistico.</span><span class="sxs-lookup"><span data-stu-id="2201e-105">Vehicle telematics ingestion and processing platforms are the key to create connected car solutions.</span></span> <span data-ttu-id="2201e-106">Questo scenario specifico è sviluppato sulla base di sistemi di inserimento ed elaborazione di dati telematici dei veicoli.</span><span class="sxs-lookup"><span data-stu-id="2201e-106">This specific scenario is motivated by the car telematics ingestion and processing systems.</span></span> <span data-ttu-id="2201e-107">Tuttavia, gli schemi progettuali sono pertinenti anche per molte aziende che usano i sensori per gestire e monitorare sistemi complessi in settori come edilizia intelligente, comunicazioni, produzione, vendita al dettaglio e sanità.</span><span class="sxs-lookup"><span data-stu-id="2201e-107">However, the design patterns are relevant for many industries using sensors to manage and monitor complex systems in industries such as smart buildings, communications, manufacturing, retail, and healthcare.</span></span>

<span data-ttu-id="2201e-108">Questo esempio illustra una pipeline di inserimento ed elaborazione dei dati in tempo reale per i messaggi dai dispositivi IoT installati nei veicoli.</span><span class="sxs-lookup"><span data-stu-id="2201e-108">This example demonstrates a real time data ingestion and processing pipeline for messages from IoT devices installed in vehicles.</span></span> <span data-ttu-id="2201e-109">Migliaia e milioni di messaggi (o eventi) vengono generati da dispositivi IoT e sensori.</span><span class="sxs-lookup"><span data-stu-id="2201e-109">Thousands and millions of messages (or events) are generated by the IoT devices and sensors.</span></span> <span data-ttu-id="2201e-110">Tramite l'acquisizione e l'analisi di questi messaggi, è possibile decifrare importanti informazioni dettagliate e intraprendere azioni appropriate.</span><span class="sxs-lookup"><span data-stu-id="2201e-110">By capturing and analyzing these messages, we can decipher valuable insights and take appropriate actions.</span></span> <span data-ttu-id="2201e-111">Ad esempio, nel caso di dispositivi telematici predisposti per le automobili, se si riescono ad acquisire i messaggi dei dispositivi (IoT) in tempo reale, è possibile monitorare la posizione in tempo reale dei veicoli, pianificare percorsi ottimizzati, fornire assistenza agli automobilisti e supportare i settori correlati ai dati telematici come quello delle assicurazioni auto.</span><span class="sxs-lookup"><span data-stu-id="2201e-111">For example, with cars equipped telematics devices, if we can capture the device (IoT) messages in real time, we would be able to monitor the live location of vehicles, plan optimized routes, provide assistance to drivers, and support telematics-related industries such as auto insurance.</span></span>

<span data-ttu-id="2201e-112">Per questa dimostrazione di esempio, si supponga che un'azienda produttrice di autoveicoli voglia creare un sistema in tempo reale per inserire ed elaborare i messaggi provenienti dai dispositivi telematici.</span><span class="sxs-lookup"><span data-stu-id="2201e-112">For this example demonstration, imagine a car manufacturing company that wants to create a real time system to ingest and process messages from telematics devices.</span></span> <span data-ttu-id="2201e-113">Gli obiettivi dell'azienda includono:</span><span class="sxs-lookup"><span data-stu-id="2201e-113">The company's goals include:</span></span>

- <span data-ttu-id="2201e-114">Inserimento e archiviazione dei dati in tempo reale da dispositivi e sensori dei veicoli.</span><span class="sxs-lookup"><span data-stu-id="2201e-114">Ingest and store data in real time from vehicles sensors and devices.</span></span>
- <span data-ttu-id="2201e-115">Analisi dei messaggi per comprendere la posizione dei veicoli e altre informazioni generate tramite diversi tipi di sensori (ad esempio sensori del motore e sensori di ambiente).</span><span class="sxs-lookup"><span data-stu-id="2201e-115">Analyze the messages to understand vehicle location, and other information emitted through different types of sensors (such as engine-related sensors and environment-related sensors).</span></span>
- <span data-ttu-id="2201e-116">Archiviazione dei dati dopo l'analisi per un'ulteriore elaborazione downstream in modo da fornire informazioni dettagliate su cui è possibile eseguire azioni (ad esempio, negli scenari relativi agli incidenti le compagnie assicurative potrebbero essere interessate a sapere cosa è successo durante un incidente e così via).</span><span class="sxs-lookup"><span data-stu-id="2201e-116">Store the data after analysis for other downstream processing to provide actionable insights (For example, in accident scenarios, insurance agencies may be interested to know what happened during an accident etc.)</span></span>

## <a name="relevant-use-cases"></a><span data-ttu-id="2201e-117">Casi d'uso pertinenti</span><span class="sxs-lookup"><span data-stu-id="2201e-117">Relevant use cases</span></span>

<span data-ttu-id="2201e-118">Gli altri casi d'uso pertinenti includono:</span><span class="sxs-lookup"><span data-stu-id="2201e-118">Other relevant use cases include:</span></span>

- <span data-ttu-id="2201e-119">Promemoria e avvisi per la manutenzione del veicolo.</span><span class="sxs-lookup"><span data-stu-id="2201e-119">Vehicle maintenance reminders and alerting.</span></span>
- <span data-ttu-id="2201e-120">Servizi basati sulla posizione per i passeggeri del veicolo (SOS).</span><span class="sxs-lookup"><span data-stu-id="2201e-120">Location-based services for the vehicle passengers (that is, SOS).</span></span>
- <span data-ttu-id="2201e-121">Veicoli autonomi (senza pilota).</span><span class="sxs-lookup"><span data-stu-id="2201e-121">Autonomous (self-driving) vehicles.</span></span>

## <a name="architecture"></a><span data-ttu-id="2201e-122">Architettura</span><span class="sxs-lookup"><span data-stu-id="2201e-122">Architecture</span></span>

![Schermata](media/architecture-realtime-analytics-vehicle-data1.png)

<span data-ttu-id="2201e-124">In un'implementazione tipica di una pipeline di elaborazione dei Big Data il flusso di dati va da sinistra a destra.</span><span class="sxs-lookup"><span data-stu-id="2201e-124">In a typical big data processing pipeline implementation, the data flows from left to right.</span></span> <span data-ttu-id="2201e-125">In questa pipeline di elaborazione dei Big Data in tempo reale il flusso dei dati attraverso la soluzione avviene come segue:</span><span class="sxs-lookup"><span data-stu-id="2201e-125">In this real time big data processing pipeline, the data flows through the solution as follows:</span></span>

1. <span data-ttu-id="2201e-126">Gli eventi generati dalle origini dati IoT vengono inviati al livello di inserimento del flusso tramite Azure HDInsight Kafka sotto forma di flusso di messaggi.</span><span class="sxs-lookup"><span data-stu-id="2201e-126">Events generated from the IoT data sources are sent to the stream ingestion layer through Azure HDInsight Kafka as a stream of messages.</span></span> <span data-ttu-id="2201e-127">HDInsight Kafka archivia i flussi di dati negli argomenti per un intervallo di tempo configurabile.</span><span class="sxs-lookup"><span data-stu-id="2201e-127">HDInsight Kafka stores streams of data in topics for a configurable of time.</span></span>
2. <span data-ttu-id="2201e-128">Il consumer Kafka, Azure Databricks, preleva il messaggio in tempo reale dall'argomento Kafka, per elaborare i dati in base alla logica di business e può quindi inviarlo al livello di gestione per l'archiviazione.</span><span class="sxs-lookup"><span data-stu-id="2201e-128">Kafka consumer, Azure Databricks, picks up the message in real time from the Kafka topic, to process the data based on the business logic and can then send to Serving layer for storage.</span></span>
3. <span data-ttu-id="2201e-129">I servizi di archiviazione downstream, come Azure Cosmos DB, Azure SQL Data Warehouse o il database SQL di Azure, potranno quindi essere un'origine dati per il livello di presentazione e di azione.</span><span class="sxs-lookup"><span data-stu-id="2201e-129">Downstream storage services, like Azure Cosmos DB, Azure SQL Data warehouse, or Azure SQL DB, will then be a data source for presentation and action layer.</span></span>
4. <span data-ttu-id="2201e-130">Gli analisti aziendali possono usare Microsoft Power BI per analizzare i dati del data warehouse.</span><span class="sxs-lookup"><span data-stu-id="2201e-130">Business analysts can use Microsoft Power BI to analyze warehoused data.</span></span> <span data-ttu-id="2201e-131">È possibile creare anche altre applicazioni basate sul livello di gestione.</span><span class="sxs-lookup"><span data-stu-id="2201e-131">Other applications can be built upon the serving layer as well.</span></span> <span data-ttu-id="2201e-132">Ad esempio, è possibile esporre le API basate sui dati del livello del servizio per l'uso da parte di terze parti.</span><span class="sxs-lookup"><span data-stu-id="2201e-132">For example, we can expose APIs based on the service layer data for third party uses.</span></span>

### <a name="components"></a><span data-ttu-id="2201e-133">Componenti</span><span class="sxs-lookup"><span data-stu-id="2201e-133">Components</span></span>

<span data-ttu-id="2201e-134">Gli eventi generati dai dispositivi IoT (dati o messaggi) vengono inseriti, elaborati e quindi archiviati per un'ulteriore analisi, presentazione e azione, usando i componenti di Azure seguenti:</span><span class="sxs-lookup"><span data-stu-id="2201e-134">IoT device-generated events (data or messages) are ingested, processed, and then stored for further analysis, presentation, and action, using the following Azure components:</span></span>

- <span data-ttu-id="2201e-135">[Apache Kafka in HDInsight](/azure/hdinsight/kafka/apache-kafka-introduction) è nel livello di inserimento.</span><span class="sxs-lookup"><span data-stu-id="2201e-135">[Apache Kafka on HDInsight](/azure/hdinsight/kafka/apache-kafka-introduction) is in the ingestion layer.</span></span> <span data-ttu-id="2201e-136">I dati vengono scritti nell'argomento Kafka usando un'API Kafka Producer.</span><span class="sxs-lookup"><span data-stu-id="2201e-136">The data is written into the Kafka topic using a Kafka producer API.</span></span>
- <span data-ttu-id="2201e-137">[Azure Databricks](/services/databricks) si trova nel livello di trasformazione e analisi.</span><span class="sxs-lookup"><span data-stu-id="2201e-137">[Azure Databricks](/services/databricks) is located in the transformation and analytics layer.</span></span> <span data-ttu-id="2201e-138">I notebook di Databricks implementano un'API Kafka Consumer per leggere i dati dall'argomento Kafka.</span><span class="sxs-lookup"><span data-stu-id="2201e-138">Databricks notebooks implement a Kafka consumer API to read the data from the Kafka topic.</span></span>
- <span data-ttu-id="2201e-139">[Azure Cosmos DB](/services/cosmos-db), il [database SQL di Azure](/azure/sql-database/sql-database-technical-overview) e Azure SQL Data Warehouse si trovano nel livello di archiviazione di gestione, in cui Azure Databricks può scrivere i dati tramite connettori dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-139">[Azure Cosmos DB](/services/cosmos-db), [Azure SQL Database](/azure/sql-database/sql-database-technical-overview), and Azure SQL Data Warehouse are in the Serving storage layer, where Azure Databricks can write the data via data connectors.</span></span>
- <span data-ttu-id="2201e-140">[Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is) è un sistema distribuito per l'archiviazione e l'analisi di set di dati di dimensioni elevate.</span><span class="sxs-lookup"><span data-stu-id="2201e-140">[Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is) is a distributed system for storing and analyzing large datasets.</span></span> <span data-ttu-id="2201e-141">L'uso dell'elaborazione parallela elevata (MPP, Massively Parallel Processing) lo rende appropriato per l'esecuzione di analisi ad alte prestazioni.</span><span class="sxs-lookup"><span data-stu-id="2201e-141">Its use of massive parallel processing (MPP) makes it suitable for running high-performance analytics.</span></span>
- <span data-ttu-id="2201e-142">[Power BI](https://docs.microsoft.com/power-bi) è una suite di strumenti di analisi business che consente di analizzare i dati e condividere informazioni dettagliate.</span><span class="sxs-lookup"><span data-stu-id="2201e-142">[Power BI](https://docs.microsoft.com/power-bi) is a suite of business analytics tools to analyze data and share insights.</span></span> <span data-ttu-id="2201e-143">Power BI può eseguire una query su un modello semantico archiviato in Analysis Services oppure può eseguire direttamente una query in SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="2201e-143">Power BI can query a semantic model stored in Analysis Services, or it can query SQL Data Warehouse directly.</span></span>
- <span data-ttu-id="2201e-144">[Azure Active Directory (Azure AD)](/azure/active-directory) autentica gli utenti durante la connessione ad [Azure Databricks](https://azure.microsoft.com/services/databricks).</span><span class="sxs-lookup"><span data-stu-id="2201e-144">[Azure Active Directory (Azure AD)](/azure/active-directory) authenticates users, when connecting to [Azure Databricks](https://azure.microsoft.com/services/databricks).</span></span> <span data-ttu-id="2201e-145">Se si crea un cubo in [Analysis Services](/azure/analysis-services) in base al modello basato sui dati di Azure SQL Data Warehouse, è possibile usare AAD per connettersi al server di Analysis Services tramite Power BI.</span><span class="sxs-lookup"><span data-stu-id="2201e-145">If we would build a cube in [Analysis Services](/azure/analysis-services) based on the model based on Azure SQL Data Warehouse data, we could use AAD to connect to the Analysis Services server through Power BI.</span></span> <span data-ttu-id="2201e-146">Data Factory può usare anche Azure AD per eseguire l'autenticazione in SQL Data Warehouse tramite un'entità servizio o un'identità del servizio gestita.</span><span class="sxs-lookup"><span data-stu-id="2201e-146">Data Factory can also use Azure AD to authenticate to SQL Data Warehouse via a service principal or Managed Service Identity (MSI).</span></span>
- <span data-ttu-id="2201e-147">[Servizi app di Azure](/azure/app-service/app-service-web-overview), in particolare l'[app per le API](/services/app-service/api), può essere usato per esporre i dati a terze parti, sulla base dei dati archiviati nel livello di gestione.</span><span class="sxs-lookup"><span data-stu-id="2201e-147">[Azure App Services](/azure/app-service/app-service-web-overview), in particular [API App](/services/app-service/api) can be used to expose data to third parties, based on the data stored in the Serving Layer.</span></span>

## <a name="alternatives"></a><span data-ttu-id="2201e-148">Alternative</span><span class="sxs-lookup"><span data-stu-id="2201e-148">Alternatives</span></span>

![Schermata](media/architecture-realtime-analytics-vehicle-data2.png)

<span data-ttu-id="2201e-150">Una pipeline di Big Data più generalizzata può essere implementata usando altri componenti di Azure.</span><span class="sxs-lookup"><span data-stu-id="2201e-150">A more generalized big data pipeline could be implemented using other Azure components.</span></span>

- <span data-ttu-id="2201e-151">Nel livello di inserimento del flusso è possibile usare l'[hub IoT](https://azure.microsoft.com/services/iot-hub) o l'[hub eventi](https://azure.microsoft.com/services/event-hubs) invece di [HDInsight Kafka](/azure/hdinsight/kafka/apache-kafka-introduction) per inserire i dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-151">In the stream ingestion layer, we could use [IoT Hub](https://azure.microsoft.com/services/iot-hub) or [Event Hub](https://azure.microsoft.com/services/event-hubs), instead of [HDInsight Kafka](/azure/hdinsight/kafka/apache-kafka-introduction) to ingest data.</span></span>
- <span data-ttu-id="2201e-152">Nel livello di trasformazione e analisi è possibile usare [HDInsight Storm](/azure/hdinsight/storm/apache-storm-overview), [HDInsight Spark](/azure/hdinsight/spark/apache-spark-overview) o [Analisi di flusso di Azure](https://azure.microsoft.com/services/stream-analytics).</span><span class="sxs-lookup"><span data-stu-id="2201e-152">In the transformation and analytics layer, we could use [HDInsight Storm](/azure/hdinsight/storm/apache-storm-overview), [HDInsight Spark](/azure/hdinsight/spark/apache-spark-overview), or [Azure Stream Analytics](https://azure.microsoft.com/services/stream-analytics).</span></span>
- <span data-ttu-id="2201e-153">[Analysis Services](/azure/analysis-services) offre un modello semantico per i dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-153">[Analysis Services](/azure/analysis-services) provides a semantic model for your data.</span></span> <span data-ttu-id="2201e-154">Può anche aumentare le prestazioni del sistema durante l'analisi dei dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-154">It can also increase system performance when analyzing your data.</span></span> <span data-ttu-id="2201e-155">È possibile compilare il modello sulla base dei dati di Azure DW.</span><span class="sxs-lookup"><span data-stu-id="2201e-155">You can build the model based on Azure DW data.</span></span>

## <a name="considerations"></a><span data-ttu-id="2201e-156">Considerazioni</span><span class="sxs-lookup"><span data-stu-id="2201e-156">Considerations</span></span>

<span data-ttu-id="2201e-157">Le tecnologie disponibili in questa architettura sono state scelte in base alla scalabilità richiesta per elaborare gli eventi, al contratto di servizio per i servizi, alla gestione dei costi e alla facilità di gestione dei componenti.</span><span class="sxs-lookup"><span data-stu-id="2201e-157">The technologies in this architecture were chosen based on the scale needed to process events, the SLA of the services, the cost management and ease of management of the components.</span></span>

- <span data-ttu-id="2201e-158">L'istanza gestita di [HDInsight Kafka](/azure/hdinsight/kafka/apache-kafka-introduction) assicura un contratto di servizio del 99,9% ed è integrata con Azure Managed Disks.</span><span class="sxs-lookup"><span data-stu-id="2201e-158">Managed [HDInsight Kafka](/azure/hdinsight/kafka/apache-kafka-introduction) comes with a 99.9% SLA is integrated with Azure Managed Disks</span></span>
- <span data-ttu-id="2201e-159">[Azure Databricks](/azure/azure-databricks/what-is-azure-databricks) è ottimizzato per le prestazioni e la convenienza economica nel cloud.</span><span class="sxs-lookup"><span data-stu-id="2201e-159">[Azure Databricks](/azure/azure-databricks/what-is-azure-databricks) is optimized from the ground up for performance and cost-efficiency in the cloud.</span></span> <span data-ttu-id="2201e-160">Databricks Runtime aggiunge diverse funzionalità chiave per i carichi di lavoro di Apache Spark che possono migliorare le prestazioni e ridurre i costi da 10 a 100 volte durante l'esecuzione in Azure, ad esempio:</span><span class="sxs-lookup"><span data-stu-id="2201e-160">The Databricks Runtime adds several key capabilities to Apache Spark workloads that can increase performance and reduce costs by as much as 10-100x when running on Azure, including:</span></span>
- <span data-ttu-id="2201e-161">Azure Databricks si integra perfettamente con archivi e database di Azure: [Azure SQL Data Warehouse](/azure/sql-data-warehouse), [Azure Cosmos DB](https://azure.microsoft.com/services/cosmos-db), [Azure Data Lake Storage](https://azure.microsoft.com/services/storage/data-lake-storage) e [Archiviazione BLOB di Azure](https://azure.microsoft.com/services/storage/blobs)</span><span class="sxs-lookup"><span data-stu-id="2201e-161">Azure Databricks integrates deeply with Azure databases and stores: [Azure SQL Data Warehouse](/azure/sql-data-warehouse), [Azure Cosmos DB](https://azure.microsoft.com/services/cosmos-db), [Azure Data Lake Storage](https://azure.microsoft.com/services/storage/data-lake-storage), and [Azure Blob Storage](https://azure.microsoft.com/services/storage/blobs)</span></span>
  - <span data-ttu-id="2201e-162">Ridimensionamento e terminazione automatici dei cluster Spark per ridurre automaticamente al minimo i costi.</span><span class="sxs-lookup"><span data-stu-id="2201e-162">Autoscaling and autotermination for Spark clusters to automatically minimize costs.</span></span>
  - <span data-ttu-id="2201e-163">Ottimizzazioni delle prestazioni tra cui memorizzazione nella cache, indicizzazione e ottimizzazione query avanzata, in grado di migliorare le prestazioni da 10 a 100 volte rispetto alle distribuzioni tradizionali di Apache Spark in ambienti cloud o locali.</span><span class="sxs-lookup"><span data-stu-id="2201e-163">Performance optimizations including caching, indexing, and advanced query optimization, which can improve performance by as much as 10-100x over traditional Apache Spark deployments in cloud or on-premises environments.</span></span>
  - <span data-ttu-id="2201e-164">L'integrazione con Azure Active Directory consente di eseguire soluzioni complete basate su Azure tramite Azure Databricks.</span><span class="sxs-lookup"><span data-stu-id="2201e-164">Integration with Azure Active Directory enables you to run complete Azure-based solutions using Azure Databricks.</span></span>
  - <span data-ttu-id="2201e-165">Con l'accesso basato sui ruoli in Azure Databricks è possibile definire autorizzazioni utente specifiche per notebook, cluster, processi e dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-165">Role-based access in Azure Databricks enables fine-grained user permissions for notebooks, clusters, jobs, and data.</span></span>
  - <span data-ttu-id="2201e-166">Viene fornito con contratti di servizio di livello aziendale.</span><span class="sxs-lookup"><span data-stu-id="2201e-166">Comes with Enterprise-grade SLAs.</span></span>
- <span data-ttu-id="2201e-167">Azure Cosmos DB è il database multimodello di Microsoft distribuito a livello globale.</span><span class="sxs-lookup"><span data-stu-id="2201e-167">Azure Cosmos DB is Microsoft’s globally distributed, multi-model database.</span></span> <span data-ttu-id="2201e-168">Azure Cosmos DB è stato progettato con un'attenzione particolare alla distribuzione globale e alla scalabilità orizzontale.</span><span class="sxs-lookup"><span data-stu-id="2201e-168">Azure Cosmos DB was built from the ground up with global distribution and horizontal scale at its core.</span></span> <span data-ttu-id="2201e-169">Offre la distribuzione globale chiavi in mano in molte aree di Azure, tramite il ridimensionamento trasparente e la replica dei dati ovunque si trovino gli utenti.</span><span class="sxs-lookup"><span data-stu-id="2201e-169">It offers turnkey global distribution across any number of Azure regions by transparently scaling and replicating your data wherever your users are.</span></span> <span data-ttu-id="2201e-170">È possibile ridimensionare in modo elastico la velocità effettiva e le risorse di archiviazione in tutto il mondo e pagare solo quello che è necessario.</span><span class="sxs-lookup"><span data-stu-id="2201e-170">You can elastically scale throughput and storage worldwide, and pay only for the throughput and storage you need.</span></span>
- <span data-ttu-id="2201e-171">L'architettura di elaborazione parallela elevata (MPP, Massively Parallel Processing) di SQL Data Warehouse assicura scalabilità e prestazioni elevate.</span><span class="sxs-lookup"><span data-stu-id="2201e-171">The massively parallel processing architecture of SQL Data Warehouse provides scalability and high performance.</span></span>
- <span data-ttu-id="2201e-172">Azure SQL Data Warehouse offre contratti di servizio garantiti e procedure consigliate per la disponibilità elevata.</span><span class="sxs-lookup"><span data-stu-id="2201e-172">Azure SQL Data Warehouse has guaranteed SLAs and recommended practices for achieving high availability.</span></span>
- <span data-ttu-id="2201e-173">Quando l'attività di analisi è scarsa, l'azienda può ridimensionare Azure SQL Data Warehouse su richiesta, riducendo o persino sospendendo il calcolo per ridurre i costi.</span><span class="sxs-lookup"><span data-stu-id="2201e-173">When analysis activity is low, the company can scale Azure SQL Data Warehouse on demand, reducing or even pausing compute to lower costs.</span></span>
- <span data-ttu-id="2201e-174">Il modello di protezione di Azure SQL Data Warehouse assicura la sicurezza della connessione, l'autenticazione e l'autorizzazione tramite Azure AD o l'autenticazione di SQL Server, oltre alla crittografia.</span><span class="sxs-lookup"><span data-stu-id="2201e-174">The Azure SQL Data Warehouse security model provides connection security, authentication, and authorization via Azure AD or SQL Server authentication, and encryption.</span></span>

## <a name="pricing"></a><span data-ttu-id="2201e-175">Prezzi</span><span class="sxs-lookup"><span data-stu-id="2201e-175">Pricing</span></span>

<span data-ttu-id="2201e-176">Esaminare i [prezzi di Azure Databricks](https://azure.microsoft.com/pricing/details/databricks), i [prezzi di Azure HDInsight](https://azure.microsoft.com/pricing/details/hdinsight) e l'[esempio del costo di uno scenario di data warehousing](https://azure.com/e/b798fb70c53e4dd19fdeacea4db78276) tramite il calcolatore prezzi di Azure.</span><span class="sxs-lookup"><span data-stu-id="2201e-176">Review [Azure Databricks pricing](https://azure.microsoft.com/pricing/details/databricks), [Azure HDInsight pricing](https://azure.microsoft.com/pricing/details/hdinsight), [pricing sample for a data warehousing scenario](https://azure.com/e/b798fb70c53e4dd19fdeacea4db78276) via the Azure pricing calculator.</span></span> <span data-ttu-id="2201e-177">Modificare i valori per verificare l'effetto delle specifiche esigenze sui costi.</span><span class="sxs-lookup"><span data-stu-id="2201e-177">Adjust the values to see how your requirements affect your costs.</span></span>

- <span data-ttu-id="2201e-178">[Azure HDInsight](/azure/hdinsight) è un servizio cloud completamente gestito che rende semplice, facile e conveniente l'elaborazione di quantità molto elevate di dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-178">[Azure HDInsight](/azure/hdinsight) is a fully-managed cloud service that makes it easy, fast, and cost-effective to process massive amounts of data</span></span>
- <span data-ttu-id="2201e-179">[Azure Databricks](https://azure.microsoft.com/services/databricks) offre due carichi di lavoro distinti per numerose [istanze di macchina virtuale](https://azure.microsoft.com/pricing/details/databricks/#instances) ottimizzati per lo specifico flusso di lavoro di analisi dei dati. Il carico di lavoro per ingegneria dei dati consente ai data engineer di creare ed eseguire processi con facilità e il carico di lavoro per analisi dei dati permette ai data scientist di esplorare, visualizzare, modificare e condividere con facilità e in modo interattivo i dati e le informazioni dettagliate.</span><span class="sxs-lookup"><span data-stu-id="2201e-179">[Azure Databricks](https://azure.microsoft.com/services/databricks) offers two distinct workloads on several [VM Instances](https://azure.microsoft.com/pricing/details/databricks/#instances) tailored for your data analytics workflow—the Data Engineering workload makes it easy for data engineers to build and execute jobs, and the Data Analytics workload makes it easy for data scientists to explore, visualize, manipulate, and share data and insights interactively.</span></span>
- <span data-ttu-id="2201e-180">[Azure Cosmos DB](https://azure.microsoft.com/services/cosmos-db) garantisce latenze di pochi millisecondi al 99° percentile ovunque nel mondo, offre [più modelli di coerenza ben definiti](/azure/cosmos-db/consistency-levels) per ottimizzare le prestazioni e garantisce la disponibilità elevata con funzionalità di multihosting, il tutto basato su [contratti di servizio](https://azure.microsoft.com/support/legal/sla/cosmos-db) completi e leader del settore.</span><span class="sxs-lookup"><span data-stu-id="2201e-180">[Azure Cosmos DB](https://azure.microsoft.com/services/cosmos-db) guarantees single-digit-millisecond latencies at the 99th percentile anywhere in the world, offers [multiple well-defined consistency models](/azure/cosmos-db/consistency-levels) to fine-tune performance, and guarantees high availability with multi-homing capabilities—all backed by industry leading comprehensive [service level agreements](https://azure.microsoft.com/support/legal/sla/cosmos-db) (SLAs).</span></span>
- <span data-ttu-id="2201e-181">[Azure SQL Data Warehouse](https://azure.microsoft.com/pricing/details/sql-data-warehouse/gen2) consente di ridimensionare in modo indipendente i livelli di calcolo e archiviazione.</span><span class="sxs-lookup"><span data-stu-id="2201e-181">[Azure SQL Data Warehouse](https://azure.microsoft.com/pricing/details/sql-data-warehouse/gen2) allows you to scale your compute and storage levels independently.</span></span> <span data-ttu-id="2201e-182">Le risorse di calcolo vengono addebitate su base oraria ed è possibile ridimensionare o sospendere queste risorse su richiesta.</span><span class="sxs-lookup"><span data-stu-id="2201e-182">Compute resources are charged per hour, and you can scale or pause these resources on demand.</span></span> <span data-ttu-id="2201e-183">Le risorse di archiviazione vengono addebitate per terabyte, pertanto i costi aumenteranno man mano che si inseriscono altri dati.</span><span class="sxs-lookup"><span data-stu-id="2201e-183">Storage resources are billed per terabyte, so your costs will increase as you ingest more data.</span></span>
- <span data-ttu-id="2201e-184">[Analysis Services](https://azure.microsoft.com/pricing/details/analysis-services) è disponibile nei livelli Developer, Basic e Standard.</span><span class="sxs-lookup"><span data-stu-id="2201e-184">[Analysis Services](https://azure.microsoft.com/pricing/details/analysis-services) is available in developer, basic, and standard tiers.</span></span> <span data-ttu-id="2201e-185">Le istanze vengono addebitate in base alle unità di elaborazione di query (QPU) e alla memoria disponibile.</span><span class="sxs-lookup"><span data-stu-id="2201e-185">Instances are priced based on query processing units (QPUs) and available memory.</span></span> <span data-ttu-id="2201e-186">Per contenere i costi, ridurre al minimo il numero di query eseguite, la quantità di dati elaborata e la frequenza di esecuzione.</span><span class="sxs-lookup"><span data-stu-id="2201e-186">To keep your costs lower, minimize the number of queries you run, how much data they process, and how often they run.</span></span>
- <span data-ttu-id="2201e-187">[Power BI](https://powerbi.microsoft.com/pricing) offre diverse opzioni di prodotto per i differenti requisiti.</span><span class="sxs-lookup"><span data-stu-id="2201e-187">[Power BI](https://powerbi.microsoft.com/pricing) has different product options for different requirements.</span></span> <span data-ttu-id="2201e-188">[Power BI Embedded](https://azure.microsoft.com/pricing/details/power-bi-embedded) fornisce un'opzione basata su Azure per incorporare le funzionalità di Power BI all'interno delle applicazioni.</span><span class="sxs-lookup"><span data-stu-id="2201e-188">[Power BI Embedded](https://azure.microsoft.com/pricing/details/power-bi-embedded) provides an Azure-based option for embedding Power BI functionality inside your applications.</span></span> <span data-ttu-id="2201e-189">Un'istanza di Power BI Embedded è inclusa nell'esempio di costi riportato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="2201e-189">A Power BI Embedded instance is included in the pricing sample above.</span></span>

## <a name="next-steps"></a><span data-ttu-id="2201e-190">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="2201e-190">Next Steps</span></span>

- <span data-ttu-id="2201e-191">Esaminare l'architettura di riferimento di [analisi in tempo reale](https://azure.microsoft.com/solutions/architecture/real-time-analytics) che include il flusso della pipeline di Big Data.</span><span class="sxs-lookup"><span data-stu-id="2201e-191">Review the [Real-time analytics](https://azure.microsoft.com/solutions/architecture/real-time-analytics) reference architecture that includes big data pipeline flow.</span></span>
- <span data-ttu-id="2201e-192">Esaminare l'architettura di riferimento di [analisi avanzata sui Big Data](https://azure.microsoft.com/solutions/architecture/advanced-analytics-on-big-data) per comprendere come i diversi componenti di Azure consentono di creare una pipeline di Big Data.</span><span class="sxs-lookup"><span data-stu-id="2201e-192">Review the [Advanced analytics on big data](https://azure.microsoft.com/solutions/architecture/advanced-analytics-on-big-data) reference architecture to get a peek on how different azure components can help build a big data pipeline.</span></span>
- <span data-ttu-id="2201e-193">Leggere la documentazione di Azure sull'[elaborazione in tempo reale](/azure/architecture/data-guide/big-data/real-time-processing) per una panoramica di come i diversi componenti di Azure consentono l'elaborazione di flussi di dati in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="2201e-193">Read the [Real time processing](/azure/architecture/data-guide/big-data/real-time-processing) Azure documentation to get a quick view of how different Azure components help in processing streams of data in real time.</span></span>
- <span data-ttu-id="2201e-194">Nella [Guida all'architettura dei dati di Azure](/azure/architecture/data-guide) sono disponibili indicazioni sull'architettura per pipeline di dati, data warehousing, Online Analytical Processing (OLAP) e Big Data.</span><span class="sxs-lookup"><span data-stu-id="2201e-194">Find comprehensive architectural guidance on data pipelines, data warehousing, online analytical processing (OLAP), and big data in the [Azure Data Architecture Guide](/azure/architecture/data-guide).</span></span>
