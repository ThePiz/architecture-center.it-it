---
title: Inserimento e flusso di lavoro nei microservizi
description: Inserimento e flusso di lavoro nei microservizi
author: MikeWasson
ms.date: 10/23/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: a36d2b4c7bfd2b26d5e1de44ddd8005fbce4bdd2
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 04/17/2019
ms.locfileid: "59640856"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="27742-103">Progettazione di microservizi: Inserimento e flusso di lavoro</span><span class="sxs-lookup"><span data-stu-id="27742-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="27742-104">I microservizi presentano spesso un flusso di lavoro che coinvolge più servizi per una singola transazione.</span><span class="sxs-lookup"><span data-stu-id="27742-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="27742-105">Il flusso di lavoro deve essere affidabile e non può perdere transazioni o lasciarle in uno stato parzialmente completato.</span><span class="sxs-lookup"><span data-stu-id="27742-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="27742-106">È anche fondamentale controllare la frequenza di inserimento delle richieste in ingresso.</span><span class="sxs-lookup"><span data-stu-id="27742-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="27742-107">Con un numero elevato di piccoli servizi che comunicano tra loro, un picco di richieste in ingresso può compromettere la comunicazione tra i servizi.</span><span class="sxs-lookup"><span data-stu-id="27742-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![Diagramma del flusso di lavoro di inserimento](./images/ingestion-workflow.png)

> [!NOTE]
> <span data-ttu-id="27742-109">Questo articolo si basa su un'implementazione di riferimento di microservizi denominata il [applicazione di recapito tramite Drone](./design/index.md).</span><span class="sxs-lookup"><span data-stu-id="27742-109">This article is based on a microservices reference implementation called the [Drone Delivery application](./design/index.md).</span></span>

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="27742-110">Flusso di lavoro per il recapito tramite drone</span><span class="sxs-lookup"><span data-stu-id="27742-110">The drone delivery workflow</span></span>

<span data-ttu-id="27742-111">Nell'applicazione di recapito tramite drone è necessario eseguire le operazioni seguenti per pianificare un recapito:</span><span class="sxs-lookup"><span data-stu-id="27742-111">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="27742-112">Controllare lo stato dell'account del cliente (servizio account).</span><span class="sxs-lookup"><span data-stu-id="27742-112">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="27742-113">Creare una nuova entità pacchetto (servizio pacchetto).</span><span class="sxs-lookup"><span data-stu-id="27742-113">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="27742-114">Controllare se per il recapito è necessario un trasporto di terze parti, in base alle posizioni di prelievo e di recapito (servizio di trasporto di terze parti).</span><span class="sxs-lookup"><span data-stu-id="27742-114">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="27742-115">Pianificare un drone per il prelievo (servizio drone).</span><span class="sxs-lookup"><span data-stu-id="27742-115">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="27742-116">Creare una nuova entità recapito (servizio di recapito).</span><span class="sxs-lookup"><span data-stu-id="27742-116">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="27742-117">Questa è la parte centrale dell'intera applicazione, quindi il processo end-to-end deve essere efficiente e affidabile.</span><span class="sxs-lookup"><span data-stu-id="27742-117">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="27742-118">È necessario risolvere alcune sfide specifiche:</span><span class="sxs-lookup"><span data-stu-id="27742-118">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="27742-119">**Livellamento del carico**.</span><span class="sxs-lookup"><span data-stu-id="27742-119">**Load leveling**.</span></span> <span data-ttu-id="27742-120">Un numero eccessivo di richieste client può sovraccaricare il sistema con il traffico di rete tra servizi.</span><span class="sxs-lookup"><span data-stu-id="27742-120">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="27742-121">Può sovraccaricare anche le dipendenze di back-end, ad esempio i servizi di archiviazione o remoti.</span><span class="sxs-lookup"><span data-stu-id="27742-121">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="27742-122">Questi a loro volta potrebbero limitare i servizi che eseguono le chiamate, creando così una congestione nel sistema.</span><span class="sxs-lookup"><span data-stu-id="27742-122">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="27742-123">È quindi importante livellare il carico delle richieste in ingresso nel sistema, inserendole in un buffer o in una coda per l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="27742-123">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="27742-124">**Recapito garantito**.</span><span class="sxs-lookup"><span data-stu-id="27742-124">**Guaranteed delivery**.</span></span> <span data-ttu-id="27742-125">Per evitare di tralasciare le richieste client, il componente di inserimento deve fornire una garanzia di recapito dei messaggi di tipo at-least-once.</span><span class="sxs-lookup"><span data-stu-id="27742-125">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="27742-126">**Gestione degli errori**.</span><span class="sxs-lookup"><span data-stu-id="27742-126">**Error handling**.</span></span> <span data-ttu-id="27742-127">Se uno dei servizi restituisce un codice di errore o se si verifica un errore non temporaneo, non è possibile pianificare il recapito.</span><span class="sxs-lookup"><span data-stu-id="27742-127">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="27742-128">Un codice di errore potrebbe indicare una condizione di errore previsto (ad esempio, l'account del cliente è sospeso) o un errore imprevisto del server (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="27742-128">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="27742-129">Potrebbe anche non essere disponibile un servizio, con il conseguente timeout della chiamata di rete.</span><span class="sxs-lookup"><span data-stu-id="27742-129">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="27742-130">Verrà prima di tutto esaminato l'aspetto dell'inserimento, ovvero in che modo il sistema può inserire le richieste utente in ingresso a una velocità effettiva elevata.</span><span class="sxs-lookup"><span data-stu-id="27742-130">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="27742-131">Verrà quindi analizzato il modo in cui l'applicazione di recapito tramite drone può implementare un flusso di lavoro affidabile.</span><span class="sxs-lookup"><span data-stu-id="27742-131">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="27742-132">Ciò che emerge è che la progettazione del sottosistema di inserimento influisce sul back-end del flusso di lavoro.</span><span class="sxs-lookup"><span data-stu-id="27742-132">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="27742-133">Ingestion</span><span class="sxs-lookup"><span data-stu-id="27742-133">Ingestion</span></span>

<span data-ttu-id="27742-134">In base ai requisiti aziendali, il team di sviluppo ha identificato i seguenti requisiti non funzionali per l'inserimento:</span><span class="sxs-lookup"><span data-stu-id="27742-134">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="27742-135">Velocità effettiva elevata di 10.000 richieste/sec.</span><span class="sxs-lookup"><span data-stu-id="27742-135">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="27742-136">Possibilità di gestire picchi fino a 50.000 richieste/sec senza tralasciare le richieste client o senza che si verifichi il timeout.</span><span class="sxs-lookup"><span data-stu-id="27742-136">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="27742-137">Latenza inferiore a 500 ms nel 99° percentile.</span><span class="sxs-lookup"><span data-stu-id="27742-137">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="27742-138">Il requisito di gestione dei picchi di traffico occasionali rappresenta una sfida di progettazione.</span><span class="sxs-lookup"><span data-stu-id="27742-138">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="27742-139">In teoria, è possibile scalare orizzontalmente il sistema per gestire il traffico massimo previsto.</span><span class="sxs-lookup"><span data-stu-id="27742-139">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="27742-140">Il provisioning di un numero così elevato di risorse potrebbe però essere poco efficiente.</span><span class="sxs-lookup"><span data-stu-id="27742-140">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="27742-141">Per la maggior parte del tempo, l'applicazione non necessita di una capacità così elevata, quindi si tratterebbe di core inattivi, che costano denaro ma non aggiungono valore.</span><span class="sxs-lookup"><span data-stu-id="27742-141">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="27742-142">Un approccio migliore consiste nell'inserire le richieste in ingresso in un buffer e lasciare che il buffer funga da livellatore del carico.</span><span class="sxs-lookup"><span data-stu-id="27742-142">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="27742-143">In questo caso, il servizio di inserimento deve essere in grado di gestire la frequenza di inserimento massima in brevi periodi, ma i servizi back-end devono gestire solo il carico massimo prolungato.</span><span class="sxs-lookup"><span data-stu-id="27742-143">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="27742-144">Grazie al buffering nel front-end, non è necessario che i servizi back-end gestiscano picchi elevati di traffico.</span><span class="sxs-lookup"><span data-stu-id="27742-144">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="27742-145">Al livello richiesto dall'applicazione di recapito tramite drone, [Hub eventi di Azure](/azure/event-hubs/) è una buona opzione per il livellamento del carico.</span><span class="sxs-lookup"><span data-stu-id="27742-145">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="27742-146">Hub eventi offre bassa latenza e velocità effettiva elevata ed è una soluzione conveniente per volumi di inserimento elevati.</span><span class="sxs-lookup"><span data-stu-id="27742-146">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="27742-147">Per i test è stato usato un hub eventi di livello Standard con 32 partizioni e 100 unità elaborate.</span><span class="sxs-lookup"><span data-stu-id="27742-147">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="27742-148">Sono stati osservati circa 32.000 eventi di inserimento al secondo, con una latenza intorno ai 90 ms.</span><span class="sxs-lookup"><span data-stu-id="27742-148">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="27742-149">Attualmente, il limite predefinito è di 20 unità elaborate, ma i clienti di Azure possono richiedere unità elaborate aggiuntive presentando una richiesta di supporto.</span><span class="sxs-lookup"><span data-stu-id="27742-149">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="27742-150">Per altre informazioni, vedere [Quote di Hub eventi](/azure/event-hubs/event-hubs-quotas).</span><span class="sxs-lookup"><span data-stu-id="27742-150">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="27742-151">Come per tutte le metriche delle prestazioni, ci sono molti fattori che possono influire sulle prestazioni, ad esempio le dimensioni del payload dei messaggio, quindi non bisogna interpretare questi valori come benchmark.</span><span class="sxs-lookup"><span data-stu-id="27742-151">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="27742-152">Se è necessaria una velocità effettiva maggiore, il servizio di inserimento può essere partizionato tra più hub eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-152">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="27742-153">Per velocità effettive ancora più alte, [Hub eventi dedicato](/azure/event-hubs/event-hubs-dedicated-overview) offre distribuzioni a singolo tenant che consentono di inserire oltre 2 milioni di eventi al secondo.</span><span class="sxs-lookup"><span data-stu-id="27742-153">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="27742-154">È importante capire in che modo Hub eventi può raggiungere una velocità effettiva così elevata, perché ciò influisce sul modo in cui un client deve utilizzare i messaggi di Hub eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-154">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="27742-155">Hub eventi non implementa una *coda*.</span><span class="sxs-lookup"><span data-stu-id="27742-155">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="27742-156">Implementa invece un *flusso di eventi*.</span><span class="sxs-lookup"><span data-stu-id="27742-156">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="27742-157">Con una coda, un singolo consumer può rimuovere un messaggio dalla coda e il consumer successivo non vedrà tale messaggio.</span><span class="sxs-lookup"><span data-stu-id="27742-157">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="27742-158">Le code permettono quindi di usare un [modello di consumer concorrenti](../patterns/competing-consumers.md) per elaborare i messaggi in parallelo e migliorare la scalabilità.</span><span class="sxs-lookup"><span data-stu-id="27742-158">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="27742-159">Per una maggiore resilienza, il consumer mantiene un blocco sul messaggio e lo rilascia al termine dell'elaborazione del messaggio.</span><span class="sxs-lookup"><span data-stu-id="27742-159">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="27742-160">Se si verifica un errore del consumer, ad esempio se il nodo in cui è in esecuzione si arresta in modo anomalo, si verifica il timeout del blocco e il messaggio torna nella coda.</span><span class="sxs-lookup"><span data-stu-id="27742-160">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![Diagramma della semantica delle code](./images/queue-semantics.png)

<span data-ttu-id="27742-162">Hub eventi usa invece una semantica di streaming.</span><span class="sxs-lookup"><span data-stu-id="27742-162">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="27742-163">I consumer leggono il flusso in modo indipendente in base al proprio ritmo.</span><span class="sxs-lookup"><span data-stu-id="27742-163">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="27742-164">Ogni consumer è responsabile di tenere traccia della propria posizione corrente nel flusso.</span><span class="sxs-lookup"><span data-stu-id="27742-164">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="27742-165">Un consumer deve scrivere la posizione corrente nell'archivio permanente a intervalli di tempo predefiniti.</span><span class="sxs-lookup"><span data-stu-id="27742-165">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="27742-166">In tal modo, se si verifica un errore del consumer (ad esempio, in caso di arresto anomalo del consumer o errore dell'host), una nuova istanza può riprendere la lettura del flusso dall'ultima posizione registrata.</span><span class="sxs-lookup"><span data-stu-id="27742-166">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="27742-167">Questo processo è detto *impostazione del checkpoint*.</span><span class="sxs-lookup"><span data-stu-id="27742-167">This process is called *checkpointing*.</span></span>

<span data-ttu-id="27742-168">Per motivi di prestazioni, un consumer in genere non imposta un checkpoint dopo ogni messaggio.</span><span class="sxs-lookup"><span data-stu-id="27742-168">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="27742-169">Lo fa invece a intervalli di tempo fissi, ad esempio dopo l'elaborazione di *n* messaggi o ogni *n* secondi.</span><span class="sxs-lookup"><span data-stu-id="27742-169">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="27742-170">Di conseguenza, in caso di errore di un consumer, alcuni eventi possono venire elaborati due volte, perché una nuova istanza preleva sempre i messaggi dall'ultimo checkpoint.</span><span class="sxs-lookup"><span data-stu-id="27742-170">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="27742-171">È necessario raggiungere un compromesso: checkpoint frequenti possono influire negativamente sulle prestazioni, mentre checkpoint sporadici comportano la ripetizione di un numero maggiore di eventi dopo un errore.</span><span class="sxs-lookup"><span data-stu-id="27742-171">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![Diagramma della semantica di streaming](./images/stream-semantics.png)

<span data-ttu-id="27742-173">Hub eventi non è progettato per i consumer concorrenti.</span><span class="sxs-lookup"><span data-stu-id="27742-173">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="27742-174">Anche se più consumer possono leggere un flusso, ognuno attraversa il flusso in modo indipendente.</span><span class="sxs-lookup"><span data-stu-id="27742-174">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="27742-175">Hub eventi usa invece un modello di consumer partizionato.</span><span class="sxs-lookup"><span data-stu-id="27742-175">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="27742-176">Un hub eventi può avere fino a 32 partizioni.</span><span class="sxs-lookup"><span data-stu-id="27742-176">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="27742-177">La scalabilità orizzontale viene ottenuta tramite l'assegnazione di un consumer separato a ogni partizione.</span><span class="sxs-lookup"><span data-stu-id="27742-177">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="27742-178">Cosa significa questo per il flusso di lavoro di recapito tramite drone?</span><span class="sxs-lookup"><span data-stu-id="27742-178">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="27742-179">Per sfruttare al meglio Hub eventi, l'utilità di pianificazione del recapito non può attendere l'elaborazione di ogni messaggio prima di passare al successivo.</span><span class="sxs-lookup"><span data-stu-id="27742-179">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="27742-180">Se lo facesse, passerebbe la maggior parte del tempo in attesa del completamento delle chiamate di rete.</span><span class="sxs-lookup"><span data-stu-id="27742-180">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="27742-181">Deve invece elaborare i batch di messaggi in parallelo, usando chiamate asincrone ai servizi back-end.</span><span class="sxs-lookup"><span data-stu-id="27742-181">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="27742-182">Come si vedrà, anche la scelta della giusta strategia di impostazione del checkpoint è importante.</span><span class="sxs-lookup"><span data-stu-id="27742-182">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="27742-183">Flusso di lavoro</span><span class="sxs-lookup"><span data-stu-id="27742-183">Workflow</span></span>

<span data-ttu-id="27742-184">Sono state esaminate tre opzioni per la lettura e l'elaborazione dei messaggi: l'host processore di eventi, le code del bus di servizio e la libreria IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="27742-184">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="27742-185">È stata scelta la libreria IoTHub React, ma per comprendere il motivo è utile iniziare dall'host processore di eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-185">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="27742-186">Host processore di eventi</span><span class="sxs-lookup"><span data-stu-id="27742-186">Event Processor Host</span></span>

<span data-ttu-id="27742-187">L'host processore di eventi è progettato per l'invio in batch dei messaggi.</span><span class="sxs-lookup"><span data-stu-id="27742-187">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="27742-188">L'applicazione implementa l'interfaccia `IEventProcessor` e l'host processore crea un'istanza del processore di eventi per ogni partizione nell'hub eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-188">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="27742-189">L'host processore di eventi chiama quindi ogni metodo `ProcessEventsAsync` del processore di eventi con batch dei messaggi di evento.</span><span class="sxs-lookup"><span data-stu-id="27742-189">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="27742-190">L'applicazione controlla quando impostare un checkpoint all'interno del metodo `ProcessEventsAsync` e l'host processore di eventi scrive i checkpoint in Archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="27742-190">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="27742-191">All'interno di una partizione, l'host processore di eventi attende che il metodo `ProcessEventsAsync` restituisca un risultato prima di eseguire una nuova chiamata con il batch successivo.</span><span class="sxs-lookup"><span data-stu-id="27742-191">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="27742-192">Questo approccio semplifica il modello di programmazione, perché il codice di elaborazione di eventi non deve necessariamente essere rientrante.</span><span class="sxs-lookup"><span data-stu-id="27742-192">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="27742-193">Tuttavia, significa anche che il processore di eventi gestisce un solo batch alla volta, limitando così la velocità con cui l'host processore può elaborare i messaggi.</span><span class="sxs-lookup"><span data-stu-id="27742-193">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="27742-194">L'host processore non resta effettivamente in *attesa*, nel senso di bloccare un thread.</span><span class="sxs-lookup"><span data-stu-id="27742-194">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="27742-195">Il metodo `ProcessEventsAsync` è asincrono, quindi l'host processore può eseguire altre operazioni mentre il metodo viene completato.</span><span class="sxs-lookup"><span data-stu-id="27742-195">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="27742-196">Tuttavia, non recapita un altro batch di messaggi per la partizione fino a quando il metodo non restituisce un risultato.</span><span class="sxs-lookup"><span data-stu-id="27742-196">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="27742-197">Nell'applicazione del drone, un batch di messaggi può essere elaborato in parallelo.</span><span class="sxs-lookup"><span data-stu-id="27742-197">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="27742-198">L'attesa del completamento dell'intero batch può però causare un collo di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="27742-198">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="27742-199">La velocità di elaborazione dipende dalla velocità del messaggio più lento all'interno di un batch.</span><span class="sxs-lookup"><span data-stu-id="27742-199">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="27742-200">Qualsiasi variazione nei tempi di risposta può creare una "lunga coda" in cui poche risposte lente intralciano l'intero sistema.</span><span class="sxs-lookup"><span data-stu-id="27742-200">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="27742-201">Dai test delle prestazioni è emerso che usando questo approccio non è stato raggiunto l'obiettivo prefissato per la velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="27742-201">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="27742-202">Ciò *non* significa che bisogna evitare di usare l'host processore di eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-202">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="27742-203">Per ottenere una velocità effettiva elevata, tuttavia, evitare le attività a esecuzione prolungata all'interno del metodo `ProcessEventsAsync`.</span><span class="sxs-lookup"><span data-stu-id="27742-203">But for high throughput, avoid doing any long-running tasks inside the `ProcessEventsAsync` method.</span></span> <span data-ttu-id="27742-204">Elaborare ogni batch rapidamente.</span><span class="sxs-lookup"><span data-stu-id="27742-204">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="27742-205">IotHub React</span><span class="sxs-lookup"><span data-stu-id="27742-205">IotHub React</span></span>

<span data-ttu-id="27742-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) è una libreria Akka Streams per la lettura degli eventi dall'hub eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="27742-207">Akka Streams è un framework di programmazione basato su flussi che implementa la specifica [Reactive Streams](https://www.reactive-streams.org/).</span><span class="sxs-lookup"><span data-stu-id="27742-207">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="27742-208">Consente di creare pipeline di streaming efficienti, in cui tutte le operazioni di streaming vengono eseguite in modo asincrono e la pipeline gestisce normalmente la congestione.</span><span class="sxs-lookup"><span data-stu-id="27742-208">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="27742-209">La congestione si verifica quando un'origine evento produce eventi a una frequenza maggiore rispetto a quanto i consumer downstream possono ricevere, che è esattamente la situazione che si verifica quando il sistema di recapito tramite drone ha un picco di traffico.</span><span class="sxs-lookup"><span data-stu-id="27742-209">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="27742-210">Se i servizi back-end rallentano, IoTHub React rallenta.</span><span class="sxs-lookup"><span data-stu-id="27742-210">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="27742-211">Se la capacità aumenta, IoTHub React esegue il push di più messaggi nella pipeline.</span><span class="sxs-lookup"><span data-stu-id="27742-211">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="27742-212">Akka Streams è anche un modello di programmazione molto naturale per lo streaming di eventi da Hub eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-212">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="27742-213">Invece di eseguire cicli in un batch di eventi, si definisce un set di operazioni che verranno applicate a ogni evento e si lascia gestire lo streaming da Akka Streams.</span><span class="sxs-lookup"><span data-stu-id="27742-213">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="27742-214">Akka Streams definisce una pipeline di streaming in termini di *origini*, *flussi* e *sink*.</span><span class="sxs-lookup"><span data-stu-id="27742-214">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="27742-215">Un'origine genera un flusso di output, un flusso elabora un flusso di input e produce un flusso di output e un sink utilizza un flusso senza produrre alcun output.</span><span class="sxs-lookup"><span data-stu-id="27742-215">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="27742-216">Ecco il codice nel servizio Utilità di pianificazione che consente di impostare la pipeline di Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="27742-216">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="27742-217">Questo codice configura Hub eventi come origine.</span><span class="sxs-lookup"><span data-stu-id="27742-217">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="27742-218">L'istruzione `map` deserializza ogni messaggio di evento in una classe Java che rappresenta una richiesta di recapito.</span><span class="sxs-lookup"><span data-stu-id="27742-218">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="27742-219">L'istruzione `filter` rimuove qualsiasi oggetto `null` dal flusso, per rispondere al caso in cui un messaggio non può essere deserializzato.</span><span class="sxs-lookup"><span data-stu-id="27742-219">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="27742-220">L'istruzione `via` crea un join tra l'origine e un flusso che elabora ogni richiesta di recapito.</span><span class="sxs-lookup"><span data-stu-id="27742-220">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="27742-221">Il metodo `to` crea un join tra il flusso e il sink di checkpoint, integrato in IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="27742-221">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="27742-222">IoTHub React usa una strategia di impostazione del checkpoint diversa rispetto al processore host di eventi.</span><span class="sxs-lookup"><span data-stu-id="27742-222">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="27742-223">I checkpoint vengono scritti dal sink di checkpoint, ovvero la fase finale nella pipeline.</span><span class="sxs-lookup"><span data-stu-id="27742-223">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="27742-224">La progettazione di Akka Streams contente alla pipeline di continuare a trasmettere i dati in streaming mentre il sink sta scrivendo il checkpoint.</span><span class="sxs-lookup"><span data-stu-id="27742-224">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="27742-225">Ciò significa che le fasi di elaborazione upstream non devono attendere l'impostazione del checkpoint.</span><span class="sxs-lookup"><span data-stu-id="27742-225">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="27742-226">È possibile configurare l'impostazione del checkpoint in modo che avvenga dopo un timeout o dopo l'elaborazione di un determinato numero di messaggi.</span><span class="sxs-lookup"><span data-stu-id="27742-226">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="27742-227">Il metodo `deliveryProcessor` crea il flusso Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="27742-227">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="27742-228">Il flusso chiama un metodo `processDeliveryRequestAsync` statico che esegue il lavoro effettivo di elaborazione di ogni messaggio.</span><span class="sxs-lookup"><span data-stu-id="27742-228">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="27742-229">Scalabilità con IoTHub React</span><span class="sxs-lookup"><span data-stu-id="27742-229">Scaling with IoTHub React</span></span>

<span data-ttu-id="27742-230">Il servizio Utilità di pianificazione è progettato in modo che ogni istanza di contenitore legga da una singola partizione.</span><span class="sxs-lookup"><span data-stu-id="27742-230">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="27742-231">Se, ad esempio, l'hub eventi ha 32 partizioni, il servizio Utilità di pianificazione viene distribuito con 32 repliche.</span><span class="sxs-lookup"><span data-stu-id="27742-231">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="27742-232">Questo consente una notevole flessibilità in termini di scalabilità orizzontale.</span><span class="sxs-lookup"><span data-stu-id="27742-232">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="27742-233">A seconda delle dimensioni del cluster, in un nodo del cluster può essere in esecuzione più di un pod del servizio Utilità di pianificazione.</span><span class="sxs-lookup"><span data-stu-id="27742-233">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="27742-234">Se però il servizio Utilità di pianificazione richiede più risorse, è possibile scalare orizzontalmente il cluster, per distribuire i pod tra più nodi.</span><span class="sxs-lookup"><span data-stu-id="27742-234">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="27742-235">Dai test delle prestazioni è emerso che il servizio Utilità di pianificazione dipende dalla memoria e dai thread, quindi le prestazioni dipendono in gran parte dalle dimensioni delle VM e dal numero di pod per ogni nodo.</span><span class="sxs-lookup"><span data-stu-id="27742-235">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="27742-236">Ogni istanza deve sapere da quale partizione di Hub eventi leggere.</span><span class="sxs-lookup"><span data-stu-id="27742-236">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="27742-237">Per configurare il numero di partizione, viene usato il tipo di risorsa [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) in Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="27742-237">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="27742-238">I pod in un oggetto StatefulSet hanno un identificatore permanente che include un indice numerico.</span><span class="sxs-lookup"><span data-stu-id="27742-238">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="27742-239">In particolare, il nome del pod è `<statefulset name>-<index>` e questo valore è disponibile per il contenitore attraverso l'[API Downward](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="27742-239">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="27742-240">In fase di esecuzione, il servizio Utilità di pianificazione legge il nome del pod e usa l'indice del pod come ID partizione.</span><span class="sxs-lookup"><span data-stu-id="27742-240">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="27742-241">Se è necessaria ulteriore scalabilità orizzontale per il servizio Utilità di pianificazione, è possibile assegnare più di un pod per partizione dell'hub eventi, in modo che più pod leggano ogni partizione.</span><span class="sxs-lookup"><span data-stu-id="27742-241">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="27742-242">In tal caso, tuttavia, ogni istanza leggerebbe tutti gli eventi nella partizione assegnata.</span><span class="sxs-lookup"><span data-stu-id="27742-242">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="27742-243">Per evitare l'elaborazione duplicata, sarebbe necessario usare un algoritmo di hash, in modo che ogni istanza ignori una parte dei messaggi.</span><span class="sxs-lookup"><span data-stu-id="27742-243">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="27742-244">In questo modo, più lettori possono utilizzare il flusso, ma ogni messaggio viene elaborato da una sola istanza.</span><span class="sxs-lookup"><span data-stu-id="27742-244">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![Diagramma dell'hashing di hub eventi](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="27742-246">Code del bus di servizio</span><span class="sxs-lookup"><span data-stu-id="27742-246">Service Bus queues</span></span>

<span data-ttu-id="27742-247">Una terza opzione considerata consiste nel copiare i messaggi da Hub eventi in una coda del bus di servizio e quindi fare in modo che il servizio Utilità di pianificazione legga i messaggi dal bus di servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-247">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="27742-248">Potrebbe sembrare strano scrivere le richieste in ingresso in Hub eventi solo per copiarle nel bus di servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-248">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="27742-249">Lo scopo, tuttavia, è sfruttare i diversi punti di forza di ogni servizio: usare Hub eventi per assorbire i picchi di traffico elevato sfruttando al tempo stesso la semantica delle code del bus di servizio per elaborare il carico di lavoro con un modello di consumer concorrenti.</span><span class="sxs-lookup"><span data-stu-id="27742-249">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="27742-250">Tenere presente che l'obiettivo per la velocità effettiva elevata è inferiore al carico di picco previsto, quindi l'elaborazione della coda del bus di servizio non deve necessariamente essere veloce quanto l'inserimento di messaggi.</span><span class="sxs-lookup"><span data-stu-id="27742-250">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="27742-251">Con questo approccio, l'implementazione di prova ha raggiunto circa 4.000 operazioni al secondo.</span><span class="sxs-lookup"><span data-stu-id="27742-251">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="27742-252">Per questi test sono stati usati servizi back-end fittizi che non eseguivano un lavoro effettivo, ma semplicemente aggiungevano una quantità fissa di latenza per ogni servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-252">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="27742-253">Si noti che i valori delle prestazioni sono stati molto inferiori rispetto al massimo teorico per il bus di servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-253">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="27742-254">Le possibili cause di questa discrepanza includono:</span><span class="sxs-lookup"><span data-stu-id="27742-254">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="27742-255">Assenza di valori ottimali per diversi parametri client, ad esempio il limite relativo al pool di connessioni, il grado di parallelizzazione, il numero di preletture e le dimensioni del batch.</span><span class="sxs-lookup"><span data-stu-id="27742-255">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="27742-256">Colli di bottiglia di I/O di rete.</span><span class="sxs-lookup"><span data-stu-id="27742-256">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="27742-257">Uso della modalità [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) invece di [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), necessaria per fornire una garanzia di recapito dei messaggi di tipo at-least-once.</span><span class="sxs-lookup"><span data-stu-id="27742-257">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="27742-258">Ulteriori test delle prestazioni avrebbero potuto aiutare a individuare la causa radice e a risolvere questi problemi.</span><span class="sxs-lookup"><span data-stu-id="27742-258">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="27742-259">Tuttavia, IotHub React ha soddisfatto l'obiettivo di prestazioni e quindi è stata scelta questa opzione.</span><span class="sxs-lookup"><span data-stu-id="27742-259">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="27742-260">Ciò detto, il bus di servizio è un'opzione valida per questo scenario.</span><span class="sxs-lookup"><span data-stu-id="27742-260">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="27742-261">Gestione degli errori</span><span class="sxs-lookup"><span data-stu-id="27742-261">Handling failures</span></span>

<span data-ttu-id="27742-262">Ci sono tre categorie generali di errore da considerare.</span><span class="sxs-lookup"><span data-stu-id="27742-262">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="27742-263">In un servizio downstream può verificarsi un errore non temporaneo, ovvero qualsiasi errore che è improbabile che si risolva da solo.</span><span class="sxs-lookup"><span data-stu-id="27742-263">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="27742-264">Gli errori non temporanei includono condizioni di errore normali, ad esempio un input non valido per un metodo.</span><span class="sxs-lookup"><span data-stu-id="27742-264">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="27742-265">Includono anche le eccezioni non gestite nel codice dell'applicazione o l'arresto anomalo di un processo.</span><span class="sxs-lookup"><span data-stu-id="27742-265">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="27742-266">Se si verifica questo tipo di errore, l'intera transazione aziendale deve essere contrassegnata come errore.</span><span class="sxs-lookup"><span data-stu-id="27742-266">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="27742-267">Potrebbe essere necessario annullare altri passaggi nella stessa transazione che hanno già avuto esito positivo.</span><span class="sxs-lookup"><span data-stu-id="27742-267">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="27742-268">Vedere la sezione Transazioni di compensazione più avanti.</span><span class="sxs-lookup"><span data-stu-id="27742-268">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="27742-269">In un servizio downstream può verificarsi un errore temporaneo, ad esempio un timeout di rete.</span><span class="sxs-lookup"><span data-stu-id="27742-269">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="27742-270">Questi errori spesso possono essere risolti semplicemente eseguendo nuovamente la chiamata.</span><span class="sxs-lookup"><span data-stu-id="27742-270">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="27742-271">Se l'errore continua a verificarsi dopo un certo numero di tentativi, viene considerato come errore non temporaneo.</span><span class="sxs-lookup"><span data-stu-id="27742-271">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="27742-272">Può verificarsi anche un errore del servizio Utilità di pianificazione stesso (ad esempio in caso di arresto anomalo di un nodo).</span><span class="sxs-lookup"><span data-stu-id="27742-272">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="27742-273">In tal caso, Kubernetes attiverà una nuova istanza del servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-273">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="27742-274">Sarà tuttavia necessario riprendere tutte le transazioni già in corso.</span><span class="sxs-lookup"><span data-stu-id="27742-274">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="27742-275">Transazioni di compensazione</span><span class="sxs-lookup"><span data-stu-id="27742-275">Compensating transactions</span></span>

<span data-ttu-id="27742-276">Se si verifica un errore non temporaneo, la transazione corrente potrebbe trovarsi in uno stato di *errore parziale*, in cui uno o più passaggi sono già stati completati correttamente.</span><span class="sxs-lookup"><span data-stu-id="27742-276">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="27742-277">Se, ad esempio, il servizio drone ha già pianificato un drone, il drone deve essere annullato.</span><span class="sxs-lookup"><span data-stu-id="27742-277">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="27742-278">In tal caso, l'applicazione deve annullare i passaggi che hanno avuto esito positivo, usando una [transazione di compensazione](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="27742-278">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="27742-279">In alcuni casi, questa operazione deve essere eseguita da un sistema esterno o anche tramite un processo manuale.</span><span class="sxs-lookup"><span data-stu-id="27742-279">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="27742-280">Se la logica per le transazioni di compensazione è complessa, prendere in considerazione la creazione di un servizio separato responsabile di questo processo.</span><span class="sxs-lookup"><span data-stu-id="27742-280">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="27742-281">Nell'applicazione di recapito tramite drone il servizio Utilità di pianificazione inserisce le operazioni non riuscite in una coda dedicata.</span><span class="sxs-lookup"><span data-stu-id="27742-281">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="27742-282">Un microservizio separato, detto supervisore, legge da questa coda e chiama un'API di annullamento per i servizi per cui è necessaria la compensazione.</span><span class="sxs-lookup"><span data-stu-id="27742-282">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="27742-283">Questa è una variante del [modello di supervisione agente di pianificazione][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="27742-283">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="27742-284">Il servizio supervisore potrebbe eseguire anche altre operazioni, ad esempio inviare all'utente una notifica tramite SMS o posta elettronica oppure inviare un avviso a un dashboard delle operazioni.</span><span class="sxs-lookup"><span data-stu-id="27742-284">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![Diagramma che illustra il microservizio supervisore](./images/supervisor.png)

## <a name="idempotent-versus-non-idempotent-operations"></a><span data-ttu-id="27742-286">Idempotenti rispetto alle operazioni non idempotenti</span><span class="sxs-lookup"><span data-stu-id="27742-286">Idempotent versus non-idempotent operations</span></span>

<span data-ttu-id="27742-287">Per evitare di perdere le richieste, il servizio Utilità di pianificazione deve garantire che tutti i messaggi vengano elaborati almeno una volta.</span><span class="sxs-lookup"><span data-stu-id="27742-287">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="27742-288">Hub eventi può fornire una garanzia di recapito dei messaggi di tipo at-least-once se il client imposta correttamente i checkpoint.</span><span class="sxs-lookup"><span data-stu-id="27742-288">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="27742-289">Se il servizio Utilità di pianificazione si arresta in modo anomalo, potrebbe essere in corso l'elaborazione di una o più richieste client.</span><span class="sxs-lookup"><span data-stu-id="27742-289">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="27742-290">Tali messaggi verranno prelevati da un'altra istanza dell'utilità di pianificazione e rielaborati.</span><span class="sxs-lookup"><span data-stu-id="27742-290">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="27742-291">Cosa succede se una richiesta viene elaborata due volte?</span><span class="sxs-lookup"><span data-stu-id="27742-291">What happens if a request is processed twice?</span></span> <span data-ttu-id="27742-292">È importante evitare di duplicare il lavoro.</span><span class="sxs-lookup"><span data-stu-id="27742-292">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="27742-293">Dopotutto, non si vuole che il sistema invii due droni per lo stesso pacchetto.</span><span class="sxs-lookup"><span data-stu-id="27742-293">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="27742-294">Un approccio consiste nel progettare tutte le operazioni in modo che siano idempotenti.</span><span class="sxs-lookup"><span data-stu-id="27742-294">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="27742-295">Un'operazione è idempotente se può essere chiamata più volte senza produrre effetti collaterali aggiuntivi dopo la prima chiamata.</span><span class="sxs-lookup"><span data-stu-id="27742-295">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="27742-296">In altre parole, un client può richiamare l'operazione una volta, due volte o più volte e il risultato sarà lo stesso.</span><span class="sxs-lookup"><span data-stu-id="27742-296">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="27742-297">In pratica, il servizio deve ignorare le chiamate duplicate.</span><span class="sxs-lookup"><span data-stu-id="27742-297">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="27742-298">Affinché un metodo con effetti collaterali sia idempotente, il servizio deve essere in grado di rilevare le chiamate duplicate.</span><span class="sxs-lookup"><span data-stu-id="27742-298">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="27742-299">Ad esempio, è possibile fare in modo che il chiamante assegni l'ID, piuttosto che generare un nuovo ID tramite il servizio.</span><span class="sxs-lookup"><span data-stu-id="27742-299">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="27742-300">Il servizio può quindi controllare la presenza di ID duplicati.</span><span class="sxs-lookup"><span data-stu-id="27742-300">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="27742-301">La specifica HTTP stabilisce che i metodi GET, PUT e DELETE devono essere idempotenti.</span><span class="sxs-lookup"><span data-stu-id="27742-301">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="27742-302">Non è invece garantito che i metodi POST siano idempotenti.</span><span class="sxs-lookup"><span data-stu-id="27742-302">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="27742-303">Se un metodo POST crea una nuova risorsa, in genere non ci sono garanzie che questa operazione sia idempotente.</span><span class="sxs-lookup"><span data-stu-id="27742-303">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="27742-304">Scrivere un metodo idempotente non è sempre semplice.</span><span class="sxs-lookup"><span data-stu-id="27742-304">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="27742-305">Un'altra opzione prevede che l'utilità di pianificazione tenga traccia dell'avanzamento di ogni transazione in un archivio permanente.</span><span class="sxs-lookup"><span data-stu-id="27742-305">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="27742-306">Ogni volta che viene elaborato un messaggio, viene eseguita una ricerca del relativo stato nell'archivio durevole.</span><span class="sxs-lookup"><span data-stu-id="27742-306">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="27742-307">Dopo ogni passaggio, il risultato deve essere scritto nell'archivio.</span><span class="sxs-lookup"><span data-stu-id="27742-307">After each step, it would write the result to the store.</span></span> <span data-ttu-id="27742-308">Questo approccio può influire sulle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="27742-308">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="27742-309">Esempio: operazioni idempotenti</span><span class="sxs-lookup"><span data-stu-id="27742-309">Example: Idempotent operations</span></span>

<span data-ttu-id="27742-310">La specifica HTTP stabilisce che i metodi PUT devono essere idempotenti.</span><span class="sxs-lookup"><span data-stu-id="27742-310">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="27742-311">La specifica definisce il concetto di idempotente in questo modo:</span><span class="sxs-lookup"><span data-stu-id="27742-311">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="27742-312">Un metodo di richiesta viene considerato "idempotente" se l'effetto previsto sul server di più richieste identiche con tale metodo è uguale all'effetto di una singola richiesta</span><span class="sxs-lookup"><span data-stu-id="27742-312">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="27742-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4)).</span><span class="sxs-lookup"><span data-stu-id="27742-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="27742-314">È importante comprendere la differenza tra la semantica di PUT e di POST quando si crea una nuova entità.</span><span class="sxs-lookup"><span data-stu-id="27742-314">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="27742-315">In entrambi i casi, il client invia una rappresentazione di un'entità nel corpo della richiesta.</span><span class="sxs-lookup"><span data-stu-id="27742-315">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="27742-316">Il significato dell'URI è tuttavia diverso.</span><span class="sxs-lookup"><span data-stu-id="27742-316">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="27742-317">Per un metodo POST, l'URI rappresenta una risorsa padre della nuova entità, ad esempio una raccolta.</span><span class="sxs-lookup"><span data-stu-id="27742-317">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="27742-318">Per creare, ad esempio, un nuovo recapito, l'URI potrebbe essere `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="27742-318">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="27742-319">Il server crea l'entità e le assegna un nuovo URI, ad esempio `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="27742-319">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="27742-320">Questo URI viene restituito nell'intestazione Location della risposta.</span><span class="sxs-lookup"><span data-stu-id="27742-320">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="27742-321">Ogni volta che il client invia una richiesta, il server crea una nuova entità con un nuovo URI.</span><span class="sxs-lookup"><span data-stu-id="27742-321">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="27742-322">Per un metodo PUT, l'URI identifica l'entità.</span><span class="sxs-lookup"><span data-stu-id="27742-322">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="27742-323">Se c'è già un'entità con tale URI, il server sostituisce l'entità esistente con la versione nella richiesta.</span><span class="sxs-lookup"><span data-stu-id="27742-323">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="27742-324">Se non c'è alcuna entità con tale URI, il server ne crea una.</span><span class="sxs-lookup"><span data-stu-id="27742-324">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="27742-325">Si supponga, ad esempio, che il client invii una richiesta PUT a `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="27742-325">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="27742-326">Presupponendo che non ci sia alcun recapito con tale URI, il server ne crea uno nuovo.</span><span class="sxs-lookup"><span data-stu-id="27742-326">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="27742-327">Se il client invia la stessa richiesta di nuovo, il server sostituisce l'entità esistente.</span><span class="sxs-lookup"><span data-stu-id="27742-327">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="27742-328">Di seguito è illustrata l'implementazione del servizio di recapito del metodo PUT.</span><span class="sxs-lookup"><span data-stu-id="27742-328">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="27742-329">È previsto che la maggior parte delle richieste creerà una nuova entità, quindi il metodo chiama in modo ottimistico `CreateAsync` sull'oggetto del repository e quindi gestisce eventuali eccezioni di risorsa duplicata aggiornando invece la risorsa.</span><span class="sxs-lookup"><span data-stu-id="27742-329">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md