---
title: Elaborazione batch
description: ''
author: zoinerTejada
ms.date: 02/12/2018
ms.openlocfilehash: 50e50ae121fda7ceb9dd298b8a072bd7cc4053d9
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 01/08/2019
ms.locfileid: "54114182"
---
# <a name="batch-processing"></a><span data-ttu-id="e26c4-102">Elaborazione batch</span><span class="sxs-lookup"><span data-stu-id="e26c4-102">Batch processing</span></span>

<span data-ttu-id="e26c4-103">Uno scenario di Big Data comune è costituito dall'elaborazione batch di dati inattivi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-103">A common big data scenario is batch processing of data at rest.</span></span> <span data-ttu-id="e26c4-104">In questo scenario i dati di origine vengono caricati nella risorsa di archiviazione dei dati tramite l'applicazione di origine o da un flusso di lavoro di orchestrazione.</span><span class="sxs-lookup"><span data-stu-id="e26c4-104">In this scenario, the source data is loaded into data storage, either by the source application itself or by an orchestration workflow.</span></span> <span data-ttu-id="e26c4-105">I dati vengono quindi elaborati sul posto da un processo parallelizzato, che può essere avviato anche dal flusso di lavoro di orchestrazione.</span><span class="sxs-lookup"><span data-stu-id="e26c4-105">The data is then processed in-place by a parallelized job, which can also be initiated by the orchestration workflow.</span></span> <span data-ttu-id="e26c4-106">L'elaborazione può includere più passaggi iterativi prima che i risultati trasformati vengano caricati in un archivio dati analitici su cui è possibile eseguire query tramite i componenti di analisi e report.</span><span class="sxs-lookup"><span data-stu-id="e26c4-106">The processing may include multiple iterative steps before the transformed results are loaded into an analytical data store, which can be queried by analytics and reporting components.</span></span>

<span data-ttu-id="e26c4-107">Ad esempio, i log di un server Web possono essere copiati in una cartella e quindi elaborati durante la notte per generare report giornalieri dell'attività Web.</span><span class="sxs-lookup"><span data-stu-id="e26c4-107">For example, the logs from a web server might be copied to a folder and then processed overnight to generate daily reports of web activity.</span></span>

![Diagramma di una pipeline di elaborazione batch](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a><span data-ttu-id="e26c4-109">Quando usare questa soluzione</span><span class="sxs-lookup"><span data-stu-id="e26c4-109">When to use this solution</span></span>

<span data-ttu-id="e26c4-110">L'elaborazione batch viene usata in una vasta gamma di scenari, dalle semplici trasformazioni di dati fino a pipeline ETL (Extract-Transform-Load) più complete.</span><span class="sxs-lookup"><span data-stu-id="e26c4-110">Batch processing is used in a variety of scenarios, from simple data transformations to a more complete ETL (extract-transform-load) pipeline.</span></span> <span data-ttu-id="e26c4-111">In un contesto di Big Data l'elaborazione batch può funzionare su set di dati di grandi dimensioni, in cui la fase di calcolo richiede tempi molto lunghi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-111">In a big data context, batch processing may operate over very large data sets, where the computation takes significant time.</span></span> <span data-ttu-id="e26c4-112">Ad esempio, vedere [Lambda architecture](../big-data/index.md#lambda-architecture) (Architettura lambda). L'elaborazione batch porta in genere a un'ulteriore esplorazione interattiva, fornisce i dati di modellazione per l'apprendimento automatico o scrive i dati in un archivio dati ottimizzato per l'analisi e la visualizzazione.</span><span class="sxs-lookup"><span data-stu-id="e26c4-112">(For example, see [Lambda architecture](../big-data/index.md#lambda-architecture).) Batch processing typically leads to further interactive exploration, provides the modeling-ready data for machine learning, or writes the data to a data store that is optimized for analytics and visualization.</span></span>

<span data-ttu-id="e26c4-113">Un esempio di elaborazione batch è la trasformazione di un ampio set di file flat semistrutturati CSV o JSON in un formato schematizzato e strutturato pronto per altre query.</span><span class="sxs-lookup"><span data-stu-id="e26c4-113">One example of batch processing is transforming a large set of flat, semi-structured CSV or JSON files into a schematized and structured format that is ready for further querying.</span></span> <span data-ttu-id="e26c4-114">I dati vengono in genere convertiti dai formati non elaborati usati per l'inserimento (ad esempio CSV) in formati binari che risultano più efficienti per l'esecuzione di query poiché archiviano i dati in colonne e offrono spesso indici e statistiche inline sui dati.</span><span class="sxs-lookup"><span data-stu-id="e26c4-114">Typically the data is converted from the raw formats used for ingestion (such as CSV) into binary formats that are more performant for querying because they store data in a columnar format, and often provide indexes and inline statistics about the data.</span></span>

## <a name="challenges"></a><span data-ttu-id="e26c4-115">Problematiche</span><span class="sxs-lookup"><span data-stu-id="e26c4-115">Challenges</span></span>

- <span data-ttu-id="e26c4-116">**Formato di dati e codifica**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-116">**Data format and encoding**.</span></span> <span data-ttu-id="e26c4-117">Alcuni dei problemi più difficili da correggere si verificano quando i file usano una codifica o un formato non previsto.</span><span class="sxs-lookup"><span data-stu-id="e26c4-117">Some of the most difficult issues to debug happen when files use an unexpected format or encoding.</span></span> <span data-ttu-id="e26c4-118">Ad esempio, i file di origine potrebbero usare una combinazione di codifica UTF-16 e UTF-8 oppure contenere delimitatori imprevisti (spazio anziché tabulazione) o includere caratteri imprevisti.</span><span class="sxs-lookup"><span data-stu-id="e26c4-118">For example, source files might use a mix of UTF-16 and UTF-8 encoding, or contain unexpected delimiters (space versus tab), or include unexpected characters.</span></span> <span data-ttu-id="e26c4-119">Un altro esempio comune è costituito da campi di testo che contengono tabulazioni, spazi o virgole interpretati come delimitatori.</span><span class="sxs-lookup"><span data-stu-id="e26c4-119">Another common example is text fields that contain tabs, spaces, or commas that are interpreted as delimiters.</span></span> <span data-ttu-id="e26c4-120">La logica di caricamento e analisi dei dati deve essere sufficientemente flessibile da rilevare e gestire questi problemi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-120">Data loading and parsing logic must be flexible enough to detect and handle these issues.</span></span>

- <span data-ttu-id="e26c4-121">**Orchestrazione dei periodi di tempo**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-121">**Orchestrating time slices**.</span></span> <span data-ttu-id="e26c4-122">Spesso i dati di origine sono inseriti in una gerarchia di cartelle che riflette gli intervalli di elaborazione, organizzati per anno, mese, giorno, ora e così via.</span><span class="sxs-lookup"><span data-stu-id="e26c4-122">Often source data is placed in a folder hierarchy that reflects processing windows, organized by year, month, day, hour, and so on.</span></span> <span data-ttu-id="e26c4-123">In alcuni casi, i dati possono arrivare in ritardo.</span><span class="sxs-lookup"><span data-stu-id="e26c4-123">In some cases, data may arrive late.</span></span> <span data-ttu-id="e26c4-124">Ad esempio, si supponga che in un server Web si verifichi un errore e che i log relativi al 7 marzo arrivino nella cartella di elaborazione solo il 9 marzo.</span><span class="sxs-lookup"><span data-stu-id="e26c4-124">For example, suppose that a web server fails, and the logs for March 7th don't end up in the folder for processing until March 9th.</span></span> <span data-ttu-id="e26c4-125">Sarà necessario stabilire se devono essere semplicemente ignorati a causa del ritardo</span><span class="sxs-lookup"><span data-stu-id="e26c4-125">Are they just ignored because they're too late?</span></span> <span data-ttu-id="e26c4-126">o se la logica di elaborazione downstream sarà in grado di gestire i record non disponibili.</span><span class="sxs-lookup"><span data-stu-id="e26c4-126">Can the downstream processing logic handle out-of-order records?</span></span>

## <a name="architecture"></a><span data-ttu-id="e26c4-127">Architettura</span><span class="sxs-lookup"><span data-stu-id="e26c4-127">Architecture</span></span>

<span data-ttu-id="e26c4-128">Un'architettura per l'elaborazione batch include i componenti logici seguenti, illustrati nel diagramma precedente.</span><span class="sxs-lookup"><span data-stu-id="e26c4-128">A batch processing architecture has the following logical components, shown in the diagram above.</span></span>

- <span data-ttu-id="e26c4-129">**Archiviazione dei dati**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-129">**Data storage**.</span></span> <span data-ttu-id="e26c4-130">In genere si tratta di un archivio di file distribuito che può essere usato come repository per volumi elevati di file di grandi dimensioni in diversi formati.</span><span class="sxs-lookup"><span data-stu-id="e26c4-130">Typically a distributed file store that can serve as a repository for high volumes of large files in various formats.</span></span> <span data-ttu-id="e26c4-131">Genericamente, questo tipo di archivio viene spesso definito data lake.</span><span class="sxs-lookup"><span data-stu-id="e26c4-131">Generically, this kind of store is often referred to as a data lake.</span></span>

- <span data-ttu-id="e26c4-132">**Elaborazione batch**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-132">**Batch processing**.</span></span> <span data-ttu-id="e26c4-133">Poiché i Big Data hanno dimensioni considerevoli, le soluzioni spesso devono elaborare i file di dati mediante processi batch con esecuzione prolungata per filtrare, aggregare e preparare in altro modo i dati per l'analisi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-133">The high-volume nature of big data often means that solutions must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="e26c4-134">In genere questi processi prevedono la lettura dei file di origine, la relativa elaborazione e la scrittura dell'output in nuovi file.</span><span class="sxs-lookup"><span data-stu-id="e26c4-134">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span>

- <span data-ttu-id="e26c4-135">**Archivio dati analitici**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-135">**Analytical data store**.</span></span> <span data-ttu-id="e26c4-136">Numerose soluzioni per Big Data sono progettate per preparare i dati per l'analisi e quindi servire i dati elaborati in un formato strutturato su cui è possibile eseguire query con strumenti di analisi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-136">Many big data solutions are designed to prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span>

- <span data-ttu-id="e26c4-137">**Analisi e creazione di report**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-137">**Analysis and reporting**.</span></span> <span data-ttu-id="e26c4-138">L'obiettivo della maggior parte delle soluzioni per Big Data è fornire informazioni dettagliate sui dati tramite funzionalità per l'analisi e la creazione di report.</span><span class="sxs-lookup"><span data-stu-id="e26c4-138">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span>

- <span data-ttu-id="e26c4-139">**Orchestrazione**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-139">**Orchestration**.</span></span> <span data-ttu-id="e26c4-140">Con l'elaborazione batch è in genere necessaria un'orchestrazione per eseguire la migrazione o la copia dei dati nella risorsa di archiviazione dati, nell'elaborazione batch, nell'archivio dati analitici e nei livelli per la creazione di report.</span><span class="sxs-lookup"><span data-stu-id="e26c4-140">With batch processing, typically some orchestration is required to migrate or copy the data into your data storage, batch processing, analytical data store, and reporting layers.</span></span>

## <a name="technology-choices"></a><span data-ttu-id="e26c4-141">Scelte di tecnologia</span><span class="sxs-lookup"><span data-stu-id="e26c4-141">Technology choices</span></span>

<span data-ttu-id="e26c4-142">Per le soluzioni di elaborazione batch in Azure è consigliabile usare le tecnologie seguenti.</span><span class="sxs-lookup"><span data-stu-id="e26c4-142">The following technologies are recommended choices for batch processing solutions in Azure.</span></span>

### <a name="data-storage"></a><span data-ttu-id="e26c4-143">Archiviazione dei dati</span><span class="sxs-lookup"><span data-stu-id="e26c4-143">Data storage</span></span>

- <span data-ttu-id="e26c4-144">**Contenitori BLOB del servizio di archiviazione di Azure**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-144">**Azure Storage Blob Containers**.</span></span> <span data-ttu-id="e26c4-145">Molti processi aziendali di Azure esistenti prevedono già l'uso di Archiviazione BLOB di Azure. Si tratta quindi di un'ottima scelta per un archivio di Big Data.</span><span class="sxs-lookup"><span data-stu-id="e26c4-145">Many existing Azure business processes already make use of Azure blob storage, making this a good choice for a big data store.</span></span>
- <span data-ttu-id="e26c4-146">**Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-146">**Azure Data Lake Store**.</span></span> <span data-ttu-id="e26c4-147">Azure Data Lake Store offre archiviazione praticamente illimitata per file di ogni dimensione e opzioni di sicurezza complete. Si tratta quindi di un'ottima scelta per soluzioni per Big Data su larga scala che richiedono un archivio centralizzato per i dati in formati eterogenei.</span><span class="sxs-lookup"><span data-stu-id="e26c4-147">Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.</span></span>

<span data-ttu-id="e26c4-148">Per altre informazioni, vedere [Archiviazione dei dati](../technology-choices/data-storage.md).</span><span class="sxs-lookup"><span data-stu-id="e26c4-148">For more information, see [Data storage](../technology-choices/data-storage.md).</span></span>

<!-- markdownlint-disable MD024 -->

### <a name="batch-processing"></a><span data-ttu-id="e26c4-149">Elaborazione batch</span><span class="sxs-lookup"><span data-stu-id="e26c4-149">Batch processing</span></span>

<!-- markdownlint-enable MD024 -->

- <span data-ttu-id="e26c4-150">**U-SQL**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-150">**U-SQL**.</span></span> <span data-ttu-id="e26c4-151">U-SQL è il linguaggio usato da Azure Data Lake Analytics per l'elaborazione delle query.</span><span class="sxs-lookup"><span data-stu-id="e26c4-151">U-SQL is the query processing language used by Azure Data Lake Analytics.</span></span> <span data-ttu-id="e26c4-152">Combina il carattere dichiarativo di SQL con l'estendibilità procedurale di C#, avvalendosi del parallelismo per consentire un'elaborazione efficiente dei dati su larga scala.</span><span class="sxs-lookup"><span data-stu-id="e26c4-152">It combines the declarative nature of SQL with the procedural extensibility of C#, and takes advantage of parallelism to enable efficient processing of data at massive scale.</span></span>
- <span data-ttu-id="e26c4-153">**Hive**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-153">**Hive**.</span></span> <span data-ttu-id="e26c4-154">Hive è un linguaggio simile a SQL ed è supportato in quasi tutte le distribuzioni Hadoop, incluso HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e26c4-154">Hive is a SQL-like language that is supported in most Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="e26c4-155">Consente di elaborare i dati da qualsiasi archivio compatibile con HDFS, inclusi Archiviazione BLOB di Azure e Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="e26c4-155">It can be used to process data from any HDFS-compatible store, including Azure blob storage and Azure Data Lake Store.</span></span>
- <span data-ttu-id="e26c4-156">**Pig**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-156">**Pig**.</span></span> <span data-ttu-id="e26c4-157">Pig è un linguaggio di elaborazione di Big Data di carattere dichiarativo usato in molte distribuzioni Hadoop, incluso HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e26c4-157">Pig is a declarative big data processing language used in many Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="e26c4-158">È particolarmente utile per l'elaborazione di dati non strutturati o semistrutturati.</span><span class="sxs-lookup"><span data-stu-id="e26c4-158">It is particularly useful for processing data that is unstructured or semi-structured.</span></span>
- <span data-ttu-id="e26c4-159">**Spark**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-159">**Spark**.</span></span> <span data-ttu-id="e26c4-160">Il motore Spark supporta programmi di elaborazione batch scritti in una serie di linguaggi, tra cui Java, Scala e Python.</span><span class="sxs-lookup"><span data-stu-id="e26c4-160">The Spark engine supports batch processing programs written in a range of languages, including Java, Scala, and Python.</span></span> <span data-ttu-id="e26c4-161">Spark usa un'architettura distribuita per elaborare i dati in parallelo in più nodi di lavoro.</span><span class="sxs-lookup"><span data-stu-id="e26c4-161">Spark uses a distributed architecture to process data in parallel across multiple worker nodes.</span></span>

<span data-ttu-id="e26c4-162">Per altre informazioni, vedere [Elaborazione batch](../technology-choices/batch-processing.md).</span><span class="sxs-lookup"><span data-stu-id="e26c4-162">For more information, see [Batch processing](../technology-choices/batch-processing.md).</span></span>

### <a name="analytical-data-store"></a><span data-ttu-id="e26c4-163">Archivio dati analitici</span><span class="sxs-lookup"><span data-stu-id="e26c4-163">Analytical data store</span></span>

- <span data-ttu-id="e26c4-164">**SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-164">**SQL Data Warehouse**.</span></span> <span data-ttu-id="e26c4-165">Azure SQL Data Warehouse è un servizio gestito basato su tecnologie di database di SQL Server e ottimizzato per supportare carichi di lavoro di data warehousing su larga scala.</span><span class="sxs-lookup"><span data-stu-id="e26c4-165">Azure SQL Data Warehouse is a managed service based on SQL Server database technologies and optimized to support large-scale data warehousing workloads.</span></span>
- <span data-ttu-id="e26c4-166">**Spark SQL**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-166">**Spark SQL**.</span></span> <span data-ttu-id="e26c4-167">Spark SQL è un'API basata su Spark che supporta la creazione di dataframe e tabelle su cui è possibile eseguire query usando la sintassi SQL.</span><span class="sxs-lookup"><span data-stu-id="e26c4-167">Spark SQL is an API built on Spark that supports the creation of dataframes and tables that can be queried using SQL syntax.</span></span>
- <span data-ttu-id="e26c4-168">**HBase**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-168">**HBase**.</span></span> <span data-ttu-id="e26c4-169">HBase è un archivio NoSQL a bassa latenza che offre un'opzione flessibile e a prestazioni elevate per eseguire query su dati strutturati e semistrutturati.</span><span class="sxs-lookup"><span data-stu-id="e26c4-169">HBase is a low-latency NoSQL store that offers a high-performance, flexible option for querying structured and semi-structured data.</span></span>
- <span data-ttu-id="e26c4-170">**Hive**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-170">**Hive**.</span></span> <span data-ttu-id="e26c4-171">Oltre a essere utile per l'elaborazione batch, Hive offre un'architettura di database concettualmente simile a quella di un sistema di gestione di database relazionali tipico.</span><span class="sxs-lookup"><span data-stu-id="e26c4-171">In addition to being useful for batch processing, Hive offers a database architecture that is conceptually similar to that of a typical relational database management system.</span></span> <span data-ttu-id="e26c4-172">I miglioramenti apportati alle prestazioni di esecuzione delle query Hive attraverso innovazioni come il motore Tez e l'iniziativa Stinger indicano che le tabelle Hive possono essere usate efficacemente come origini per query analitiche in alcuni scenari.</span><span class="sxs-lookup"><span data-stu-id="e26c4-172">Improvements in Hive query performance through innovations like the Tez engine and Stinger initiative mean that Hive tables can be used effectively as sources for analytical queries in some scenarios.</span></span>

<span data-ttu-id="e26c4-173">Per altre informazioni, vedere [Archivi dati analitici](../technology-choices/analytical-data-stores.md).</span><span class="sxs-lookup"><span data-stu-id="e26c4-173">For more information, see [Analytical data stores](../technology-choices/analytical-data-stores.md).</span></span>

### <a name="analytics-and-reporting"></a><span data-ttu-id="e26c4-174">Analisi e report</span><span class="sxs-lookup"><span data-stu-id="e26c4-174">Analytics and reporting</span></span>

- <span data-ttu-id="e26c4-175">**Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-175">**Azure Analysis Services**.</span></span> <span data-ttu-id="e26c4-176">Molte soluzioni per Big Data emulano le architetture di business intelligence aziendale tradizionali introducendo un modello di dati OLAP centralizzato (noto anche come cubo) in base al quale è possibile creare report, dashboard e analisi interattive approfondite.</span><span class="sxs-lookup"><span data-stu-id="e26c4-176">Many big data solutions emulate traditional enterprise business intelligence architectures by including a centralized online analytical processing (OLAP) data model (often referred to as a cube) on which reports, dashboards, and interactive “slice and dice” analysis can be based.</span></span> <span data-ttu-id="e26c4-177">Azure Analysis Services supporta la creazione di modelli tabulari per soddisfare questa esigenza.</span><span class="sxs-lookup"><span data-stu-id="e26c4-177">Azure Analysis Services supports the creation of tabular models to meet this need.</span></span>
- <span data-ttu-id="e26c4-178">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-178">**Power BI**.</span></span> <span data-ttu-id="e26c4-179">Power BI consente agli analisti di dati di creare visualizzazioni dati interattive basate sui modelli di dati di un modello OLAP o direttamente da un archivio dati analitici.</span><span class="sxs-lookup"><span data-stu-id="e26c4-179">Power BI enables data analysts to create interactive data visualizations based on data models in an OLAP model or directly from an analytical data store.</span></span>
- <span data-ttu-id="e26c4-180">**Microsoft Excel**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-180">**Microsoft Excel**.</span></span> <span data-ttu-id="e26c4-181">Microsoft Excel è una delle applicazioni software più diffuso al mondo e offre una vasta gamma di funzionalità di visualizzazione e analisi dei dati.</span><span class="sxs-lookup"><span data-stu-id="e26c4-181">Microsoft Excel is one of the most widely used software applications in the world, and offers a wealth of data analysis and visualization capabilities.</span></span> <span data-ttu-id="e26c4-182">Gli analisti di dati possono usare Excel per creare modelli di dati documento dagli archivi dati analitici o per recuperare dati da modelli di dati OLAP e trasferirli in tabelle pivot e grafici interattivi.</span><span class="sxs-lookup"><span data-stu-id="e26c4-182">Data analysts can use Excel to build document data models from analytical data stores, or to retrieve data from OLAP data models into interactive PivotTables and charts.</span></span>

<span data-ttu-id="e26c4-183">Per altre informazioni, vedere [Analisi e report](../technology-choices/analysis-visualizations-reporting.md).</span><span class="sxs-lookup"><span data-stu-id="e26c4-183">For more information, see [Analytics and reporting](../technology-choices/analysis-visualizations-reporting.md).</span></span>

### <a name="orchestration"></a><span data-ttu-id="e26c4-184">Orchestrazione</span><span class="sxs-lookup"><span data-stu-id="e26c4-184">Orchestration</span></span>

- <span data-ttu-id="e26c4-185">**Azure Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-185">**Azure Data Factory**.</span></span> <span data-ttu-id="e26c4-186">È possibile usare le pipeline di Azure Data Factory per definire una sequenza di attività pianificate per finestre temporali ricorrenti.</span><span class="sxs-lookup"><span data-stu-id="e26c4-186">Azure Data Factory pipelines can be used to define a sequence of activities, scheduled for recurring temporal windows.</span></span> <span data-ttu-id="e26c4-187">Queste attività possono avviare operazioni di copia dei dati, nonché processi Hive, Pig, MapReduce o Spark in cluster HDInsight su richiesta. Possono anche avviare processi di U-SQL in Azure Data Lake Analytics e stored procedure in Azure SQL Data Warehouse o nel database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="e26c4-187">These activities can initiate data copy operations as well as Hive, Pig, MapReduce, or Spark jobs in on-demand HDInsight clusters; U-SQL jobs in Azure Date Lake Analytics; and stored procedures in Azure SQL Data Warehouse or Azure SQL Database.</span></span>
- <span data-ttu-id="e26c4-188">**Oozie** e **Sqoop**.</span><span class="sxs-lookup"><span data-stu-id="e26c4-188">**Oozie** and **Sqoop**.</span></span> <span data-ttu-id="e26c4-189">Oozie è un motore di automazione dei processi per l'ecosistema Apache Hadoop e può essere usato per avviare operazioni di copia dei dati, nonché processi Hive, Pig e MapReduce per elaborare i dati e processi Sqoop per copiare i dati tra HDFS e i database SQL.</span><span class="sxs-lookup"><span data-stu-id="e26c4-189">Oozie is a job automation engine for the Apache Hadoop ecosystem and can be used to initiate data copy operations as well as Hive, Pig, and MapReduce jobs to process data and Sqoop jobs to copy data between HDFS and SQL databases.</span></span>

<span data-ttu-id="e26c4-190">Per altre informazioni, vedere [Orchestrazione di pipeline](../technology-choices/pipeline-orchestration-data-movement.md)</span><span class="sxs-lookup"><span data-stu-id="e26c4-190">For more information, see [Pipeline orchestration](../technology-choices/pipeline-orchestration-data-movement.md)</span></span>
