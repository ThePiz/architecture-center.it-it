---
title: Stile di architettura per Big Data
description: Descrive i vantaggi, le problematiche e le procedure consigliate per le architetture per i Big Data in Azure
author: MikeWasson
ms.openlocfilehash: 4e8b58d5fa0f6a441d70e05ec7d6a0e668712563
ms.sourcegitcommit: b0482d49aab0526be386837702e7724c61232c60
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 11/14/2017
ms.locfileid: "24540890"
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="cd44b-103">Stile di architettura per Big Data</span><span class="sxs-lookup"><span data-stu-id="cd44b-103">Big data architecture style</span></span>

<span data-ttu-id="cd44b-104">Un'architettura per Big Data è progettata per gestire l'inserimento, l'elaborazione e l'analisi di dati troppo grandi o complessi per i sistemi di database tradizionali.</span><span class="sxs-lookup"><span data-stu-id="cd44b-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="cd44b-105">Le soluzioni per i Big Data implicano in genere uno o più dei seguenti tipi di carico di lavoro:</span><span class="sxs-lookup"><span data-stu-id="cd44b-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="cd44b-106">L'elaborazione batch di origini di Big Data inattivi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="cd44b-107">L'elaborazione in tempo reale di Big Data in movimento.</span><span class="sxs-lookup"><span data-stu-id="cd44b-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="cd44b-108">L'esplorazione interattiva di Big Data.</span><span class="sxs-lookup"><span data-stu-id="cd44b-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="cd44b-109">L'analisi predittiva e il Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="cd44b-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="cd44b-110">La maggior parte delle architetture per i Big Data include alcuni o tutti i seguenti componenti:</span><span class="sxs-lookup"><span data-stu-id="cd44b-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="cd44b-111">**Origini dati**: tutte le soluzioni per i Big Data iniziano con una o più origini dati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="cd44b-112">Tra gli esempi sono inclusi:</span><span class="sxs-lookup"><span data-stu-id="cd44b-112">Examples include:</span></span>

    - <span data-ttu-id="cd44b-113">Archivi dati di applicazioni, ad esempio database relazionali.</span><span class="sxs-lookup"><span data-stu-id="cd44b-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="cd44b-114">File statici generati dalle applicazioni, ad esempio file di log di server Web.</span><span class="sxs-lookup"><span data-stu-id="cd44b-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="cd44b-115">Origini dati in tempo reale, ad esempio dispositivi IoT.</span><span class="sxs-lookup"><span data-stu-id="cd44b-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="cd44b-116">**Archiviazione dei dati**: i dati per le operazioni di elaborazione batch vengono in genere archiviati in un archivio di file distribuito che può contenere volumi elevati di file di grandi dimensioni in vari formati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="cd44b-117">Questo tipo di archivio viene spesso chiamato *data lake*.</span><span class="sxs-lookup"><span data-stu-id="cd44b-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="cd44b-118">Alcune opzioni per l'implementazione di questo tipo di archiviazione sono Azure Data Lake Store o i contenitori BLOB in Archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="cd44b-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="cd44b-119">**Elaborazione batch**: i set di dati sono di grandi dimensioni e una soluzione per Big Data deve spesso elaborare i file di dati mediante processi batch con esecuzione prolungata per filtrare, aggregare e preparare in altro modo i dati per l'analisi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="cd44b-120">In genere questi processi prevedono la lettura dei file di origine, la relativa elaborazione e la scrittura dell'output in nuovi file.</span><span class="sxs-lookup"><span data-stu-id="cd44b-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="cd44b-121">Le opzioni includono l'esecuzione di processi U-SQL in Azure Data Lake Analytics, l'utilizzo di Hive, Pig o di processi MapReduce personalizzati in un cluster HDInsight Hadoop o l'utilizzo di programmi Java, Scala o Python in un cluster HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="cd44b-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="cd44b-122">**Inserimento di messaggi in tempo reale**: se la soluzione include origini in tempo reale, l'architettura deve includere un modo per acquisire e archiviare i messaggi in tempo reale per l'elaborazione del flusso.</span><span class="sxs-lookup"><span data-stu-id="cd44b-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="cd44b-123">Potrebbe trattarsi di un archivio dati semplice in cui i messaggi in ingresso vengono rilasciati in una cartella per l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="cd44b-124">Tuttavia, molte soluzioni richiedono che un archivio di inserimento dei messaggi funga da buffer per i messaggi e supporti l'elaborazione scale-out, il recapito affidabile e altri tipi di semantica di accodamento dei messaggi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="cd44b-125">Le opzioni includono Hub eventi di Azure, hub IoT di Azure e Kafka.</span><span class="sxs-lookup"><span data-stu-id="cd44b-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="cd44b-126">**Elaborazione del flusso**: dopo avere acquisito i messaggi in tempo reale, la soluzione deve elaborarli filtrando, aggregando e preparando in altro modo i dati per l'analisi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="cd44b-127">I dati del flusso elaborati vengono quindi scritti in un sink di output.</span><span class="sxs-lookup"><span data-stu-id="cd44b-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="cd44b-128">Analisi di flusso di Azure offre un servizio di elaborazione del flusso gestito basato su query SQL in esecuzione perenne che operano su flussi non associati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="cd44b-129">È possibile anche usare tecnologie di streaming open source di Apache, come Storm e Spark Streaming in un cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="cd44b-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="cd44b-130">**Archivio dati analitici**: numerose soluzioni per Big Data preparano i dati per l'analisi e quindi servono i dati elaborati in un formato strutturato su sui è possibile eseguire query con strumenti analitici.</span><span class="sxs-lookup"><span data-stu-id="cd44b-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="cd44b-131">L'archivio dati analitici usato per rispondere a queste query può essere un data warehouse relazionale in stile Kimball, come nella maggior parte delle soluzioni di business intelligence (BI) tradizionali.</span><span class="sxs-lookup"><span data-stu-id="cd44b-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="cd44b-132">In alternativa, i dati possono essere presentati tramite una tecnologia NoSQL a bassa latenza come HBase o un database Hive interattivo che fornisce un'astrazione di metadati sui file di dati nell'archivio dati distribuito.</span><span class="sxs-lookup"><span data-stu-id="cd44b-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="cd44b-133">Azure SQL Data Warehouse fornisce un servizio gestito per il data warehousing su larga scala basato su cloud.</span><span class="sxs-lookup"><span data-stu-id="cd44b-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="cd44b-134">HDInsight supporta Interactive Hive, HBase e Spark SQL, che possono anche essere usati per fornire dati per l'analisi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="cd44b-135">**Analisi e creazione di report**: l'obiettivo della maggior parte delle soluzioni per Big Data è fornire informazioni dettagliate sui dati tramite l'analisi e il reporting.</span><span class="sxs-lookup"><span data-stu-id="cd44b-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="cd44b-136">Per consentire agli utenti di analizzare i dati, l'architettura può includere un livello di modellazione dei dati, ad esempio un cubo OLAP multidimensionale o un modello di dati tabulari in Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cd44b-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="cd44b-137">Potrebbe inoltre supportare la business intelligence in modalità self-service, usando le tecnologie di modellazione e visualizzazione in Microsoft Power BI o Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="cd44b-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="cd44b-138">L'analisi e il reporting possono anche assumere la forma di esplorazione interattiva dei dati da parte di data scientist o analisti di dati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="cd44b-139">Per questi scenari, molti servizi di Azure supportano notebook analitici come Jupyter, consentendo a questi utenti di sfruttare le proprie competenze esistenti con Python o R. Per l'esplorazione di dati su larga scala, è possibile usare Microsoft R Server, sia autonomo che con Spark.</span><span class="sxs-lookup"><span data-stu-id="cd44b-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="cd44b-140">**Orchestrazione**: la maggior parte delle soluzioni per Big Data consiste in operazioni ripetute di elaborazione dei dati, incapsulate in flussi di lavoro, che trasformano i dati di origine, spostano i dati tra più origini e sink, caricano i dati elaborati in un archivio dati analitico o li inseriscono direttamente in un report o i un dashboard.</span><span class="sxs-lookup"><span data-stu-id="cd44b-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="cd44b-141">Per automatizzare questi flussi di lavoro, è possibile usare una tecnologia di orchestrazione come Azure Data Factory o Apache Oozie e Sqoop.</span><span class="sxs-lookup"><span data-stu-id="cd44b-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="cd44b-142">Azure include molti servizi che possono essere usati in un'architettura per Big Data.</span><span class="sxs-lookup"><span data-stu-id="cd44b-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="cd44b-143">Si dividono approssimativamente in due categorie:</span><span class="sxs-lookup"><span data-stu-id="cd44b-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="cd44b-144">Servizi gestiti, tra cui Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Analisi di flusso di Azure, Azure Event Hub, Hub IoT e Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="cd44b-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="cd44b-145">Tecnologie open source basate sulla piattaforma Apache Hadoop, tra cui Hadoop Distributed File System, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop e Kafka.</span><span class="sxs-lookup"><span data-stu-id="cd44b-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="cd44b-146">Queste tecnologie sono disponibili in Azure nel servizio Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="cd44b-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="cd44b-147">Queste opzioni non si escludono a vicenda e molte soluzioni combinano le tecnologie open source con i servizi Azure.</span><span class="sxs-lookup"><span data-stu-id="cd44b-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="cd44b-148">Quando usare questa architettura</span><span class="sxs-lookup"><span data-stu-id="cd44b-148">When to use this architecture</span></span>

<span data-ttu-id="cd44b-149">Prendere in considerazione questo stile di architettura quando è necessario:</span><span class="sxs-lookup"><span data-stu-id="cd44b-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="cd44b-150">Archiviare ed elaborare i dati in volumi troppo grandi per un database tradizionale.</span><span class="sxs-lookup"><span data-stu-id="cd44b-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="cd44b-151">Trasformare i dati non strutturati per consentire l'analisi e il reporting.</span><span class="sxs-lookup"><span data-stu-id="cd44b-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="cd44b-152">Acquisire, elaborare e analizzare i flussi di dati non associati in tempo reale o con una latenza bassa.</span><span class="sxs-lookup"><span data-stu-id="cd44b-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="cd44b-153">Usare Microsoft Azure Machine Learning o Servizi cognitivi Microsoft.</span><span class="sxs-lookup"><span data-stu-id="cd44b-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="cd44b-154">Vantaggi</span><span class="sxs-lookup"><span data-stu-id="cd44b-154">Benefits</span></span>

- <span data-ttu-id="cd44b-155">**Scelte tecnologiche**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-155">**Technology choices**.</span></span> <span data-ttu-id="cd44b-156">È possibile combinare i servizi gestiti Azure e le tecnologie Apache nei cluster HDInsight per sfruttare appieno le competenze o gli investimenti tecnologici esistenti.</span><span class="sxs-lookup"><span data-stu-id="cd44b-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="cd44b-157">**Prestazioni tramite il parallelismo**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-157">**Performance through parallelism**.</span></span> <span data-ttu-id="cd44b-158">Le soluzioni per i Big Data sfruttano i vantaggi del parallelismo, consentendo soluzioni ad alte prestazioni che si adattano a grandi volumi di dati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="cd44b-159">**Scalabilità elastica**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-159">**Elastic scale**.</span></span> <span data-ttu-id="cd44b-160">Tutti i componenti dell'architettura per Big Data supportano il provisioning scale-out che consente di adattare la soluzione a carichi di lavoro piccoli o grandi e pagare solo per le risorse usate.</span><span class="sxs-lookup"><span data-stu-id="cd44b-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="cd44b-161">**Interoperabilità con soluzioni esistenti**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="cd44b-162">I componenti dell'architettura per Big Data vengono usati anche per l'elaborazione IoT e le soluzioni di BI enterprise, consentendo di creare una soluzione integrata tra i carichi di lavoro di dati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="cd44b-163">Problematiche</span><span class="sxs-lookup"><span data-stu-id="cd44b-163">Challenges</span></span>

- <span data-ttu-id="cd44b-164">**Complessità**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-164">**Complexity**.</span></span> <span data-ttu-id="cd44b-165">Le soluzioni per Big Data possono essere estremamente complesse, con numerosi componenti per gestire l'inserimento di dati da più origini dati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="cd44b-166">Può essere difficile compilare, testare e risolvere i problemi relativi ai processi con Big Data.</span><span class="sxs-lookup"><span data-stu-id="cd44b-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="cd44b-167">Inoltre potrebbe esistere un numero elevato di impostazioni di configurazione tra più sistemi che devono essere usate per ottimizzare le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="cd44b-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="cd44b-168">**Competenze**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-168">**Skillset**.</span></span> <span data-ttu-id="cd44b-169">Molte tecnologie per Big Data sono altamente specializzate e usano framework e linguaggi che non sono tipici di architetture applicative più generali.</span><span class="sxs-lookup"><span data-stu-id="cd44b-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="cd44b-170">D'altra parte, le tecnologie per i Big Data stanno evolvendo nuove API basate su altri linguaggi consolidati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="cd44b-171">Ad esempio, il linguaggio U-SQL in Azure Data Lake Analytics si basa su una combinazione di Transact-SQL e C#.</span><span class="sxs-lookup"><span data-stu-id="cd44b-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="cd44b-172">Analogamente, le API basate su SQL sono disponibili per Hive, HBase e Spark.</span><span class="sxs-lookup"><span data-stu-id="cd44b-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="cd44b-173">**Maturità tecnologica**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-173">**Technology maturity**.</span></span> <span data-ttu-id="cd44b-174">Molte tecnologie usate per i Big Data sono in continua evoluzione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="cd44b-175">Mentre le tecnologie Hadoop principali come Hive e Pig sono ormai stabili, le tecnologie emergenti come Spark introducono numerosi cambiamenti e miglioramenti in ogni nuova versione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="cd44b-176">I servizi gestiti come Azure Data Lake Analytics e Azure Data Factory sono relativamente recenti rispetto ad altri servizi Azure e probabilmente si evolveranno ancora nel tempo.</span><span class="sxs-lookup"><span data-stu-id="cd44b-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="cd44b-177">**Sicurezza**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-177">**Security**.</span></span> <span data-ttu-id="cd44b-178">Le soluzioni per Big Data di solito si basano sull'archiviazione di tutti i dati statici in un data lake centralizzato.</span><span class="sxs-lookup"><span data-stu-id="cd44b-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="cd44b-179">Garantire l'accesso sicuro a questi dati può essere difficile, specialmente quando i dati devono essere inseriti e usati da più applicazioni e piattaforme.</span><span class="sxs-lookup"><span data-stu-id="cd44b-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="cd44b-180">Procedure consigliate</span><span class="sxs-lookup"><span data-stu-id="cd44b-180">Best practices</span></span>

- <span data-ttu-id="cd44b-181">**Sfruttare il parallelismo**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-181">**Leverage parallelism**.</span></span> <span data-ttu-id="cd44b-182">La maggior parte delle tecnologie di elaborazione per i Big Data distribuisce il carico di lavoro su più unità di elaborazione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="cd44b-183">È necessario che i file di dati statici vengano creati e archiviati in un formato divisibile.</span><span class="sxs-lookup"><span data-stu-id="cd44b-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="cd44b-184">I file system distribuiti come HDFS possono ottimizzare le prestazioni in lettura e in scrittura e l'elaborazione effettiva viene eseguita da più nodi del cluster in parallelo, riducendo i tempi complessivi del processo.</span><span class="sxs-lookup"><span data-stu-id="cd44b-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="cd44b-185">**Dati di partizione**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-185">**Partition data**.</span></span> <span data-ttu-id="cd44b-186">L'elaborazione batch di solito si verifica in base a una pianificazione ricorrente, ad esempio, settimanale o mensile.</span><span class="sxs-lookup"><span data-stu-id="cd44b-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="cd44b-187">Partizionare i file di dati e le strutture di dati come tabelle, in base a periodi temporali corrispondenti alla pianificazione di elaborazione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="cd44b-188">Ciò semplifica l'inserimento dei dati e la pianificazione dei processi e quindi la risoluzione dei problemi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="cd44b-189">Inoltre, le tabelle delle partizioni usate nelle query Hive, U-SQL o SQL possono migliorare significativamente le prestazioni delle query.</span><span class="sxs-lookup"><span data-stu-id="cd44b-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="cd44b-190">**Applicare la semantica dello schema in lettura**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="cd44b-191">L'utilizzo di un data lake consente di combinare l'archiviazione per i file in più formati, siano essi strutturati, semi-strutturati o non strutturati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="cd44b-192">Usare la semantica dello *schema in lettura* che applica uno schema sui dati in fase di elaborazione e non in fase di archiviazione.</span><span class="sxs-lookup"><span data-stu-id="cd44b-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="cd44b-193">In questo modo aumenta la flessibilità della soluzione e si prevengono colli di bottiglia durante l'inserimento dei dati a causa della convalida dei dati e del controllo del tipo.</span><span class="sxs-lookup"><span data-stu-id="cd44b-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="cd44b-194">**Elaborare i dati sul posto**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-194">**Process data in-place**.</span></span> <span data-ttu-id="cd44b-195">Le soluzioni tradizionali di business intelligence usano spesso un processo di estrazione, trasformazione e (ETL) per trasferire i dati in un data warehouse.</span><span class="sxs-lookup"><span data-stu-id="cd44b-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="cd44b-196">Con volumi di dati di dimensioni maggiori e una gamma di formati più ampia, in genere le soluzioni per Big Data usano variazioni del processo ETL, ad esempio trasformazione, estrazione e caricamento (TEL).</span><span class="sxs-lookup"><span data-stu-id="cd44b-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="cd44b-197">Con questo approccio i dati vengono elaborati all'interno dell'archivio dati distribuito, trasformandoli nella struttura richiesta, prima di spostare i dati trasformati in un archivio dati analitici.</span><span class="sxs-lookup"><span data-stu-id="cd44b-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="cd44b-198">**Bilanciare il costo unitario e il costo per l'utilizzo**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="cd44b-199">Per i processi di elaborazione batch, è importante considerare due fattori: il costo unitario dei nodi di calcolo e il costo al minuto dell'utilizzo di tali nodi per completare il processo.</span><span class="sxs-lookup"><span data-stu-id="cd44b-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="cd44b-200">Ad esempio, un processo batch può richiedere otto ore con quattro nodi cluster.</span><span class="sxs-lookup"><span data-stu-id="cd44b-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="cd44b-201">Tuttavia, potrebbe risultare che il processo usi tutti e quattro i nodi solo durante le prime due ore e, successivamente, siano necessari solo due nodi.</span><span class="sxs-lookup"><span data-stu-id="cd44b-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="cd44b-202">In tal caso, eseguire l'intero lavoro su due nodi aumenterebbe il tempo totale del lavoro, ma non lo raddoppierebbe e quindi il costo totale sarebbe inferiore.</span><span class="sxs-lookup"><span data-stu-id="cd44b-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="cd44b-203">In alcuni scenari aziendali, un tempo di elaborazione più lungo può essere preferibile al costo più elevato dell'utilizzo di risorse cluster sottoutilizzate.</span><span class="sxs-lookup"><span data-stu-id="cd44b-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="cd44b-204">**Separare le risorse del cluster**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-204">**Separate cluster resources**.</span></span> <span data-ttu-id="cd44b-205">Quando si distribuiscono cluster HDInsight, di solito si ottengono prestazioni migliori mediante il provisioning di risorse cluster separate per ogni tipo di carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="cd44b-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="cd44b-206">Ad esempio, sebbene i cluster Spark includano Hive, se è necessario eseguire un'elaborazione estesa con Hive e Spark, è consigliabile considerare l'implementazione di cluster Spark e Hadoop dedicati separati.</span><span class="sxs-lookup"><span data-stu-id="cd44b-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="cd44b-207">Analogamente, se si usa HBase e Storm per l'elaborazione di flussi a bassa latenza e Hive per l'elaborazione batch, considerare l'utilizzo di cluster separati per Storm, HBase e Hadoop.</span><span class="sxs-lookup"><span data-stu-id="cd44b-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="cd44b-208">**Orchestrare l'inserimento di dati**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="cd44b-209">In alcuni casi, le applicazioni aziendali esistenti possono scrivere file di dati per l'elaborazione batch direttamente nei contenitori BLOB di archiviazione di Azure, dove possono essere usati da HDInsight o Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="cd44b-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="cd44b-210">Tuttavia sarà spesso necessario orchestrare l'inserimento di dati da origini dati locali o esterne nel data lake.</span><span class="sxs-lookup"><span data-stu-id="cd44b-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="cd44b-211">Usare un flusso di lavoro o una pipeline di orchestrazione, ad esempio quelli supportati da Azure Data Factory oppure Oozie, per ottenere questo risultato in modo prevedibile e gestibile a livello centrale.</span><span class="sxs-lookup"><span data-stu-id="cd44b-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="cd44b-212">**Eseguire lo scrubbing dei dati sensibili in anticipo**.</span><span class="sxs-lookup"><span data-stu-id="cd44b-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="cd44b-213">Il flusso di lavoro per l'inserimento dei dati dovrebbe eseguire lo scrubbing dei dati sensibili all'inizio del processo, per evitare di archiviarli nel data lake.</span><span class="sxs-lookup"><span data-stu-id="cd44b-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>
