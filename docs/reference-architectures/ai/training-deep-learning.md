---
title: Training distribuito di modelli di Deep Learning in Azure
description: Questa architettura di riferimento mostra come svolgere un training distribuito dei modelli di Deep Learning tra cluster di VM abilitate per GPU usando Azure Batch per intelligenza artificiale.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307784"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="8ada6-103">Training distribuito di modelli di Deep Learning in Azure</span><span class="sxs-lookup"><span data-stu-id="8ada6-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="8ada6-104">Questa architettura di riferimento mostra come svolgere un training distribuito dei modelli di Deep Learning tra cluster di VM abilitate per GPU.</span><span class="sxs-lookup"><span data-stu-id="8ada6-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="8ada6-105">Lo scenario riguarda la classificazione di immagini, ma la soluzione può essere generalizzata per altri scenari di Deep Learning, come la segmentazione e il rilevamento di oggetti.</span><span class="sxs-lookup"><span data-stu-id="8ada6-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="8ada6-106">Un'implementazione di riferimento per questa architettura è disponibile in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ada6-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architettura per Deep Learning distribuito][0]

<span data-ttu-id="8ada6-108">**Scenario**: la classificazione di immagini è una tecnica ampiamente diffusa nel campo della visione artificiale, spesso applicata tramite training di una rete neurale convoluzionale (CNN, Convolutional Neural Network).</span><span class="sxs-lookup"><span data-stu-id="8ada6-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="8ada6-109">Per modelli particolarmente grandi con set di dati di grandi dimensioni, il processo di training può richiedere diverse settimane o anche mesi con una singola GPU.</span><span class="sxs-lookup"><span data-stu-id="8ada6-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="8ada6-110">In alcune situazioni i modelli sono talmente grandi che non è possibile inserire batch di dimensioni ragionevoli nella GPU.</span><span class="sxs-lookup"><span data-stu-id="8ada6-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="8ada6-111">Usando il training distribuito in queste situazioni è possibile abbreviare i tempi.</span><span class="sxs-lookup"><span data-stu-id="8ada6-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="8ada6-112">In questo scenario specifico viene eseguito il training di un [modello di CNN ResNet50][resnet] usando [Horovod][horovod] sul [set di dati Imagenet][imagenet] e su dati sintetici.</span><span class="sxs-lookup"><span data-stu-id="8ada6-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="8ada6-113">L'implementazione di riferimento mostra come realizzare questa attività con tre framework di Deep Learning tra i più diffusi: TensorFlow, Keras e PyTorch.</span><span class="sxs-lookup"><span data-stu-id="8ada6-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="8ada6-114">Il training di un modello di Deep Learning in modalità distribuita può essere eseguito in vari modi, tra cui con approcci basati su parallelismo dei dati e parallelismo dei modelli e con aggiornamenti sincroni o asincroni.</span><span class="sxs-lookup"><span data-stu-id="8ada6-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="8ada6-115">Attualmente lo scenario più comune è il parallelismo dei dati con aggiornamenti sincroni.</span><span class="sxs-lookup"><span data-stu-id="8ada6-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="8ada6-116">Si tratta dell'approccio più facile da implementare e si rivela sufficiente per la maggior parte dei casi d'uso.</span><span class="sxs-lookup"><span data-stu-id="8ada6-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="8ada6-117">Nel training distribuito con parallelismo dei dati e aggiornamenti sincroni, il modello viene replicato tra *n* dispositivi hardware.</span><span class="sxs-lookup"><span data-stu-id="8ada6-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="8ada6-118">Un mini-batch di campioni di training viene diviso in *n* micro-batch.</span><span class="sxs-lookup"><span data-stu-id="8ada6-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="8ada6-119">Ogni dispositivo esegue i passaggi in avanti e a ritroso per un micro-batch.</span><span class="sxs-lookup"><span data-stu-id="8ada6-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="8ada6-120">Quando un dispositivo completa il processo, condivide gli aggiornamenti con gli altri dispositivi.</span><span class="sxs-lookup"><span data-stu-id="8ada6-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="8ada6-121">Questi valori vengono usati per calcolare i pesi aggiornati dell'intero mini-batch, che vengono quindi sincronizzati tra i modelli.</span><span class="sxs-lookup"><span data-stu-id="8ada6-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="8ada6-122">Questo scenario viene trattato nel repository [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ada6-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Training distribuito con parallelismo dei dati][1]

<span data-ttu-id="8ada6-124">Questa architettura può essere usata anche per il parallelismo dei modelli e gli aggiornamenti asincroni.</span><span class="sxs-lookup"><span data-stu-id="8ada6-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="8ada6-125">Nel training distribuito con parallelismo dei modelli, il modello viene diviso tra *n* dispositivi hardware, ognuno dei quali ne mantiene una parte.</span><span class="sxs-lookup"><span data-stu-id="8ada6-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="8ada6-126">Nell'implementazione più semplice, ogni dispositivo può mantenere un livello della rete e le informazioni vengono passate tra i dispositivi durante il passaggio in avanti e a ritroso.</span><span class="sxs-lookup"><span data-stu-id="8ada6-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="8ada6-127">Il training delle reti neurali più grandi può essere eseguito in questo modo, ma a discapito delle prestazioni, perché i dispositivi rimangono costantemente in attesa che gli altri completino il passaggio in avanti o a ritroso.</span><span class="sxs-lookup"><span data-stu-id="8ada6-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="8ada6-128">Con alcune tecniche avanzate è possibile provare ad alleviare parzialmente questo problema usando gradienti sintetici.</span><span class="sxs-lookup"><span data-stu-id="8ada6-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="8ada6-129">I passaggi del training sono i seguenti:</span><span class="sxs-lookup"><span data-stu-id="8ada6-129">The steps for training are:</span></span>

1. <span data-ttu-id="8ada6-130">Creare script che verranno eseguiti nel cluster per il training del modello, quindi trasferirli nella risorsa di archiviazione file.</span><span class="sxs-lookup"><span data-stu-id="8ada6-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="8ada6-131">Scrivere i dati nell'archiviazione BLOB.</span><span class="sxs-lookup"><span data-stu-id="8ada6-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="8ada6-132">Creare un file server di Batch per intelligenza artificiale e scaricarvi i file dall'archiviazione BLOB.</span><span class="sxs-lookup"><span data-stu-id="8ada6-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="8ada6-133">Creare i contenitori Docker per ogni framework di Deep Learning e trasferirli in un registro contenitori (hub Docker).</span><span class="sxs-lookup"><span data-stu-id="8ada6-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="8ada6-134">Creare un pool di Batch per intelligenza artificiale che monta anche il relativo file server.</span><span class="sxs-lookup"><span data-stu-id="8ada6-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="8ada6-135">Inviare i processi.</span><span class="sxs-lookup"><span data-stu-id="8ada6-135">Submit jobs.</span></span> <span data-ttu-id="8ada6-136">Ogni processo esegue il pull nell'immagine Docker e negli script appropriati.</span><span class="sxs-lookup"><span data-stu-id="8ada6-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="8ada6-137">Una volta completato il processo, scrivere tutti i risultati nell'archiviazione file.</span><span class="sxs-lookup"><span data-stu-id="8ada6-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="8ada6-138">Architettura</span><span class="sxs-lookup"><span data-stu-id="8ada6-138">Architecture</span></span>

<span data-ttu-id="8ada6-139">L'architettura è costituita dai componenti seguenti.</span><span class="sxs-lookup"><span data-stu-id="8ada6-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="8ada6-140">**[Azure Batch per intelligenza artificiale][batch-ai]**, che ricopre un ruolo centrale in questa architettura, ridimensionando le risorse secondo necessità.</span><span class="sxs-lookup"><span data-stu-id="8ada6-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="8ada6-141">Batch per intelligenza artificiale è un servizio che agevola il provisioning e la gestione di cluster di VM, la pianificazione dei processi, la raccolta dei risultati, la scalabilità delle risorse, la gestione degli errori e la creazione di risorse di archiviazione appropriate.</span><span class="sxs-lookup"><span data-stu-id="8ada6-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="8ada6-142">Supporta VM abilitate per GPU per i carichi di lavoro di Deep Learning.</span><span class="sxs-lookup"><span data-stu-id="8ada6-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="8ada6-143">Per Batch per intelligenza artificiale sono disponibili un SKD Python e un'interfaccia della riga di comando.</span><span class="sxs-lookup"><span data-stu-id="8ada6-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="8ada6-144">Il servizio Azure Batch per intelligenza artificiale verrà ritirato a marzo 2019 e le relative funzionalità di training e assegnazione dei punteggi su larga scala sono ora disponibili nel [servizio Azure Machine Learning][amls].</span><span class="sxs-lookup"><span data-stu-id="8ada6-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="8ada6-145">Questa architettura di riferimento verrà presto aggiornata per l'uso di Machine Learning, che offre una destinazione di calcolo gestita, l'[ambiente di calcolo di Machine Learning di Azure][aml-compute] per il training, la distribuzione e l'assegnazione di punteggi dei modelli di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="8ada6-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="8ada6-146">**[Archiviazione BLOB][azure-blob]**, per la gestione temporanea dei dati.</span><span class="sxs-lookup"><span data-stu-id="8ada6-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="8ada6-147">Questi dati vengono scaricati in un file server di Batch per intelligenza artificiale durante il training.</span><span class="sxs-lookup"><span data-stu-id="8ada6-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="8ada6-148">**[File di Azure][files]**, per archiviare script, log e risultati finali del training.</span><span class="sxs-lookup"><span data-stu-id="8ada6-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="8ada6-149">L'archiviazione file è particolarmente indicata per archiviare log e script, ma non offre le stesse prestazioni di Archiviazione BLOB, quindi non è consigliabile usarla per attività a uso intensivo di dati.</span><span class="sxs-lookup"><span data-stu-id="8ada6-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="8ada6-150">**[File server di Batch per intelligenza artificiale][batch-ai-files]**, una condivisione NFS a nodo singolo usata in questa architettura per archiviare i dati di training.</span><span class="sxs-lookup"><span data-stu-id="8ada6-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="8ada6-151">Batch per intelligenza artificiale crea una condivisione NFS e la monta sul cluster.</span><span class="sxs-lookup"><span data-stu-id="8ada6-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="8ada6-152">I file server di Batch per intelligenza artificiale rappresentano la scelta consigliata per inviare i dati al cluster con la velocità effettiva necessaria.</span><span class="sxs-lookup"><span data-stu-id="8ada6-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="8ada6-153">**[Hub Docker][docker]**, per archiviare l'immagine Docker usata da Batch per intelligenza artificiale per eseguire il training.</span><span class="sxs-lookup"><span data-stu-id="8ada6-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="8ada6-154">L'hub Docker è stato scelto per questa architettura perché è facile da usare ed è il repository di immagini predefinito per gli utenti di Docker.</span><span class="sxs-lookup"><span data-stu-id="8ada6-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="8ada6-155">È possibile usare anche il [Registro contenitori di Azure][acr].</span><span class="sxs-lookup"><span data-stu-id="8ada6-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="8ada6-156">Considerazioni sulle prestazioni</span><span class="sxs-lookup"><span data-stu-id="8ada6-156">Performance considerations</span></span>

<span data-ttu-id="8ada6-157">Azure offre quattro [tipi di VM abilitate per GPU][gpu] indicate per il training dei modelli di Deep Learning.</span><span class="sxs-lookup"><span data-stu-id="8ada6-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="8ada6-158">Sono disponibili in una gamma di fasce di prezzo e livelli di velocità, come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="8ada6-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="8ada6-159">**Serie di VM di Azure**</span><span class="sxs-lookup"><span data-stu-id="8ada6-159">**Azure VM series**</span></span> | <span data-ttu-id="8ada6-160">**GPU NVIDIA**</span><span class="sxs-lookup"><span data-stu-id="8ada6-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="8ada6-161">NC</span><span class="sxs-lookup"><span data-stu-id="8ada6-161">NC</span></span>                  | <span data-ttu-id="8ada6-162">K80</span><span class="sxs-lookup"><span data-stu-id="8ada6-162">K80</span></span>            |
| <span data-ttu-id="8ada6-163">ND</span><span class="sxs-lookup"><span data-stu-id="8ada6-163">ND</span></span>                  | <span data-ttu-id="8ada6-164">P40</span><span class="sxs-lookup"><span data-stu-id="8ada6-164">P40</span></span>            |
| <span data-ttu-id="8ada6-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="8ada6-165">NCv2</span></span>                | <span data-ttu-id="8ada6-166">P100</span><span class="sxs-lookup"><span data-stu-id="8ada6-166">P100</span></span>           |
| <span data-ttu-id="8ada6-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="8ada6-167">NCv3</span></span>                | <span data-ttu-id="8ada6-168">V100</span><span class="sxs-lookup"><span data-stu-id="8ada6-168">V100</span></span>           |

<span data-ttu-id="8ada6-169">Per il training è consigliabile adottare la scalabilità verticale prima di quella orizzontale. Provare ad esempio a usare una singola VM V100 prima di un cluster di K80.</span><span class="sxs-lookup"><span data-stu-id="8ada6-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="8ada6-170">Il grafico seguente illustra le differenze di prestazioni dei vari tipi di GPU in base ai [test di benchmarking][benchmark] eseguiti usando TensorFlow e Horovod con Batch per intelligenza artificiale.</span><span class="sxs-lookup"><span data-stu-id="8ada6-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="8ada6-171">Il grafico mostra la velocità effettiva di 32 cluster di GPU di vari modelli, con tipi di GPU e versioni di MPI differenti.</span><span class="sxs-lookup"><span data-stu-id="8ada6-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="8ada6-172">I modelli sono stati implementati in TensorFlow 1.9</span><span class="sxs-lookup"><span data-stu-id="8ada6-172">Models were implemented in TensorFlow 1.9</span></span>

![Risultati della velocità effettiva per i modelli TensorFlow con cluster di GPU][2]

<span data-ttu-id="8ada6-174">Ogni serie di VM indicata nella tabella precedente include una configurazione con InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="8ada6-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="8ada6-175">Usare le configurazioni di InfiniBand quando si esegue il training distribuito per velocizzare la comunicazione tra i nodi.</span><span class="sxs-lookup"><span data-stu-id="8ada6-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="8ada6-176">InfiniBand offre anche una maggiore efficienza della scalabilità del training per i framework che possono trarne vantaggio.</span><span class="sxs-lookup"><span data-stu-id="8ada6-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="8ada6-177">Per i dettagli, vedere il [confronto dei benchmark][benchmark] di InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="8ada6-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="8ada6-178">Anche se Batch per intelligenza artificiale può montare l'archiviazione BLOB usando l'adattatore [blobfuse][blobfuse], questa scelta non è consigliata per il training distribuito, perché le prestazioni non sono sufficienti per gestire la necessaria velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="8ada6-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="8ada6-179">Spostare invece i dati in un file server di Batch per intelligenza artificiale, come illustrato nel diagramma dell'architettura.</span><span class="sxs-lookup"><span data-stu-id="8ada6-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="8ada6-180">Considerazioni sulla scalabilità</span><span class="sxs-lookup"><span data-stu-id="8ada6-180">Scalability considerations</span></span>

<span data-ttu-id="8ada6-181">L'efficienza della scalabilità del training distribuito è sempre inferiore al 100% a causa del sovraccarico di rete. La sincronizzazione dell'intero modello tra dispositivi diventa infatti un collo di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="8ada6-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="8ada6-182">Pertanto, il training distribuito è più indicato per i modelli più grandi, per cui non è possibile usare dimensioni ragionevoli dei batch in una singola GPU, oppure per problemi non risolvibili distribuendo il modello in un semplice modo parallelo.</span><span class="sxs-lookup"><span data-stu-id="8ada6-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="8ada6-183">Il training distribuito non è consigliato per l'esecuzione di ricerche di iperparametri.</span><span class="sxs-lookup"><span data-stu-id="8ada6-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="8ada6-184">L'efficienza della scalabilità influisce sulle prestazioni e riduce l'efficacia di un approccio distribuito rispetto al training di più configurazioni di modelli separatamente.</span><span class="sxs-lookup"><span data-stu-id="8ada6-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="8ada6-185">Uno dei modi per aumentare l'efficienza della scalabilità consiste nell'aumentare le dimensioni dei batch.</span><span class="sxs-lookup"><span data-stu-id="8ada6-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="8ada6-186">In questo caso è tuttavia necessario prestare una particolare attenzione, perché l'aumento delle dimensioni dei batch senza una corrispondente regolazione degli altri parametri può incidere negativamente sulle prestazioni finali del modello.</span><span class="sxs-lookup"><span data-stu-id="8ada6-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="8ada6-187">Considerazioni sulle risorse di archiviazione</span><span class="sxs-lookup"><span data-stu-id="8ada6-187">Storage considerations</span></span>

<span data-ttu-id="8ada6-188">Quando si esegue il training dei modelli di Deep Learning, un aspetto spesso sottovalutato riguarda la risorsa in cui vengono archiviati i file.</span><span class="sxs-lookup"><span data-stu-id="8ada6-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="8ada6-189">Se la risorsa di archiviazione è troppo lenta per tenere il passo con i requisiti delle GPU, le prestazioni del training possono diminuire.</span><span class="sxs-lookup"><span data-stu-id="8ada6-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="8ada6-190">Batch per intelligenza artificiale supporta molte soluzioni di archiviazione.</span><span class="sxs-lookup"><span data-stu-id="8ada6-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="8ada6-191">Questa architettura usa il file server di Batch per intelligenza artificiale, perché offre il miglior compromesso tra facilità d'uso e prestazioni.</span><span class="sxs-lookup"><span data-stu-id="8ada6-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="8ada6-192">Per prestazioni ottimali, caricare i dati in locale.</span><span class="sxs-lookup"><span data-stu-id="8ada6-192">For best performance, load the data locally.</span></span> <span data-ttu-id="8ada6-193">Questo approccio può tuttavia rivelarsi poco efficiente, perché tutti i nodi devono scaricare i file da Archiviazione BLOB e con il set di dati ImageNet la procedura può richiedere diverse ore.</span><span class="sxs-lookup"><span data-stu-id="8ada6-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="8ada6-194">La soluzione [Archiviazione BLOB di Azure Premium][blob] (anteprima pubblica limitata) è un'altra opzione valida da considerare.</span><span class="sxs-lookup"><span data-stu-id="8ada6-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="8ada6-195">Non montare le risorse di archiviazione BLOB e archiviazione file come archivi dati per il training distribuito.</span><span class="sxs-lookup"><span data-stu-id="8ada6-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="8ada6-196">Sono infatti troppo lente e pregiudicheranno le prestazioni del training.</span><span class="sxs-lookup"><span data-stu-id="8ada6-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="8ada6-197">Considerazioni relative alla sicurezza</span><span class="sxs-lookup"><span data-stu-id="8ada6-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="8ada6-198">Limitare l'accesso ad Archiviazione BLOB di Azure</span><span class="sxs-lookup"><span data-stu-id="8ada6-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="8ada6-199">Questa architettura usa [chiavi dell'account di archiviazione][security-guide] per l'accesso all'archiviazione BLOB.</span><span class="sxs-lookup"><span data-stu-id="8ada6-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="8ada6-200">Per livelli maggiori di controllo e protezione, provare a usare una firma di accesso condiviso (SAS),</span><span class="sxs-lookup"><span data-stu-id="8ada6-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="8ada6-201">che consente l'accesso limitato agli oggetti archiviati nella risorsa, senza la necessità di codificare le chiavi dell'account o salvarle in testo non crittografato.</span><span class="sxs-lookup"><span data-stu-id="8ada6-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="8ada6-202">L'uso di una firma di accesso condiviso assicura anche una governance appropriata per l'account di archiviazione e che l'accesso venga concesso solo alle persone previste.</span><span class="sxs-lookup"><span data-stu-id="8ada6-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="8ada6-203">Per gli scenari con più dati sensibili, assicurarsi che tutte le chiavi di archiviazione siano protette, poiché concedono un accesso completo a tutti i dati di input e output dal carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="8ada6-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="8ada6-204">Crittografare i dati inattivi e in movimento</span><span class="sxs-lookup"><span data-stu-id="8ada6-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="8ada6-205">Negli scenari in cui si usano dati sensibili, crittografare i dati inattivi, ossia quelli presenti nella risorsa di archiviazione.</span><span class="sxs-lookup"><span data-stu-id="8ada6-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="8ada6-206">Ogni volta che i dati vengono spostati da una posizione a quella successiva, usare SSL per proteggerne il trasferimento.</span><span class="sxs-lookup"><span data-stu-id="8ada6-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="8ada6-207">Per altre informazioni, vedere la [Guida alla sicurezza di Archiviazione di Azure][security-guide].</span><span class="sxs-lookup"><span data-stu-id="8ada6-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="8ada6-208">Proteggere i dati in una rete virtuale</span><span class="sxs-lookup"><span data-stu-id="8ada6-208">Secure data in a virtual network</span></span>

<span data-ttu-id="8ada6-209">Per le distribuzioni di produzione, è consigliabile distribuire il cluster di Batch per intelligenza artificiale in una subnet di una rete virtuale specificata.</span><span class="sxs-lookup"><span data-stu-id="8ada6-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="8ada6-210">In questo modo i nodi di calcolo nel cluster possono comunicare in modo sicuro con altre macchine virtuali o con una rete locale.</span><span class="sxs-lookup"><span data-stu-id="8ada6-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="8ada6-211">È anche possibile usare [endpoint di servizio][endpoints] con archiviazione BLOB per concedere l'accesso da una rete virtuale oppure usare una condivisione NFS a nodo singolo all'interno della rete virtuale con Batch per intelligenza artificiale.</span><span class="sxs-lookup"><span data-stu-id="8ada6-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="8ada6-212">Considerazioni sul monitoraggio</span><span class="sxs-lookup"><span data-stu-id="8ada6-212">Monitoring considerations</span></span>

<span data-ttu-id="8ada6-213">Quando si esegue un processo, è importante monitorare lo stato di avanzamento e assicurarsi che tutto funzioni come previsto.</span><span class="sxs-lookup"><span data-stu-id="8ada6-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="8ada6-214">Tuttavia, il monitoraggio in un cluster di nodi attivi può rivelarsi un problema.</span><span class="sxs-lookup"><span data-stu-id="8ada6-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="8ada6-215">I file server di Batch per intelligenza artificiale possono essere gestiti tramite il portale di Azure o con l'[interfaccia della riga di comando di Azure][cli] e l'SDK Python.</span><span class="sxs-lookup"><span data-stu-id="8ada6-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="8ada6-216">Per avere un'idea dello stato complessivo del cluster, passare al pannello **Batch per intelligenza artificiale** del portale di Azure e ispezionare lo stato dei nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="8ada6-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="8ada6-217">Se un nodo è inattivo oppure un processo non riesce, i log degli errori vengono salvati nell'archiviazione BLOB e sono accessibili anche dal pannello **Processi** nel portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="8ada6-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="8ada6-218">Per un monitoraggio più completo, è possibile connettere i log ad [Azure Application Insights][ai] o eseguire processi separati per il polling dello stato del cluster di Batch per intelligenza artificiale e relativi processi.</span><span class="sxs-lookup"><span data-stu-id="8ada6-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="8ada6-219">Batch per intelligenza artificiale registra automaticamente tutti i percorsi StdOut/StdErr per l'account di archiviazione BLOB associato.</span><span class="sxs-lookup"><span data-stu-id="8ada6-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="8ada6-220">L'uso di uno strumento di esplorazione dell'archiviazione, come ad esempio [Azure Storage Explorer][storage-explorer], offre un'esperienza molto più semplice per scorrere i file di log.</span><span class="sxs-lookup"><span data-stu-id="8ada6-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="8ada6-221">È anche possibile trasmettere i log per ogni processo.</span><span class="sxs-lookup"><span data-stu-id="8ada6-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="8ada6-222">Per i dettagli su questa opzione, vedere i passaggi di sviluppo in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ada6-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="8ada6-223">Distribuzione</span><span class="sxs-lookup"><span data-stu-id="8ada6-223">Deployment</span></span>

<span data-ttu-id="8ada6-224">L'implementazione di riferimento per questa architettura è disponibile in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ada6-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="8ada6-225">Seguire i passaggi descritti per svolgere un training distribuito dei modelli di Deep Learning tra cluster di VM abilitate per GPU.</span><span class="sxs-lookup"><span data-stu-id="8ada6-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="8ada6-226">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="8ada6-226">Next steps</span></span>

<span data-ttu-id="8ada6-227">L'output di questa architettura è un modello sottoposto a training salvato nell'archiviazione BLOB.</span><span class="sxs-lookup"><span data-stu-id="8ada6-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="8ada6-228">È possibile usare questo modello per l'assegnazione di punteggi in tempo reale o in batch.</span><span class="sxs-lookup"><span data-stu-id="8ada6-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="8ada6-229">Per altre informazioni, vedere le architetture di riferimento seguenti:</span><span class="sxs-lookup"><span data-stu-id="8ada6-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="8ada6-230">[Assegnazione di punteggi in tempo reale per modelli Python scikit-learn e di Deep Learning in Azure][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="8ada6-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="8ada6-231">[Punteggio batch in Azure per modelli di apprendimento avanzato][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="8ada6-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning