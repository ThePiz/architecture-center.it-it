---
title: Assegnazione dei punteggi con i modelli R in Azure batch
description: Eseguire con i modelli R con Azure Batch e un set di dati basato su vendite al dettaglio store le previsioni di vendita di assegnazione punteggio batch.
author: njray
ms.date: 03/29/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 72769cf078596f0312a1f4293205dda5a086ef41
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 04/17/2019
ms.locfileid: "59639904"
---
# <a name="batch-scoring-of-r-machine-learning-models-on-azure"></a><span data-ttu-id="918f7-103">Valutazione dei modelli di machine learning di R in Azure batch</span><span class="sxs-lookup"><span data-stu-id="918f7-103">Batch scoring of R machine learning models on Azure</span></span>

<span data-ttu-id="918f7-104">Questa architettura di riferimento illustra come eseguire l'assegnazione del punteggio con modelli R con Batch di Azure batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-104">This reference architecture shows how to perform batch scoring with R models using Azure Batch.</span></span> <span data-ttu-id="918f7-105">Lo scenario è basato sulla previsione della vendita store delle vendite al dettaglio, ma questa architettura può essere generalizzata per qualsiasi scenario che richiedono la generazione di stime su un grande scaler usando i modelli R.</span><span class="sxs-lookup"><span data-stu-id="918f7-105">The scenario is based on retail store sales forecasting, but this architecture can be generalized for any scenario requiring the generation of predictions on a large scaler using R models.</span></span> <span data-ttu-id="918f7-106">Un'implementazione di riferimento per questa architettura è disponibile in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="918f7-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Diagramma dell'architettura][0]

<span data-ttu-id="918f7-108">**Scenario**: Una catena di supermercati deve prevedere le vendite di prodotti in trimestre imminente.</span><span class="sxs-lookup"><span data-stu-id="918f7-108">**Scenario**: A supermarket chain needs to forecast sales of products over the upcoming quarter.</span></span> <span data-ttu-id="918f7-109">La previsione consente all'azienda di gestire meglio la supply chain e verificare che è possibile soddisfare la domanda per i prodotti in ciascuno dei relativi oggetti Store.</span><span class="sxs-lookup"><span data-stu-id="918f7-109">The forecast allows the company to manage its supply chain better and ensure it can meet demand for products at each of its stores.</span></span> <span data-ttu-id="918f7-110">L'azienda Aggiorna rispettive previsioni ogni settimana di nuovi dati di vendita da settimana precedente diventano disponibili mentre il prodotto della strategia di marketing per trimestre successivo.</span><span class="sxs-lookup"><span data-stu-id="918f7-110">The company updates its forecasts every week as new sales data from the previous week becomes available and the product marketing strategy for next quarter is set.</span></span> <span data-ttu-id="918f7-111">Quantile previsioni vengono generate per stimare l'incertezza di previsioni di vendita singoli.</span><span class="sxs-lookup"><span data-stu-id="918f7-111">Quantile forecasts are generated to estimate the uncertainty of the individual sales forecasts.</span></span>

<span data-ttu-id="918f7-112">L'elaborazione prevede i passaggi seguenti:</span><span class="sxs-lookup"><span data-stu-id="918f7-112">Processing involves the following steps:</span></span>

1. <span data-ttu-id="918f7-113">Un'App per la logica di Azure attiva il processo di generazione previsione una volta alla settimana.</span><span class="sxs-lookup"><span data-stu-id="918f7-113">An Azure Logic App triggers the forecast generation process once per week.</span></span>

1. <span data-ttu-id="918f7-114">L'app per la logica viene avviata un'istanza di contenitore di Azure che esegue l'utilità di pianificazione contenitore Docker, che attiva i processi di assegnazione dei punteggi nel cluster di Batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-114">The logic app starts an Azure Container Instance running the scheduler Docker container, which triggers the scoring jobs on the Batch cluster.</span></span>

1. <span data-ttu-id="918f7-115">Assegnazione dei punteggi i processi eseguiti in parallelo tra i nodi del cluster di Batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-115">Scoring jobs run in parallel across the nodes of the Batch cluster.</span></span> <span data-ttu-id="918f7-116">Ogni nodo:</span><span class="sxs-lookup"><span data-stu-id="918f7-116">Each node:</span></span>

    1. <span data-ttu-id="918f7-117">Estrae il ruolo di lavoro come immagine Docker da Docker Hub e avvia un contenitore.</span><span class="sxs-lookup"><span data-stu-id="918f7-117">Pulls the worker Docker image from Docker Hub and starts a container.</span></span>

    1. <span data-ttu-id="918f7-118">Legge i dati di input e pre-Training modelli di R da un archivio Blob di Azure.</span><span class="sxs-lookup"><span data-stu-id="918f7-118">Reads input data and pre-trained R models from Azure Blob storage.</span></span>

    1. <span data-ttu-id="918f7-119">Assegna un punteggio a dati per produrre previsioni.</span><span class="sxs-lookup"><span data-stu-id="918f7-119">Scores the data to produce the forecasts.</span></span>

    1. <span data-ttu-id="918f7-120">Scrive i risultati di previsione in archiviazione blob.</span><span class="sxs-lookup"><span data-stu-id="918f7-120">Writes the forecast results to blob storage.</span></span>

<span data-ttu-id="918f7-121">La figura seguente mostra le vendite previste per i quattro prodotti (SKU) in un archivio.</span><span class="sxs-lookup"><span data-stu-id="918f7-121">The figure below shows the forecasted sales for four products (SKUs) in one store.</span></span> <span data-ttu-id="918f7-122">La linea nera è la cronologia di vendita, la linea tratteggiata è il valore mediano (q50) di previsione, la banda rosa rappresenta i percentili venti quinto e fa quattrocentonovantadue quinto e la striscia di colore blu rappresenta i quinto e il 90 quinto percentili.</span><span class="sxs-lookup"><span data-stu-id="918f7-122">The black line is the sales history, the dashed line is the median (q50) forecast, the pink band represents the twenty-fifth and seventy-fifth percentiles, and the blue band represents the fifth and ninety-fifth percentiles.</span></span>

![Previsioni di vendita][1]

## <a name="architecture"></a><span data-ttu-id="918f7-124">Architettura</span><span class="sxs-lookup"><span data-stu-id="918f7-124">Architecture</span></span>

<span data-ttu-id="918f7-125">L'architettura è costituita dai componenti seguenti.</span><span class="sxs-lookup"><span data-stu-id="918f7-125">This architecture consists of the following components.</span></span>

<span data-ttu-id="918f7-126">[Azure Batch] [ batch] viene usato per eseguire i processi di generazione di previsione in parallelo in un cluster di macchine virtuali.</span><span class="sxs-lookup"><span data-stu-id="918f7-126">[Azure Batch][batch] is used to run forecast generation jobs in parallel on a cluster of virtual machines.</span></span> <span data-ttu-id="918f7-127">Le previsioni vengono eseguite usando macchina con training preliminare implementati in Azure Batch di R. i modelli di apprendimento può ridimensionare automaticamente il numero di macchine virtuali in base al numero di processi inviati al cluster.</span><span class="sxs-lookup"><span data-stu-id="918f7-127">Predictions are made using pre-trained machine learning models implemented in R. Azure Batch can automatically scale the number of VMs based on the number of jobs submitted to the cluster.</span></span> <span data-ttu-id="918f7-128">In ogni nodo, uno script R viene eseguito all'interno di un contenitore Docker da assegnare un punteggio dei dati e generare previsioni.</span><span class="sxs-lookup"><span data-stu-id="918f7-128">On each node, an R script runs within a Docker container to score data and generate forecasts.</span></span>

<span data-ttu-id="918f7-129">[Archiviazione Blob di Azure] [ blob] viene usato per archiviare i dati di input, i modelli di apprendimento automatico con training preliminare e i risultati di previsione.</span><span class="sxs-lookup"><span data-stu-id="918f7-129">[Azure Blob Storage][blob] is used to store the input data, the pre-trained machine learning models, and the forecast results.</span></span> <span data-ttu-id="918f7-130">Offre archiviazione molto conveniente per le prestazioni che richiede questo carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="918f7-130">It delivers very cost-effective storage for the performance that this workload requires.</span></span>

<span data-ttu-id="918f7-131">[Istanze di contenitore di Azure] [ aci] fornire calcolo senza server su richiesta.</span><span class="sxs-lookup"><span data-stu-id="918f7-131">[Azure Container Instances][aci] provide serverless compute on demand.</span></span> <span data-ttu-id="918f7-132">In questo caso, un'istanza di contenitore viene distribuita in una pianificazione per attivare i processi Batch che generano le previsioni.</span><span class="sxs-lookup"><span data-stu-id="918f7-132">In this case, a container instance is deployed on a schedule to trigger the Batch jobs that generate the forecasts.</span></span> <span data-ttu-id="918f7-133">I processi di Batch vengono attivati da uno script R con la [doAzureParallel][doAzureParallel] pacchetto.</span><span class="sxs-lookup"><span data-stu-id="918f7-133">The Batch jobs are triggered from an R script using the [doAzureParallel][doAzureParallel] package.</span></span> <span data-ttu-id="918f7-134">L'istanza di contenitore arresta automaticamente dopo aver completato i processi.</span><span class="sxs-lookup"><span data-stu-id="918f7-134">The container instance automatically shuts down once the jobs have finished.</span></span>

<span data-ttu-id="918f7-135">[Le app di Azure per la logica] [ logic-apps] attivare l'intero flusso di lavoro distribuendo le istanze di contenitore in una pianificazione.</span><span class="sxs-lookup"><span data-stu-id="918f7-135">[Azure Logic Apps][logic-apps] trigger the entire workflow by deploying the container instances on a schedule.</span></span> <span data-ttu-id="918f7-136">Un connettore di istanze di contenitore di Azure nelle App per la logica consente a un'istanza per la distribuzione su un intervallo di eventi del trigger.</span><span class="sxs-lookup"><span data-stu-id="918f7-136">An Azure Container Instances connector in Logic Apps allows an instance to be deployed upon a range of trigger events.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="918f7-137">Considerazioni sulle prestazioni</span><span class="sxs-lookup"><span data-stu-id="918f7-137">Performance considerations</span></span>

### <a name="containerized-deployment"></a><span data-ttu-id="918f7-138">Distribuzione in contenitori</span><span class="sxs-lookup"><span data-stu-id="918f7-138">Containerized deployment</span></span>

<span data-ttu-id="918f7-139">Questa architettura, tutti gli script R eseguiti all'interno [Docker](https://www.docker.com/) contenitori.</span><span class="sxs-lookup"><span data-stu-id="918f7-139">With this architecture, all R scripts run within [Docker](https://www.docker.com/) containers.</span></span> <span data-ttu-id="918f7-140">Ciò garantisce che gli script eseguiti in un ambiente coerente, con la stessa versione di R e le versioni dei pacchetti, ogni volta.</span><span class="sxs-lookup"><span data-stu-id="918f7-140">This ensures that the scripts run in a consistent environment, with the same R version and packages versions, every time.</span></span> <span data-ttu-id="918f7-141">Diverse immagini Docker vengono usate per i contenitori dell'utilità di pianificazione e di lavoro, perché ognuno ha un diverso set di dipendenze dei pacchetti R.</span><span class="sxs-lookup"><span data-stu-id="918f7-141">Separate Docker images are used for the scheduler and worker containers, because each has a different set of R package dependencies.</span></span>

<span data-ttu-id="918f7-142">Istanze di contenitore di Azure offre un ambiente senza server per eseguire il contenitore dell'utilità di pianificazione.</span><span class="sxs-lookup"><span data-stu-id="918f7-142">Azure Container Instances provides a serverless environment to run the scheduler container.</span></span> <span data-ttu-id="918f7-143">Il contenitore dell'utilità di pianificazione esegue uno script R che attiva l'assegnazione dei punteggi singoli processi in esecuzione in un cluster di Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-143">The scheduler container runs an R script that triggers the individual scoring jobs running on an Azure Batch cluster.</span></span>

<span data-ttu-id="918f7-144">Ogni nodo del cluster di Batch viene eseguito il contenitore del ruolo di lavoro, che esegue lo script di assegnazione dei punteggi.</span><span class="sxs-lookup"><span data-stu-id="918f7-144">Each node of the Batch cluster runs the worker container, which executes the scoring script.</span></span>

### <a name="parallelizing-the-workload"></a><span data-ttu-id="918f7-145">Parallelizzare il carico di lavoro</span><span class="sxs-lookup"><span data-stu-id="918f7-145">Parallelizing the workload</span></span>

<span data-ttu-id="918f7-146">Quando batch assegnare punteggi ai dati con i modelli R, prendere in considerazione come parallelizzare il carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="918f7-146">When batch scoring data with R models, consider how to parallelize the workload.</span></span> <span data-ttu-id="918f7-147">I dati di input devono essere partizionati in qualche modo, in modo che l'operazione di assegnazione dei punteggi può essere distribuito nei nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="918f7-147">The input data must be partitioned somehow so that the scoring operation can be distributed  across the cluster nodes.</span></span> <span data-ttu-id="918f7-148">Tentare approcci diversi per individuare la scelta migliore per distribuire il carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="918f7-148">Try different approaches to discover the best choice for distributing your workload.</span></span> <span data-ttu-id="918f7-149">Nel caso per caso, considerare quanto segue:</span><span class="sxs-lookup"><span data-stu-id="918f7-149">On a case-by-case basis, consider the following:</span></span>

- <span data-ttu-id="918f7-150">La quantità di dati possono essere caricati ed elaborati nella memoria di un singolo nodo.</span><span class="sxs-lookup"><span data-stu-id="918f7-150">How much data can be loaded and processed in the memory of a single node.</span></span>
- <span data-ttu-id="918f7-151">Il sovraccarico di avvio del processo ogni batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-151">The overhead of starting each batch job.</span></span>
- <span data-ttu-id="918f7-152">Il sovraccarico di caricamento dei modelli R.</span><span class="sxs-lookup"><span data-stu-id="918f7-152">The overhead of loading the R models.</span></span>

<span data-ttu-id="918f7-153">Nello scenario usato in questo esempio, gli oggetti modello sono di grandi dimensioni e richiede solo pochi secondi per generare una previsione per i singoli prodotti.</span><span class="sxs-lookup"><span data-stu-id="918f7-153">In the scenario used for this example, the model objects are large, and it takes only a few seconds to generate a forecast for individual products.</span></span> <span data-ttu-id="918f7-154">Per questo motivo, è possibile raggruppare i prodotti ed eseguire un singolo processo di Batch per ogni nodo.</span><span class="sxs-lookup"><span data-stu-id="918f7-154">For this reason, you can group the products and execute a single Batch job per node.</span></span> <span data-ttu-id="918f7-155">Un ciclo all'interno di ogni processo genera le previsioni per i prodotti in modo sequenziale.</span><span class="sxs-lookup"><span data-stu-id="918f7-155">A loop within each job generates forecasts for the products sequentially.</span></span> <span data-ttu-id="918f7-156">Questo metodo si rivela il modo più efficiente per parallelizzare il carico di lavoro specifico.</span><span class="sxs-lookup"><span data-stu-id="918f7-156">This method turns out to be the most efficient way to parallelize this particular workload.</span></span> <span data-ttu-id="918f7-157">Evita il sovraccarico di avvio molti processi Batch più piccoli e più volte il caricamento dei modelli R.</span><span class="sxs-lookup"><span data-stu-id="918f7-157">It avoids the overhead of starting many smaller Batch jobs and repeatedly loading the R models.</span></span>

<span data-ttu-id="918f7-158">Un approccio alternativo consiste nell'attivare un processo Batch per ogni prodotto.</span><span class="sxs-lookup"><span data-stu-id="918f7-158">An alternative approach is to trigger one Batch job per product.</span></span> <span data-ttu-id="918f7-159">Azure Batch automaticamente costituisce una coda dei processi e li invia a essere eseguito nel cluster di nodi appena disponibili.</span><span class="sxs-lookup"><span data-stu-id="918f7-159">Azure Batch automatically forms a queue of jobs and submits them to be executed on the cluster as nodes become available.</span></span> <span data-ttu-id="918f7-160">Uso [scalabilità automatica] [ autoscale] per regolare il numero di nodi del cluster in base al numero di processi.</span><span class="sxs-lookup"><span data-stu-id="918f7-160">Use [automatic scaling][autoscale] to adjust the number of nodes in the cluster depending on the number of jobs.</span></span> <span data-ttu-id="918f7-161">Questo approccio risulta più utile se impiegato un tempo relativamente lungo per il completamento di ogni operazione di assegnazione dei punteggi, giustificare il sovraccarico di avviare i processi e il ricaricamento di oggetti modello.</span><span class="sxs-lookup"><span data-stu-id="918f7-161">This approach makes more sense if it takes a relatively long time to complete each scoring operation, justifying the overhead of starting the jobs and reloading the model objects.</span></span> <span data-ttu-id="918f7-162">Questo approccio è inoltre più semplice da implementare e ti offre la flessibilità necessaria per usare la scalabilità automatica, una considerazione importante se le dimensioni del carico di lavoro totale non sono noto in anticipo.</span><span class="sxs-lookup"><span data-stu-id="918f7-162">This approach is also simpler to implement and gives you the flexibility to use automatic scaling—an important consideration if the size of the total workload is not known in advance.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="918f7-163">Considerazioni relative a monitoraggio e registrazione</span><span class="sxs-lookup"><span data-stu-id="918f7-163">Monitoring and logging considerations</span></span>

### <a name="monitoring-azure-batch-jobs"></a><span data-ttu-id="918f7-164">Monitoraggio dei processi di Azure Batch</span><span class="sxs-lookup"><span data-stu-id="918f7-164">Monitoring Azure Batch jobs</span></span>

<span data-ttu-id="918f7-165">Monitoraggio e terminazione dei processi di Batch dal **processi** riquadro dell'account Batch nel portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="918f7-165">Monitor and terminate Batch jobs from the **Jobs** pane of the Batch account in the Azure portal.</span></span> <span data-ttu-id="918f7-166">Monitorare il cluster di batch, compreso lo stato dei singoli nodi, il **pool** riquadro.</span><span class="sxs-lookup"><span data-stu-id="918f7-166">Monitor the batch cluster, including the state of individual nodes, from the **Pools** pane.</span></span>

### <a name="logging-with-doazureparallel"></a><span data-ttu-id="918f7-167">Registrazione con il pacchetto doAzureParallel</span><span class="sxs-lookup"><span data-stu-id="918f7-167">Logging with doAzureParallel</span></span>

<span data-ttu-id="918f7-168">Il pacchetto doAzureParallel raccoglie automaticamente i log di tutti i stdout/stderr per ogni processo inviato in Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="918f7-168">The doAzureParallel package automatically collects logs of all stdout/stderr for every job submitted on Azure Batch.</span></span> <span data-ttu-id="918f7-169">Questi sono disponibili nell'account di archiviazione creato al momento dell'installazione.</span><span class="sxs-lookup"><span data-stu-id="918f7-169">These can be found in the storage account created at setup.</span></span> <span data-ttu-id="918f7-170">Per visualizzarli, usare uno strumento di esplorazione di archiviazione, ad esempio [Azure Storage Explorer] [ storage-explorer] o il portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="918f7-170">To view them, use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] or Azure portal.</span></span>

<span data-ttu-id="918f7-171">Per eseguire rapidamente il debug dei processi di Batch durante lo sviluppo, stampa i log di sessione R locale usando il [getJobFiles][getJobFiles] funzione del pacchetto doAzureParallel.</span><span class="sxs-lookup"><span data-stu-id="918f7-171">To quickly debug Batch jobs during development, print logs in your local R session using the [getJobFiles][getJobFiles] function of doAzureParallel.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="918f7-172">Considerazioni sul costo</span><span class="sxs-lookup"><span data-stu-id="918f7-172">Cost considerations</span></span>

<span data-ttu-id="918f7-173">Le risorse di calcolo usate in questa architettura di riferimento sono i componenti più costosi.</span><span class="sxs-lookup"><span data-stu-id="918f7-173">The compute resources used in this reference architecture are the most costly components.</span></span> <span data-ttu-id="918f7-174">Per questo scenario, ogni volta che viene attivato e quindi chiusa dopo che il processo venga completato il processo viene creato un cluster di dimensioni fisse.</span><span class="sxs-lookup"><span data-stu-id="918f7-174">For this scenario, a cluster of fixed size is created whenever the job is triggered and then shut down after the job has completed.</span></span> <span data-ttu-id="918f7-175">Costi vengono addebitati solo mentre i nodi del cluster sono avvio, l'esecuzione o arresto.</span><span class="sxs-lookup"><span data-stu-id="918f7-175">Cost is incurred only while the cluster nodes are starting, running, or shutting down.</span></span> <span data-ttu-id="918f7-176">Questo approccio è adatto per uno scenario in cui le risorse di calcolo necessari per generare le previsioni rimangono abbastanza costanti da un processo a processo.</span><span class="sxs-lookup"><span data-stu-id="918f7-176">This approach is suitable for a scenario where the compute resources required to generate the forecasts remain relatively constant from job to job.</span></span>

<span data-ttu-id="918f7-177">Negli scenari in cui la quantità di calcolo necessaria per completare il processo non è noto in anticipo, potrebbe essere più opportuno usare la scalabilità automatica.</span><span class="sxs-lookup"><span data-stu-id="918f7-177">In scenarios where the amount of compute required to complete the job is not known in advance, it may be more suitable to use automatic scaling.</span></span> <span data-ttu-id="918f7-178">Con questo approccio, le dimensioni del cluster viene ridimensionata verso l'alto o verso il basso a seconda delle dimensioni del processo.</span><span class="sxs-lookup"><span data-stu-id="918f7-178">With this approach, the size of the cluster is scaled up or down depending on the size of the job.</span></span> <span data-ttu-id="918f7-179">Azure Batch supporta una gamma di formule di scalabilità automatica che è possibile impostare quando si definisce il cluster usando il [doAzureParallel][doAzureParallel] API.</span><span class="sxs-lookup"><span data-stu-id="918f7-179">Azure Batch supports a range of auto-scale formulae which you can set when defining the cluster using the [doAzureParallel][doAzureParallel] API.</span></span>

<span data-ttu-id="918f7-180">Per alcuni scenari, il tempo tra i processi potrebbe essere troppo breve per arrestare e avviare il cluster.</span><span class="sxs-lookup"><span data-stu-id="918f7-180">For some scenarios, the time between jobs may be too short to shut down and start up the cluster.</span></span> <span data-ttu-id="918f7-181">In questi casi, mantenere il cluster in esecuzione tra i processi se appropriato.</span><span class="sxs-lookup"><span data-stu-id="918f7-181">In these cases, keep the cluster running between jobs if appropriate.</span></span>

<span data-ttu-id="918f7-182">Azure Batch e doAzureParallel supporta l'uso di macchine virtuali con priorità bassa.</span><span class="sxs-lookup"><span data-stu-id="918f7-182">Azure Batch and doAzureParallel support the use of low-priority VMs.</span></span> <span data-ttu-id="918f7-183">Queste macchine virtuali includono un sconto significativo ma rischio viene prevista da altri carichi di lavoro con priorità superiore.</span><span class="sxs-lookup"><span data-stu-id="918f7-183">These VMs come with a significant discount but risk being appropriated by other higher priority workloads.</span></span> <span data-ttu-id="918f7-184">L'uso di queste macchine virtuali non sono quindi consigliati per i carichi di lavoro di produzione critici.</span><span class="sxs-lookup"><span data-stu-id="918f7-184">The use of these VMs are therefore not recommended for critical production workloads.</span></span> <span data-ttu-id="918f7-185">Tuttavia, sono molto utili per sperimentali o i carichi di lavoro di sviluppo.</span><span class="sxs-lookup"><span data-stu-id="918f7-185">However, they are very useful for experimental or development workloads.</span></span>

## <a name="deployment"></a><span data-ttu-id="918f7-186">Distribuzione</span><span class="sxs-lookup"><span data-stu-id="918f7-186">Deployment</span></span>

<span data-ttu-id="918f7-187">Per distribuire questa architettura di riferimento, seguire i passaggi descritti nel [GitHub][github] repository.</span><span class="sxs-lookup"><span data-stu-id="918f7-187">To deploy this reference architecture, follow the steps described in the [GitHub][github] repo.</span></span>

[0]: ./_images/batch-scoring-r-models.png
[1]: ./_images/sales-forecasts.png
[aci]: /azure/container-instances/container-instances-overview
[autoscale]: /azure/batch/batch-automatic-scaling
[batch]: /azure/batch/batch-technical-overview
[blob]: /azure/storage/blobs/storage-blobs-introduction
[doAzureParallel]: https://github.com/Azure/doAzureParallel/blob/master/docs/32-autoscale.md
[getJobFiles]: /azure/machine-learning/service/how-to-train-ml-models
[github]: https://github.com/Azure/RBatchScoring
[logic-apps]: /azure/logic-apps/logic-apps-overview
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows