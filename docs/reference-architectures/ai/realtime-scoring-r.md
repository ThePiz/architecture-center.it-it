---
title: Assegnazione dei punteggi in tempo reale per i modelli R di Machine Learning
description: Implementare un servizio di stima in tempo reale in R con Machine Learning Server in esecuzione nel servizio Azure Kubernetes.
author: njray
ms.date: 12/12/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 00bea3cae0c3d2f0fea2babd7b0157382cf9890a
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 01/23/2019
ms.locfileid: "54487169"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a><span data-ttu-id="67d1c-103">Assegnazione dei punteggi in tempo reale per i modelli R di Machine Learning</span><span class="sxs-lookup"><span data-stu-id="67d1c-103">Real-time scoring of R machine learning models</span></span>

<span data-ttu-id="67d1c-104">Questa architettura di riferimento mostra come implementare un servizio di stima in tempo reale (sincrono) in R con Microsoft Machine Learning Server in esecuzione nel servizio Azure Kubernetes (AKS).</span><span class="sxs-lookup"><span data-stu-id="67d1c-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="67d1c-105">Questa architettura generica è progettata per essere adatta a qualsiasi modello predittivo compilato in R che si desidera distribuire come servizio in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="67d1c-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="67d1c-106">**[Distribuire questa soluzione][github]**.</span><span class="sxs-lookup"><span data-stu-id="67d1c-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="67d1c-107">Architettura</span><span class="sxs-lookup"><span data-stu-id="67d1c-107">Architecture</span></span>

![Assegnazione dei punteggi in tempo reale per i modelli R di Machine Learning in Azure][0]

<span data-ttu-id="67d1c-109">Questa architettura di riferimento adotta un approccio basato su contenitori.</span><span class="sxs-lookup"><span data-stu-id="67d1c-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="67d1c-110">Un'immagine del Docker viene compilata con R, insieme ai vari artefatti necessari per valutare nuovi dati.</span><span class="sxs-lookup"><span data-stu-id="67d1c-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="67d1c-111">Questi includono l'oggetto modello stesso e uno script di assegnazione dei punteggi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="67d1c-112">Il push dell'immagine viene eseguito in un registro di Docker ospitato in Azure. Successivamente, l'immagine viene distribuita in un cluster Kubernetes, anch'esso in Azure.</span><span class="sxs-lookup"><span data-stu-id="67d1c-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="67d1c-113">L'architettura di questo flusso di lavoro include i seguenti componenti.</span><span class="sxs-lookup"><span data-stu-id="67d1c-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="67d1c-114">Il **[Registro Azure Container][acr]** è usato per archiviare le immagini per questo flusso di lavoro.</span><span class="sxs-lookup"><span data-stu-id="67d1c-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="67d1c-115">I registri creati con il Registro Azure Container possono essere gestiti tramite l'[API Docker Registry V2][docker] e il client standard.</span><span class="sxs-lookup"><span data-stu-id="67d1c-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="67d1c-116">Il **[servizio Azure Kubernetes][aks]** è usato per ospitare la distribuzione e il servizio.</span><span class="sxs-lookup"><span data-stu-id="67d1c-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="67d1c-117">I cluster creati con il servizio Azure Kubernetes possono essere gestiti tramite l'[API Kubernetes][k-api] e il client standard (kubectl).</span><span class="sxs-lookup"><span data-stu-id="67d1c-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="67d1c-118">**[Microsoft Machine Learning Server][mmls]** è usato per definire l'API REST per il servizio e include l'[operazionalizzazione del modello][operationalization].</span><span class="sxs-lookup"><span data-stu-id="67d1c-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="67d1c-119">Questo processo di server web orientato sui servizi rimane in ascolto in attesa di richieste, che vengono quindi passate ad altri processi in background, i quali eseguono il codice R effettivo per generare i risultati.</span><span class="sxs-lookup"><span data-stu-id="67d1c-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="67d1c-120">In questa configurazione, tutti questi processi vengono eseguiti in un singolo nodo, di cui viene eseguito il wrapping in un contenitore.</span><span class="sxs-lookup"><span data-stu-id="67d1c-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="67d1c-121">Per informazioni dettagliate sull'uso di questo servizio all'esterno di un ambiente di sviluppo o test, contattare il rappresentante Microsoft.</span><span class="sxs-lookup"><span data-stu-id="67d1c-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="67d1c-122">Considerazioni sulle prestazioni</span><span class="sxs-lookup"><span data-stu-id="67d1c-122">Performance considerations</span></span>

<span data-ttu-id="67d1c-123">I carichi di lavoro di apprendimento automatico tendono a essere processi di calcolo complessi, sia durante il training che nella classificazione di dati nuovi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="67d1c-124">Come regola generale, bisogna provare a non eseguire più di un processo di assegnazione dei punteggi per ogni core.</span><span class="sxs-lookup"><span data-stu-id="67d1c-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="67d1c-125">Microsoft Machine Learning Server consente di definire il numero di processi R in esecuzione in ciascun contenitore.</span><span class="sxs-lookup"><span data-stu-id="67d1c-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="67d1c-126">Il valore predefinito è di cinque processi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-126">The default is five processes.</span></span> <span data-ttu-id="67d1c-127">Quando si crea un modello relativamente semplice, ad esempio una regressione lineare con un numero ridotto di variabili o un albero delle decisioni di piccole dimensioni, è possibile aumentare il numero di processi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="67d1c-128">Monitorare il carico della CPU nei nodi del cluster per determinare il limite di numero di contenitori adeguato.</span><span class="sxs-lookup"><span data-stu-id="67d1c-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="67d1c-129">Un cluster abilitato per GPU può accelerare alcuni tipi di carichi di lavoro e, in particolare, alcuni modelli di deep learning.</span><span class="sxs-lookup"><span data-stu-id="67d1c-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="67d1c-130">Non tutti i carichi di lavoro possono sfruttare i vantaggi della GPU, ma solo quelli che fanno un uso massiccio dell'algebra matriciale.</span><span class="sxs-lookup"><span data-stu-id="67d1c-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="67d1c-131">I modelli basati su albero, ad esempio, tra cui le foreste casuali e i modelli di miglioramento, in genere non traggono alcun vantaggio dalle GPU.</span><span class="sxs-lookup"><span data-stu-id="67d1c-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="67d1c-132">Alcuni tipi di modello, come le foreste casuali, sono altamente parallelizzabili sulle CPU.</span><span class="sxs-lookup"><span data-stu-id="67d1c-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="67d1c-133">In questi casi, è possibile velocizzare l'assegnazione dei punteggi di una singola richiesta distribuendo il carico di lavoro su più core.</span><span class="sxs-lookup"><span data-stu-id="67d1c-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="67d1c-134">Tuttavia, questo riduce la capacità di gestire più richieste di assegnazione dei punteggi data una dimensione del cluster predefinita.</span><span class="sxs-lookup"><span data-stu-id="67d1c-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="67d1c-135">In generale, i modelli R open source archiviano tutti i dati in memoria, pertanto è necessario verificare che i nodi abbiano memoria sufficiente per supportare i processi che si desiderano eseguire simultaneamente.</span><span class="sxs-lookup"><span data-stu-id="67d1c-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="67d1c-136">Se si usa Microsoft Machine Learning Server per i modelli, usare librerie in grado di elaborare i dati su disco, anziché leggerli tutti in memoria.</span><span class="sxs-lookup"><span data-stu-id="67d1c-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="67d1c-137">Questo consente di ridurre sensibilmente i requisiti di memoria.</span><span class="sxs-lookup"><span data-stu-id="67d1c-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="67d1c-138">Indipendentemente dall'uso di Microsoft Machine Learning Server o R open source, il monitoraggio dei nodi assicura che i processi di assegnazione dei punteggi non esauriscano la memoria.</span><span class="sxs-lookup"><span data-stu-id="67d1c-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="67d1c-139">Considerazioni relative alla sicurezza</span><span class="sxs-lookup"><span data-stu-id="67d1c-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="67d1c-140">Crittografia di rete</span><span class="sxs-lookup"><span data-stu-id="67d1c-140">Network encryption</span></span>

<span data-ttu-id="67d1c-141">In questa architettura di riferimento è abilitato il protocollo HTTPS per la comunicazione con il cluster, mentre viene usato un certificato di gestione temporanea di [Let's Encrypt][encrypt].</span><span class="sxs-lookup"><span data-stu-id="67d1c-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="67d1c-142">Per scopi di produzione, sostituire il proprio certificato di un'autorità di firma adeguata.</span><span class="sxs-lookup"><span data-stu-id="67d1c-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="67d1c-143">Autenticazione e autorizzazione</span><span class="sxs-lookup"><span data-stu-id="67d1c-143">Authentication and authorization</span></span>

<span data-ttu-id="67d1c-144">L'[operazionalizzazione del modello][operationalization] di Microsoft Machine Learning Server richiede l'autenticazione delle richieste di assegnazione dei punteggi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="67d1c-145">In questa distribuzione, vengono usati un nome utente e una password.</span><span class="sxs-lookup"><span data-stu-id="67d1c-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="67d1c-146">In uno scenario aziendale, è possibile abilitare l'autenticazione usando [Azure Active Directory][AAD] oppure creare un front end separato usando [Gestione API di Azure][API].</span><span class="sxs-lookup"><span data-stu-id="67d1c-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="67d1c-147">È necessario installare un certificato token JSON Web (JWT) perché l'operazionalizzazione del modello funzioni correttamente con Microsoft Machine Learning Server nei contenitori.</span><span class="sxs-lookup"><span data-stu-id="67d1c-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="67d1c-148">Questa distribuzione usa un certificato fornito da Microsoft.</span><span class="sxs-lookup"><span data-stu-id="67d1c-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="67d1c-149">In uno scenario di produzione, è necessario fornire il proprio certificato.</span><span class="sxs-lookup"><span data-stu-id="67d1c-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="67d1c-150">Per il traffico tra il servizio Azure Kubernetes e il Registro Azure Container, provare ad abilitare il [controllo degli accessi in base al ruolo][rbac] (RBAC) per limitare i privilegi di accesso solo a quelli necessari.</span><span class="sxs-lookup"><span data-stu-id="67d1c-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span>

### <a name="separate-storage"></a><span data-ttu-id="67d1c-151">Archiviazione separata</span><span class="sxs-lookup"><span data-stu-id="67d1c-151">Separate storage</span></span>

<span data-ttu-id="67d1c-152">Questa architettura di riferimento raggruppa l'applicazione (R) e i dati (oggetto modello e script di assegnazione dei punteggi) in un'unica immagine.</span><span class="sxs-lookup"><span data-stu-id="67d1c-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="67d1c-153">In alcuni casi, può risultare vantaggioso separarli.</span><span class="sxs-lookup"><span data-stu-id="67d1c-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="67d1c-154">È possibile inserire i dati e il codice del modello nel blob o file di [archiviazione][storage] di Azure e recuperarli durante la fase di inizializzazione del contenitore.</span><span class="sxs-lookup"><span data-stu-id="67d1c-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="67d1c-155">In questo caso, assicurarsi che l'account di archiviazione sia configurato in modo da consentire l'accesso solo tramite autenticazione e con protocollo HTTPS.</span><span class="sxs-lookup"><span data-stu-id="67d1c-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="67d1c-156">Considerazioni relative a monitoraggio e registrazione</span><span class="sxs-lookup"><span data-stu-id="67d1c-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="67d1c-157">Usare la [dashboard di Kubernetes][dashboard] per monitorare lo stato complessivo del cluster del servizio Azure Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="67d1c-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="67d1c-158">Per altri dettagli, vedere il pannello di panoramica del cluster nel portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="67d1c-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="67d1c-159">Le risorse di [GitHub][github] illustrano anche come visualizzare la dashboard da R.</span><span class="sxs-lookup"><span data-stu-id="67d1c-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="67d1c-160">Anche se la dashboard offre una panoramica dell'integrità complessiva del cluster, è anche importante tenere traccia dello stato dei singoli contenitori.</span><span class="sxs-lookup"><span data-stu-id="67d1c-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="67d1c-161">A tale scopo, abilitare [Informazioni dettagliate sul monitoraggio di Azure][monitor] dal pannello di panoramica del cluster nel portale di Azure, oppure consultare [Monitoraggio di Azure per contenitori][monitor-containers] (in anteprima).</span><span class="sxs-lookup"><span data-stu-id="67d1c-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="67d1c-162">Considerazioni sul costo</span><span class="sxs-lookup"><span data-stu-id="67d1c-162">Cost considerations</span></span>

<span data-ttu-id="67d1c-163">Microsoft Machine Learning Server viene concesso in licenza in base ai core, compresi tutti i core del cluster che eseguiranno Microsoft Machine Learning Server.</span><span class="sxs-lookup"><span data-stu-id="67d1c-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="67d1c-164">Se si fa parte di un'impresa cliente Machine Learning Server o Microsoft SQL Server, contattare il rappresentante Microsoft per i dettagli sui prezzi.</span><span class="sxs-lookup"><span data-stu-id="67d1c-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="67d1c-165">Un'alternativa open source a Microsoft Machine Learning Server è rappresentata da [Plumber][plumber], un pacchetto R che trasforma il codice in un'API REST.</span><span class="sxs-lookup"><span data-stu-id="67d1c-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="67d1c-166">Plumber dispone di meno funzionalità rispetto a Microsoft Machine Learning Server.</span><span class="sxs-lookup"><span data-stu-id="67d1c-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="67d1c-167">Ad esempio, per impostazione predefinita non include le funzionalità che forniscono l'autenticazione richiesta.</span><span class="sxs-lookup"><span data-stu-id="67d1c-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="67d1c-168">Se si usa Plumber, si consiglia di abilitare la [Gestione API di Azure][API] per gestire i dettagli di autenticazione.</span><span class="sxs-lookup"><span data-stu-id="67d1c-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="67d1c-169">Oltre alle licenze, i maggiori costi sono rappresentati dalle risorse di calcolo del cluster Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="67d1c-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="67d1c-170">Il cluster deve essere sufficientemente grande per gestire il volume di richiesta previsto nei periodi di picco, ma questo approccio lascia le risorse inattive in altri momenti.</span><span class="sxs-lookup"><span data-stu-id="67d1c-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="67d1c-171">Per limitare l'impatto delle risorse inattive, abilitare la [scalabilità automatica orizzontale][autoscaler] per il cluster usando lo strumento kubectl.</span><span class="sxs-lookup"><span data-stu-id="67d1c-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="67d1c-172">In alternativa, usare il [ridimensionamento automatico del cluster][cluster-autoscaler] del servizio Azure Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="67d1c-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="67d1c-173">Distribuire la soluzione</span><span class="sxs-lookup"><span data-stu-id="67d1c-173">Deploy the solution</span></span>

<span data-ttu-id="67d1c-174">L'implementazione di riferimento per questa architettura è disponibile in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="67d1c-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="67d1c-175">Seguire la procedura indicata per distribuire un semplice modello predittivo come servizio.</span><span class="sxs-lookup"><span data-stu-id="67d1c-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
