---
title: Assegnazione del punteggio in batch per i modelli Python in Azure
description: Creare una soluzione scalabile per l'assegnazione del punteggio in batch per i modelli in base a una pianificazione in parallelo tramite il servizio Azure Machine Learning.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: 9341b9e4c17025e9623902a6202076c352b237b9
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 04/17/2019
ms.locfileid: "59640550"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="d1fc4-103">Valutazione dei modelli di machine learning di Python in Azure batch</span><span class="sxs-lookup"><span data-stu-id="d1fc4-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="d1fc4-104">Questa architettura di riferimento illustra come creare una soluzione scalabile per l'assegnazione del punteggio in batch a molti modelli in base a una pianificazione in parallelo usando il servizio Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="d1fc4-105">La soluzione può essere usata come modello e supporta la generalizzazione per problemi diversi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="d1fc4-106">Un'implementazione di riferimento per questa architettura è disponibile in [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Assegnazione del punteggio in batch per i modelli Python in Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="d1fc4-108">**Scenario**: Questa soluzione consente di monitorare il funzionamento di un numero elevato di dispositivi in uno scenario IoT in cui ogni dispositivo invia le letture dei sensori in modo continuo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="d1fc4-109">Si presuppone che ogni dispositivo sia associato a modelli di rilevamento delle anomalie sottoposti precedentemente a training per prevedere se una serie di misurazioni, aggregate per un intervallo di tempo predefinito, corrispondono o meno a un'anomalia.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="d1fc4-110">In scenari reali, potrebbe trattarsi di un flusso di letture di sensori che devono essere filtrate e aggregate prima di essere usate per operazioni di training o per l'assegnazione del punteggio in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="d1fc4-111">Per semplicità, la soluzione usa lo stesso file di dati durante l'esecuzione dei processi di assegnazione del punteggio.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="d1fc4-112">Questa architettura di riferimento è progettata per carichi di lavoro che vengono attivati in base a una pianificazione.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="d1fc4-113">L'elaborazione prevede i passaggi seguenti:</span><span class="sxs-lookup"><span data-stu-id="d1fc4-113">Processing involves the following steps:</span></span>

1. <span data-ttu-id="d1fc4-114">Inviare le letture dei sensori per l'inserimento in Hub eventi di Azure.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2. <span data-ttu-id="d1fc4-115">Eseguire l'elaborazione dei flussi e archiviare i dati non elaborati.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-115">Perform stream processing and store the raw data.</span></span>
3. <span data-ttu-id="d1fc4-116">Inviare i dati a un cluster di Machine Learning pronto a iniziare ad assumere lavoro.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="d1fc4-117">Ogni nodo del cluster esegue un processo di assegnazione del punteggio per uno specifico sensore.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4. <span data-ttu-id="d1fc4-118">Eseguire la pipeline di assegnazione del punteggio, che esegue i processi in parallelo usando script Python di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="d1fc4-119">La pipeline viene creata, pubblicata ed eseguita in un intervallo di tempo predefinito e pianificato.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5. <span data-ttu-id="d1fc4-120">Generare previsioni e archiviarle in archiviazione BLOB per un utilizzo successivo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="d1fc4-121">Architettura</span><span class="sxs-lookup"><span data-stu-id="d1fc4-121">Architecture</span></span>

<span data-ttu-id="d1fc4-122">L'architettura è costituita dai componenti seguenti:</span><span class="sxs-lookup"><span data-stu-id="d1fc4-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="d1fc4-123">[Hub eventi di Azure][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="d1fc4-124">Questo servizio di inserimento dei messaggi può inserire milioni di messaggi di eventi al secondo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="d1fc4-125">In questa architettura, i sensori inviano un flusso di dati all'hub eventi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="d1fc4-126">[Analisi di flusso di Azure][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="d1fc4-127">Un motore di elaborazione di eventi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-127">An event-processing engine.</span></span> <span data-ttu-id="d1fc4-128">Un processo di Analisi di flusso legge i flussi di dati dall'hub eventi ed esegue l'elaborazione dei flussi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="d1fc4-129">[Database SQL di Azure][sql-database].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="d1fc4-130">I dati ricavati dalle letture dei sensori vengono caricati nel database SQL.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="d1fc4-131">SQL è uno strumento familiare in cui archiviare i flussi di dati elaborati (che sono tabulari e strutturati), ma è possibile usare altri archivi dati.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="d1fc4-132">[Servizio Azure Machine Learning][amls].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="d1fc4-133">Machine Learning è un servizio cloud per il training, l'assegnazione di punteggi, la distribuzione e la gestione di modelli di Machine Learning su vasta scala.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="d1fc4-134">Nel contesto dell'assegnazione di punteggi in batch, Machine Learning crea un cluster di macchine virtuali su richiesta con un'opzione di ridimensionamento automatico, in cui ogni nodo esegue un processo di assegnazione del punteggio per un sensore specifico.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="d1fc4-135">I processi di assegnazione del punteggio vengono eseguiti in parallelo con i passaggi dello script Python accodati e gestiti da Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="d1fc4-136">Questi passaggi fanno parte di una pipeline di Machine Learning che viene creata, distribuita ed eseguita in un intervallo di tempo predefinito e pianificato.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="d1fc4-137">[Archiviazione BLOB di Azure][storage].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="d1fc4-138">I contenitori BLOB vengono usati per archiviare i modelli già sottoposti a training, i dati e le stime di output.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="d1fc4-139">I modelli vengono caricati nell'archiviazione BLOB nel notebook [01_create_resources.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="d1fc4-140">I modelli [one-class SVM][one-class-svm] vengono sottoposti a training su dati che rappresentano i valori di sensori diversi per diversi dispositivi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="d1fc4-141">Questa soluzione presuppone che i valori dei dati vengano aggregati per un intervallo di tempo fisso.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="d1fc4-142">[Registro Azure Container][acr].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="d1fc4-143">Lo [script][pyscript] Python di assegnazione del punteggio viene eseguito in contenitori Docker che vengono creati in ogni nodo del cluster, in cui legge i dati del sensore pertinenti, genera previsioni e le archivia nell'archivio Blob.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="d1fc4-144">Considerazioni sulle prestazioni</span><span class="sxs-lookup"><span data-stu-id="d1fc4-144">Performance considerations</span></span>

<span data-ttu-id="d1fc4-145">Per i modelli Python standard, le CPU sono generalmente considerate sufficienti per gestire il carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="d1fc4-146">Questa architettura usa CPU.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-146">This architecture uses CPUs.</span></span> <span data-ttu-id="d1fc4-147">Tuttavia, per [carichi di lavoro di apprendimento avanzato][deep], GPU in genere prestazioni CPU di una quantità considerevole &mdash; un cluster di numero di CPU in genere è necessaria per ottenere prestazioni analoghe.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="d1fc4-148">La parallelizzazione tra le macchine virtuali e core</span><span class="sxs-lookup"><span data-stu-id="d1fc4-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="d1fc4-149">Durante l'esecuzione dei processi di assegnazione del punteggio a molti modelli in modalità batch, i processi devono essere eseguiti in parallelo tra le macchine virtuali.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="d1fc4-150">Sono possibili due approcci:</span><span class="sxs-lookup"><span data-stu-id="d1fc4-150">Two approaches are possible:</span></span>

* <span data-ttu-id="d1fc4-151">Creare un cluster più grande con macchine virtuali a basso costo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="d1fc4-152">Creare un cluster più piccolo con macchine virtuali a prestazioni elevate con più core disponibili in ognuna.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="d1fc4-153">In generale, l'assegnazione del punteggio a modelli di Python standard non è così impegnativa come l'assegnazione del punteggio a modelli di Deep Learning e un cluster piccolo dovrebbe deve essere in grado di gestire in modo efficiente un numero elevato di modelli in coda.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="d1fc4-154">È possibile aumentare il numero di nodi del cluster man mano che aumentano le dimensioni dei set di dati.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="d1fc4-155">Per motivi di praticità, in questo scenario viene inviata un'unica attività di assegnazione del punteggio all'interno di un singolo passaggio della pipeline di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="d1fc4-156">Tuttavia, può essere più efficiente assegnare il punteggio a più blocchi di dati all'interno dello stesso passaggio della pipeline.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="d1fc4-157">In questi casi, scrivere codice personalizzato per leggere in più set di dati ed eseguire lo script di assegnazione del punteggio per tali set durante l'esecuzione di un singolo passaggio.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="d1fc4-158">Considerazioni sulla gestione</span><span class="sxs-lookup"><span data-stu-id="d1fc4-158">Management considerations</span></span>

- <span data-ttu-id="d1fc4-159">**Monitoraggio dei processi**.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-159">**Monitor jobs**.</span></span> <span data-ttu-id="d1fc4-160">È importante monitorare lo stato dei processi in esecuzione, ma può essere complesso eseguire il monitoraggio in un cluster di nodi attivi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="d1fc4-161">Per esaminare lo stato dei nodi del cluster, usare il [portale di Azure][portal] per gestire l'[area di lavoro di Machine Learning][ml-workspace].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="d1fc4-162">Se un nodo è inattivo oppure un processo ha avuto esito negativo, i log degli errori vengono salvati nell'archiviazione BLOB e sono accessibili anche nella sezione Pipeline.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="d1fc4-163">Per un monitoraggio più completo, connettere i log ad [Application Insights][app-insights] o eseguire processi separati per il polling dello stato del cluster e dei relativi processi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
- <span data-ttu-id="d1fc4-164">**Registrazione**.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-164">**Logging**.</span></span> <span data-ttu-id="d1fc4-165">Il servizio Machine Learning registra tutti i flussi StdOut/StdErr nell'account di archiviazione di Azure associato.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="d1fc4-166">Per semplificare la visualizzazione dei file di log, usare uno strumento di esplorazione dell'archiviazione, ad esempio [Azure Storage Explorer][explorer].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="d1fc4-167">Considerazioni sul costo</span><span class="sxs-lookup"><span data-stu-id="d1fc4-167">Cost considerations</span></span>

<span data-ttu-id="d1fc4-168">I componenti più onerosi usati in questa architettura di riferimento sono le risorse di calcolo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="d1fc4-169">Le dimensioni del cluster di calcolo possono aumentare o diminuire a seconda dei processi presenti nella coda.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="d1fc4-170">Abilitare il ridimensionamento automatico a livello di codice tramite l'SDK Python modificando la configurazione del provisioning del calcolo.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="d1fc4-171">In alternativa, usare l'[interfaccia della riga di comando di Azure][cli] per impostare i parametri di ridimensionamento automatico del cluster.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="d1fc4-172">Per le operazioni che non richiedono un intervento immediato, configurare la formula di scalabilità automatica in modo che lo stato predefinito (minimo) sia rappresentato da un cluster con un numero di nodi pari a zero.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="d1fc4-173">Con questa configurazione, il cluster inizia con un numero di nodi pari a zero, per poi aumentare quando rileva processi nella coda.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="d1fc4-174">Se il processo di assegnazione del punteggio in batch si verifica poche volte al giorno, questa impostazione consente di ottenere un risparmio significativo sui costi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="d1fc4-175">La scalabilità automatica potrebbe non essere appropriata per i processi batch eseguiti a distanza troppo ravvicinata.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="d1fc4-176">Anche il tempo necessario per avviare e interrompere un cluster comporta dei costi. Pertanto, se un carico di lavoro batch inizia solo pochi minuti dopo il termine del processo precedente, potrebbe essere più conveniente lasciare il cluster attivo tra i processi.</span><span class="sxs-lookup"><span data-stu-id="d1fc4-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="d1fc4-177">Ciò dipende dalla frequenza pianificata per l'esecuzione dei processi di assegnazione del punteggio, ovvero elevata (ad esempio, ogni ora) o meno frequente (ad esempio, una volta al mese).</span><span class="sxs-lookup"><span data-stu-id="d1fc4-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>

## <a name="deployment"></a><span data-ttu-id="d1fc4-178">Distribuzione</span><span class="sxs-lookup"><span data-stu-id="d1fc4-178">Deployment</span></span>

<span data-ttu-id="d1fc4-179">Per distribuire questa architettura di riferimento, seguire la procedura descritta nel [repository GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="d1fc4-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
